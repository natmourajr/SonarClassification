{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5db1e8ed",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caa72844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f61f352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "import keras.callbacks as callbacks\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "from src.functions.AuxiliarFunctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3673cc4f",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d63c88a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_id</th>\n",
       "      <th>label</th>\n",
       "      <th>wav_files_path</th>\n",
       "      <th>processed_file_folder</th>\n",
       "      <th>processed_file_path</th>\n",
       "      <th>wav_files_info</th>\n",
       "      <th>cv_alg</th>\n",
       "      <th>cv_folds</th>\n",
       "      <th>cv_path</th>\n",
       "      <th>preproc_alg</th>\n",
       "      <th>...</th>\n",
       "      <th>target_id_file</th>\n",
       "      <th>model_path</th>\n",
       "      <th>model_inits</th>\n",
       "      <th>model_neurons</th>\n",
       "      <th>model_status</th>\n",
       "      <th>model_epochs</th>\n",
       "      <th>model_patience</th>\n",
       "      <th>model_learning_rate</th>\n",
       "      <th>model_optimizer</th>\n",
       "      <th>model_batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3786470895109500580</td>\n",
       "      <td>Toy Data Classification</td>\n",
       "      <td>../data/shipsEar_AUDIOS</td>\n",
       "      <td>../data</td>\n",
       "      <td>../data/3786470895109500580_processed_data.csv</td>\n",
       "      <td>../data/wav_file_informations.csv</td>\n",
       "      <td>StratifiedKFolds</td>\n",
       "      <td>5</td>\n",
       "      <td>../data/indexes</td>\n",
       "      <td>MFCC</td>\n",
       "      <td>...</td>\n",
       "      <td>../data/models/train_id_file.csv</td>\n",
       "      <td>../data/models</td>\n",
       "      <td>5</td>\n",
       "      <td>../data/models/3786470895109500580_hidden_neur...</td>\n",
       "      <td>../data/models/3786470895109500580_model_statu...</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5662987709573759986</td>\n",
       "      <td>Toy Data Classification</td>\n",
       "      <td>../data/shipsEar_AUDIOS</td>\n",
       "      <td>../data</td>\n",
       "      <td>../data/-5662987709573759986_processed_data.csv</td>\n",
       "      <td>../data/wav_file_informations.csv</td>\n",
       "      <td>StratifiedKFolds</td>\n",
       "      <td>5</td>\n",
       "      <td>../data/indexes</td>\n",
       "      <td>MFCC</td>\n",
       "      <td>...</td>\n",
       "      <td>../data/models/train_id_file.csv</td>\n",
       "      <td>../data/models</td>\n",
       "      <td>5</td>\n",
       "      <td>../data/models/-5662987709573759986_hidden_neu...</td>\n",
       "      <td>../data/models/-5662987709573759986_model_stat...</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3837049506038808913</td>\n",
       "      <td>Toy Data Classification</td>\n",
       "      <td>../data/shipsEar_AUDIOS</td>\n",
       "      <td>../data</td>\n",
       "      <td>../data/3837049506038808913_processed_data.csv</td>\n",
       "      <td>../data/wav_file_informations.csv</td>\n",
       "      <td>StratifiedKFolds</td>\n",
       "      <td>5</td>\n",
       "      <td>../data/indexes</td>\n",
       "      <td>MFCC</td>\n",
       "      <td>...</td>\n",
       "      <td>../data/models/train_id_file.csv</td>\n",
       "      <td>../data/models</td>\n",
       "      <td>1</td>\n",
       "      <td>../data/models/3837049506038808913_hidden_neur...</td>\n",
       "      <td>../data/models/3837049506038808913_model_statu...</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4644399470053765538</td>\n",
       "      <td>Toy Data Classification</td>\n",
       "      <td>../data/shipsEar_AUDIOS</td>\n",
       "      <td>../data</td>\n",
       "      <td>../data/4644399470053765538_processed_data.csv</td>\n",
       "      <td>../data/wav_file_informations.csv</td>\n",
       "      <td>StratifiedKFolds</td>\n",
       "      <td>5</td>\n",
       "      <td>../data/indexes</td>\n",
       "      <td>MFCC</td>\n",
       "      <td>...</td>\n",
       "      <td>../data/models/train_id_file.csv</td>\n",
       "      <td>../data/models</td>\n",
       "      <td>1</td>\n",
       "      <td>../data/models/4644399470053765538_hidden_neur...</td>\n",
       "      <td>../data/models/4644399470053765538_model_statu...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adam</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5754269668442876343</td>\n",
       "      <td>Toy Data Classification</td>\n",
       "      <td>../data/shipsEar_AUDIOS</td>\n",
       "      <td>../data</td>\n",
       "      <td>../data/5754269668442876343_processed_data.csv</td>\n",
       "      <td>../data/wav_file_informations.csv</td>\n",
       "      <td>StratifiedKFolds</td>\n",
       "      <td>2</td>\n",
       "      <td>../data/indexes</td>\n",
       "      <td>MFCC</td>\n",
       "      <td>...</td>\n",
       "      <td>../data/models/train_id_file.csv</td>\n",
       "      <td>../data/models</td>\n",
       "      <td>2</td>\n",
       "      <td>../data/models/5754269668442876343_hidden_neur...</td>\n",
       "      <td>../data/models/5754269668442876343_model_statu...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adam</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-8564343657574404315</td>\n",
       "      <td>Toy Data Classification</td>\n",
       "      <td>../data/shipsEar_AUDIOS</td>\n",
       "      <td>../data</td>\n",
       "      <td>../data/-8564343657574404315_processed_data.csv</td>\n",
       "      <td>../data/wav_file_informations.csv</td>\n",
       "      <td>StratifiedKFolds</td>\n",
       "      <td>5</td>\n",
       "      <td>../data/indexes</td>\n",
       "      <td>MFCC</td>\n",
       "      <td>...</td>\n",
       "      <td>../data/models/train_id_file.csv</td>\n",
       "      <td>../data/models</td>\n",
       "      <td>2</td>\n",
       "      <td>../data/models/-8564343657574404315_hidden_neu...</td>\n",
       "      <td>../data/models/-8564343657574404315_model_stat...</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>adam</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               hash_id                    label           wav_files_path  \\\n",
       "0  3786470895109500580  Toy Data Classification  ../data/shipsEar_AUDIOS   \n",
       "1 -5662987709573759986  Toy Data Classification  ../data/shipsEar_AUDIOS   \n",
       "2  3837049506038808913  Toy Data Classification  ../data/shipsEar_AUDIOS   \n",
       "3  4644399470053765538  Toy Data Classification  ../data/shipsEar_AUDIOS   \n",
       "4  5754269668442876343  Toy Data Classification  ../data/shipsEar_AUDIOS   \n",
       "5 -8564343657574404315  Toy Data Classification  ../data/shipsEar_AUDIOS   \n",
       "\n",
       "  processed_file_folder                              processed_file_path  \\\n",
       "0               ../data   ../data/3786470895109500580_processed_data.csv   \n",
       "1               ../data  ../data/-5662987709573759986_processed_data.csv   \n",
       "2               ../data   ../data/3837049506038808913_processed_data.csv   \n",
       "3               ../data   ../data/4644399470053765538_processed_data.csv   \n",
       "4               ../data   ../data/5754269668442876343_processed_data.csv   \n",
       "5               ../data  ../data/-8564343657574404315_processed_data.csv   \n",
       "\n",
       "                      wav_files_info            cv_alg  cv_folds  \\\n",
       "0  ../data/wav_file_informations.csv  StratifiedKFolds         5   \n",
       "1  ../data/wav_file_informations.csv  StratifiedKFolds         5   \n",
       "2  ../data/wav_file_informations.csv  StratifiedKFolds         5   \n",
       "3  ../data/wav_file_informations.csv  StratifiedKFolds         5   \n",
       "4  ../data/wav_file_informations.csv  StratifiedKFolds         2   \n",
       "5  ../data/wav_file_informations.csv  StratifiedKFolds         5   \n",
       "\n",
       "           cv_path preproc_alg  ...                    target_id_file  \\\n",
       "0  ../data/indexes        MFCC  ...  ../data/models/train_id_file.csv   \n",
       "1  ../data/indexes        MFCC  ...  ../data/models/train_id_file.csv   \n",
       "2  ../data/indexes        MFCC  ...  ../data/models/train_id_file.csv   \n",
       "3  ../data/indexes        MFCC  ...  ../data/models/train_id_file.csv   \n",
       "4  ../data/indexes        MFCC  ...  ../data/models/train_id_file.csv   \n",
       "5  ../data/indexes        MFCC  ...  ../data/models/train_id_file.csv   \n",
       "\n",
       "       model_path  model_inits  \\\n",
       "0  ../data/models            5   \n",
       "1  ../data/models            5   \n",
       "2  ../data/models            1   \n",
       "3  ../data/models            1   \n",
       "4  ../data/models            2   \n",
       "5  ../data/models            2   \n",
       "\n",
       "                                       model_neurons  \\\n",
       "0  ../data/models/3786470895109500580_hidden_neur...   \n",
       "1  ../data/models/-5662987709573759986_hidden_neu...   \n",
       "2  ../data/models/3837049506038808913_hidden_neur...   \n",
       "3  ../data/models/4644399470053765538_hidden_neur...   \n",
       "4  ../data/models/5754269668442876343_hidden_neur...   \n",
       "5  ../data/models/-8564343657574404315_hidden_neu...   \n",
       "\n",
       "                                        model_status model_epochs  \\\n",
       "0  ../data/models/3786470895109500580_model_statu...         1000   \n",
       "1  ../data/models/-5662987709573759986_model_stat...         1000   \n",
       "2  ../data/models/3837049506038808913_model_statu...          100   \n",
       "3  ../data/models/4644399470053765538_model_statu...           20   \n",
       "4  ../data/models/5754269668442876343_model_statu...           10   \n",
       "5  ../data/models/-8564343657574404315_model_stat...          100   \n",
       "\n",
       "  model_patience model_learning_rate model_optimizer model_batch_size  \n",
       "0            100               0.001            adam              NaN  \n",
       "1            100               0.001            adam              NaN  \n",
       "2             10               0.001            adam              NaN  \n",
       "3             10               0.001            adam              NaN  \n",
       "4              5               0.001            adam            100.0  \n",
       "5              5               0.001            adam            100.0  \n",
       "\n",
       "[6 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_config = pd.read_csv('../data/config.csv')\n",
    "train_id = 5\n",
    "df_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70f58e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(df_config['train_data_path'][train_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24cd7f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.903746</td>\n",
       "      <td>3.184031</td>\n",
       "      <td>0.052501</td>\n",
       "      <td>-9.532997</td>\n",
       "      <td>1.425378</td>\n",
       "      <td>10.894728</td>\n",
       "      <td>0.170885</td>\n",
       "      <td>-0.774334</td>\n",
       "      <td>-10.986876</td>\n",
       "      <td>11.461837</td>\n",
       "      <td>...</td>\n",
       "      <td>10.039516</td>\n",
       "      <td>-7.124313</td>\n",
       "      <td>7.238684</td>\n",
       "      <td>1.278997</td>\n",
       "      <td>11.078094</td>\n",
       "      <td>-10.535044</td>\n",
       "      <td>-0.140006</td>\n",
       "      <td>-8.772590</td>\n",
       "      <td>1.981356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.981823</td>\n",
       "      <td>-20.750982</td>\n",
       "      <td>-0.942298</td>\n",
       "      <td>8.656325</td>\n",
       "      <td>0.158986</td>\n",
       "      <td>-10.275792</td>\n",
       "      <td>-0.552505</td>\n",
       "      <td>-0.059739</td>\n",
       "      <td>-11.232473</td>\n",
       "      <td>9.416682</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.691469</td>\n",
       "      <td>18.482490</td>\n",
       "      <td>-11.253873</td>\n",
       "      <td>0.430396</td>\n",
       "      <td>9.836899</td>\n",
       "      <td>10.421699</td>\n",
       "      <td>1.471094</td>\n",
       "      <td>-10.779757</td>\n",
       "      <td>-0.711336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.547097</td>\n",
       "      <td>2.984926</td>\n",
       "      <td>0.968209</td>\n",
       "      <td>-10.001620</td>\n",
       "      <td>-0.022503</td>\n",
       "      <td>9.344954</td>\n",
       "      <td>-0.471234</td>\n",
       "      <td>-0.959938</td>\n",
       "      <td>-10.124597</td>\n",
       "      <td>9.963728</td>\n",
       "      <td>...</td>\n",
       "      <td>10.926023</td>\n",
       "      <td>-3.391440</td>\n",
       "      <td>10.230726</td>\n",
       "      <td>1.108343</td>\n",
       "      <td>15.102184</td>\n",
       "      <td>-8.711126</td>\n",
       "      <td>-2.805098</td>\n",
       "      <td>-11.888262</td>\n",
       "      <td>0.759911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.357513</td>\n",
       "      <td>20.604116</td>\n",
       "      <td>-0.611071</td>\n",
       "      <td>9.573068</td>\n",
       "      <td>2.036371</td>\n",
       "      <td>9.170248</td>\n",
       "      <td>0.270779</td>\n",
       "      <td>-0.285000</td>\n",
       "      <td>9.534010</td>\n",
       "      <td>9.546351</td>\n",
       "      <td>...</td>\n",
       "      <td>6.925222</td>\n",
       "      <td>-14.570370</td>\n",
       "      <td>-12.142899</td>\n",
       "      <td>-1.077644</td>\n",
       "      <td>10.180091</td>\n",
       "      <td>-10.983669</td>\n",
       "      <td>0.476673</td>\n",
       "      <td>12.383629</td>\n",
       "      <td>-1.151954</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.301140</td>\n",
       "      <td>21.471281</td>\n",
       "      <td>-0.948023</td>\n",
       "      <td>7.494141</td>\n",
       "      <td>-2.700322</td>\n",
       "      <td>10.126694</td>\n",
       "      <td>-0.853863</td>\n",
       "      <td>-1.600656</td>\n",
       "      <td>10.207078</td>\n",
       "      <td>8.708084</td>\n",
       "      <td>...</td>\n",
       "      <td>8.477780</td>\n",
       "      <td>-11.371481</td>\n",
       "      <td>-9.151545</td>\n",
       "      <td>0.073678</td>\n",
       "      <td>12.375645</td>\n",
       "      <td>-9.216089</td>\n",
       "      <td>-1.500698</td>\n",
       "      <td>10.151696</td>\n",
       "      <td>-0.249882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   8.903746   3.184031   0.052501  -9.532997   1.425378  10.894728   \n",
       "1   9.981823 -20.750982  -0.942298   8.656325   0.158986 -10.275792   \n",
       "2   9.547097   2.984926   0.968209 -10.001620  -0.022503   9.344954   \n",
       "3   8.357513  20.604116  -0.611071   9.573068   2.036371   9.170248   \n",
       "4  11.301140  21.471281  -0.948023   7.494141  -2.700322  10.126694   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_11  feature_12  \\\n",
       "0   0.170885  -0.774334 -10.986876  11.461837  ...   10.039516   -7.124313   \n",
       "1  -0.552505  -0.059739 -11.232473   9.416682  ...   -9.691469   18.482490   \n",
       "2  -0.471234  -0.959938 -10.124597   9.963728  ...   10.926023   -3.391440   \n",
       "3   0.270779  -0.285000   9.534010   9.546351  ...    6.925222  -14.570370   \n",
       "4  -0.853863  -1.600656  10.207078   8.708084  ...    8.477780  -11.371481   \n",
       "\n",
       "   feature_13  feature_14  feature_15  feature_16  feature_17  feature_18  \\\n",
       "0    7.238684    1.278997   11.078094  -10.535044   -0.140006   -8.772590   \n",
       "1  -11.253873    0.430396    9.836899   10.421699    1.471094  -10.779757   \n",
       "2   10.230726    1.108343   15.102184   -8.711126   -2.805098  -11.888262   \n",
       "3  -12.142899   -1.077644   10.180091  -10.983669    0.476673   12.383629   \n",
       "4   -9.151545    0.073678   12.375645   -9.216089   -1.500698   10.151696   \n",
       "\n",
       "   feature_19  target  \n",
       "0    1.981356       1  \n",
       "1   -0.711336       0  \n",
       "2    0.759911       1  \n",
       "3   -1.151954       1  \n",
       "4   -0.249882       1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a57ede",
   "metadata": {},
   "source": [
    "## Fit a preprocessing pipeline for each kFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d514943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "index_path = df_config['cv_path'][train_id]\n",
    "pipe_path = df_config['pipeline_path'][train_id]\n",
    "n_folds =  df_config['cv_folds'][train_id]\n",
    "\n",
    "data = df_train.drop(columns=['target'])\n",
    "\n",
    "for ifold in range(n_folds):\n",
    "    index_file = '%s_CV_fold_%i_of_%i_cv_indexes.pkl'%(df_config['hash_id'][train_id],\n",
    "                                                       ifold, n_folds)\n",
    "    with open(os.path.join(index_path,index_file),'rb') as file_handler:\n",
    "            [trn_idx,val_idx] = pickle.load(file_handler)\n",
    "    \n",
    "    # criando o pipeline\n",
    "    scaler = None\n",
    "    if df_config['scaler_alg'][train_id] == \"StandardScaler\":\n",
    "        scaler = StandardScaler()\n",
    "    elif df_config['scaler_alg'][train_id] == \"MinMaxScaler\":\n",
    "        scaler = MinMaxScaler()\n",
    "    \n",
    "    pipe = Pipeline(steps=[(\"scaler\", scaler)])\n",
    "    pipe.fit(data.loc[trn_idx,:])\n",
    "    \n",
    "    pipe_name = '%s_CV_fold_%i_of_%i_cv_pipe.pkl'%(df_config['hash_id'][train_id],\n",
    "                                                   ifold, n_folds)\n",
    "    with open(os.path.join(pipe_path,pipe_name),'wb') as file_handler:\n",
    "        joblib.dump(pipe, file_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f34dd3",
   "metadata": {},
   "source": [
    "# Define Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fcf51de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel:\n",
    "    def __init__(self, n_hidden_neurons=2, verbose=2):\n",
    "        self.n_hidden_neurons = n_hidden_neurons\n",
    "        self.model = None\n",
    "        self.trn_history = None\n",
    "        self.trained = False\n",
    "        self.verbose = verbose\n",
    "    def __str__(self):\n",
    "        m_str = 'Class MLPModel\\n'\n",
    "        if self.trained:\n",
    "            m_str += 'Model is fitted, '\n",
    "        else:\n",
    "            m_str += 'Model is not fitted, '\n",
    "        m_str += 'instance created with %i hidden neurons'%(self.n_hidden_neurons) \n",
    "        return m_str\n",
    "    def model_loss(self, loss_alg='cat_crossent'):\n",
    "        if loss_alg == 'cat_crossent':\n",
    "            loss = keras.losses.CategoricalCrossentropy(from_logits=True,\n",
    "                                                        label_smoothing=0.0,\n",
    "                                                        axis=-1,\n",
    "                                                        reduction=\"auto\",\n",
    "                                                        name=loss_alg,)\n",
    "        elif loss_alg== 'mse':\n",
    "            loss = keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def model_optimizer(self, optimizer='adam', learning_rate = 0.001):\n",
    "        if optimizer == 'adam':\n",
    "            opt = keras.optimizers.Adam(learning_rate=learning_rate,\n",
    "                                        beta_1=0.9,beta_2=0.999,\n",
    "                                        epsilon=1e-07,amsgrad=False,\n",
    "                                        name=\"Adam\",)\n",
    "        return opt\n",
    "    \n",
    "    def create_model(self, data, target, random_state=0, learning_rate=0.01):\n",
    "        #tf.random.set_seed(random_state)\n",
    "\n",
    "        model = tf.keras.Sequential()\n",
    "        \n",
    "        # add a input to isolate the input of NN model\n",
    "        model.add(tf.keras.Input(shape=(data.shape[1],)))\n",
    "        # add a non-linear single neuron layer\n",
    "        hidden_layer = layers.Dense(units=self.n_hidden_neurons,\n",
    "                                    activation='tanh',\n",
    "                                    kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "                                    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "                                    bias_regularizer=regularizers.L2(1e-4),\n",
    "                                    bias_initializer=initializers.Zeros()\n",
    "                                   )\n",
    "        model.add(hidden_layer)\n",
    "        # add a non-linear output layer with max sparse target shape\n",
    "        output_layer = layers.Dense(units=target.shape[1],\n",
    "                                    activation='tanh',\n",
    "                                    kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "                                    bias_initializer=initializers.Zeros()\n",
    "                                   )\n",
    "        model.add(output_layer)\n",
    "        # creating a optimization function using steepest gradient\n",
    "        lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
    "                                                                  decay_steps=100,\n",
    "                                                                  decay_rate=0.9)\n",
    "        \n",
    "        # model optimizer\n",
    "        optimizer = self.model_optimizer(optimizer='adam', learning_rate = 0.001)\n",
    "        # model loss\n",
    "        loss = self.model_loss(loss_alg='cat_crossent')\n",
    "       \n",
    "        cat_acc_metric = keras.metrics.CategoricalAccuracy(name=\"cat_acc\", dtype=None)\n",
    "        acc_metric = keras.metrics.Accuracy(name=\"accuracy\",dtype=None)\n",
    "        mse_metric = keras.metrics.MeanSquaredError(name=\"mse\", dtype=None)\n",
    "        rmse_metric = keras.metrics.RootMeanSquaredError(name=\"rmse\", dtype=None)\n",
    "\n",
    "        model.compile(loss=loss, \n",
    "                      optimizer=optimizer,\n",
    "                      metrics=[cat_acc_metric,\n",
    "                               acc_metric,\n",
    "                               mse_metric,\n",
    "                               rmse_metric])\n",
    "        return model\n",
    "    def fit(self, X, Y,\n",
    "            trn_id=None, \n",
    "            val_id=None, \n",
    "            epochs=50,\n",
    "            batch_size=4,\n",
    "            patience = 100,\n",
    "            learning_rate=0.01, random_state=0):\n",
    "        \n",
    "        X_copy = X.copy()\n",
    "        Y_copy = Y.copy()\n",
    "        \n",
    "        model = self.create_model(X_copy,Y_copy, random_state=random_state, learning_rate=learning_rate)\n",
    "        \n",
    "        # early stopping to avoid overtraining\n",
    "        earlyStopping = callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                patience=patience,verbose=self.verbose, \n",
    "                                                mode='auto')\n",
    "    \n",
    "        trn_desc = model.fit(X_copy[trn_id,:], Y_copy[trn_id],\n",
    "                             epochs=epochs,\n",
    "                             batch_size=batch_size,\n",
    "                             callbacks=[earlyStopping], \n",
    "                             verbose=self.verbose,\n",
    "                             validation_data=(X_copy[val_id,:],\n",
    "                                              Y_copy[val_id]),\n",
    "                            )\n",
    "        self.model = model\n",
    "        self.trn_history = trn_desc\n",
    "        self.trained = True\n",
    "    def predict(self, data):\n",
    "        return self.model.predict(data)\n",
    "    def save(self, file_path):\n",
    "        with open(file_path,'wb') as file_handler:\n",
    "            joblib.dump([self.n_hidden_neurons, self.model,\n",
    "                        self.trn_history, self.trained], file_handler)\n",
    "    def load(self, file_path):\n",
    "        with open(file_path,'rb') as file_handler:\n",
    "            [self.n_hidden_neurons, self.model, self.trn_history, self.trained]= joblib.load(file_handler)\n",
    "    def model_with_no_output_layer(self):\n",
    "        buffer_model = tf.keras.Sequential()    \n",
    "        # add a input to isolate the input of NN model\n",
    "        buffer_model.add(tf.keras.Input(shape=(model.model.layers[0].get_weights()[0].shape[0],)))\n",
    "        # add a non-linear single neuron layer\n",
    "        hidden_layer = layers.Dense(units=model.model.layers[0].get_weights()[1].shape[0],\n",
    "                                    activation='tanh')\n",
    "        buffer_model.add(hidden_layer)    \n",
    "        output_layer = layers.Dense(units=1,activation='tanh')\n",
    "    \n",
    "        for idx, layer in enumerate(buffer_model.layers):\n",
    "            layer.set_weights(model.model.layers[idx].get_weights())\n",
    "        return buffer_model\n",
    "    def predict_one_layer_before_output(self, data):\n",
    "        buffer_model = self.model_with_no_output_layer()\n",
    "        return buffer_model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029814be",
   "metadata": {},
   "source": [
    "# kFold training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2edf93b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_description(df_config, train_id):\n",
    "    str_out = '\\n\\n\\n'\n",
    "    str_out +=  '=======================================\\n'\n",
    "    str_out +=  '%s Training Process'%(df_config['label'][train_id])\n",
    "    str_out += '\\n'\n",
    "    str_out +=  '=======================================\\n'\n",
    "    \n",
    "    str_out += 'Processing %s'%(df_config['train_data_path'][train_id])+'\\n'\n",
    "    str_out += 'Hidden Neurons:'\n",
    "    hidden_neurons = ' '\n",
    "    for ihidden_neuron in list(get_list_of_hidden_neurons(df_config['model_neurons'][train_id])):\n",
    "        hidden_neurons += str(ihidden_neuron)+', '\n",
    "    str_out += hidden_neurons[:-2]\n",
    "    str_out += '\\n'\n",
    "    str_out += 'CV Folds: %s\\n'%(df_config['cv_folds'][train_id])\n",
    "    str_out += 'Inits: %s\\n'%(df_config['model_inits'][train_id])\n",
    "    return str_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2c4e326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "=======================================\n",
      "Toy Data Classification Training Process\n",
      "=======================================\n",
      "Processing ../data/-8564343657574404315_train_data.csv\n",
      "Hidden Neurons: 1, 10, 100\n",
      "CV Folds: 5\n",
      "Inits: 2\n",
      "\n",
      "Training Starting\n",
      "Data shape: (100000, 20)\n",
      "Trgt shape: 100000\n",
      "Training 1 fold of 5 folds\n",
      "Training for 1 neuron in [1, 10, 100]\n",
      "Training for 1 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 1.1182 - cat_acc: 0.4882 - accuracy: 0.0000e+00 - mse: 0.2464 - rmse: 0.4964 - val_loss: 0.9462 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.3455 - val_rmse: 0.5878 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 2s - loss: 0.9038 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.4442 - rmse: 0.6665 - val_loss: 0.8783 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.5228 - val_rmse: 0.7231 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.8653 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.5716 - rmse: 0.7560 - val_loss: 0.8569 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.6118 - val_rmse: 0.7822 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.8504 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.6382 - rmse: 0.7989 - val_loss: 0.8467 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.6608 - val_rmse: 0.8129 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.8413 - cat_acc: 0.4972 - accuracy: 0.0000e+00 - mse: 0.6671 - rmse: 0.8167 - val_loss: 0.8302 - val_cat_acc: 0.4967 - val_accuracy: 0.0000e+00 - val_mse: 0.6379 - val_rmse: 0.7987 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.8051 - cat_acc: 0.4962 - accuracy: 0.0000e+00 - mse: 0.6193 - rmse: 0.7869 - val_loss: 0.7844 - val_cat_acc: 0.4965 - val_accuracy: 0.0000e+00 - val_mse: 0.6158 - val_rmse: 0.7847 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.7699 - cat_acc: 0.4963 - accuracy: 0.0000e+00 - mse: 0.6216 - rmse: 0.7884 - val_loss: 0.7557 - val_cat_acc: 0.4960 - val_accuracy: 0.0000e+00 - val_mse: 0.6218 - val_rmse: 0.7885 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.7383 - cat_acc: 0.4939 - accuracy: 0.0000e+00 - mse: 0.6186 - rmse: 0.7865 - val_loss: 0.7215 - val_cat_acc: 0.4930 - val_accuracy: 0.0000e+00 - val_mse: 0.6196 - val_rmse: 0.7872 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.7075 - cat_acc: 0.4927 - accuracy: 0.0000e+00 - mse: 0.6255 - rmse: 0.7909 - val_loss: 0.6960 - val_cat_acc: 0.4936 - val_accuracy: 0.0000e+00 - val_mse: 0.6335 - val_rmse: 0.7959 - 1s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.6865 - cat_acc: 0.4927 - accuracy: 0.0000e+00 - mse: 0.6403 - rmse: 0.8002 - val_loss: 0.6788 - val_cat_acc: 0.4938 - val_accuracy: 0.0000e+00 - val_mse: 0.6475 - val_rmse: 0.8047 - 1s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.6717 - cat_acc: 0.4930 - accuracy: 0.0000e+00 - mse: 0.6541 - rmse: 0.8088 - val_loss: 0.6663 - val_cat_acc: 0.4941 - val_accuracy: 0.0000e+00 - val_mse: 0.6612 - val_rmse: 0.8131 - 1s/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.6607 - cat_acc: 0.4930 - accuracy: 3.1250e-06 - mse: 0.6664 - rmse: 0.8163 - val_loss: 0.6567 - val_cat_acc: 0.4935 - val_accuracy: 0.0000e+00 - val_mse: 0.6721 - val_rmse: 0.8198 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.6520 - cat_acc: 0.4932 - accuracy: 0.0000e+00 - mse: 0.6766 - rmse: 0.8226 - val_loss: 0.6489 - val_cat_acc: 0.4939 - val_accuracy: 0.0000e+00 - val_mse: 0.6819 - val_rmse: 0.8258 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.6450 - cat_acc: 0.4935 - accuracy: 0.0000e+00 - mse: 0.6855 - rmse: 0.8279 - val_loss: 0.6427 - val_cat_acc: 0.4940 - val_accuracy: 0.0000e+00 - val_mse: 0.6901 - val_rmse: 0.8307 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.6393 - cat_acc: 0.4935 - accuracy: 0.0000e+00 - mse: 0.6932 - rmse: 0.8326 - val_loss: 0.6374 - val_cat_acc: 0.4947 - val_accuracy: 0.0000e+00 - val_mse: 0.6959 - val_rmse: 0.8342 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.6347 - cat_acc: 0.4939 - accuracy: 0.0000e+00 - mse: 0.6994 - rmse: 0.8363 - val_loss: 0.6333 - val_cat_acc: 0.4941 - val_accuracy: 0.0000e+00 - val_mse: 0.7030 - val_rmse: 0.8384 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.6309 - cat_acc: 0.4938 - accuracy: 0.0000e+00 - mse: 0.7050 - rmse: 0.8396 - val_loss: 0.6297 - val_cat_acc: 0.4943 - val_accuracy: 0.0000e+00 - val_mse: 0.7074 - val_rmse: 0.8410 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.6278 - cat_acc: 0.4936 - accuracy: 0.0000e+00 - mse: 0.7096 - rmse: 0.8424 - val_loss: 0.6267 - val_cat_acc: 0.4947 - val_accuracy: 0.0000e+00 - val_mse: 0.7123 - val_rmse: 0.8440 - 1s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.6251 - cat_acc: 0.4938 - accuracy: 2.1875e-05 - mse: 0.7136 - rmse: 0.8448 - val_loss: 0.6242 - val_cat_acc: 0.4944 - val_accuracy: 3.7500e-05 - val_mse: 0.7155 - val_rmse: 0.8458 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 2s - loss: 0.6228 - cat_acc: 0.4940 - accuracy: 8.7500e-05 - mse: 0.7171 - rmse: 0.8468 - val_loss: 0.6223 - val_cat_acc: 0.4946 - val_accuracy: 1.5000e-04 - val_mse: 0.7192 - val_rmse: 0.8480 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.6209 - cat_acc: 0.4940 - accuracy: 1.5625e-04 - mse: 0.7199 - rmse: 0.8485 - val_loss: 0.6207 - val_cat_acc: 0.4951 - val_accuracy: 2.5000e-04 - val_mse: 0.7211 - val_rmse: 0.8492 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.6194 - cat_acc: 0.4940 - accuracy: 2.0625e-04 - mse: 0.7224 - rmse: 0.8500 - val_loss: 0.6195 - val_cat_acc: 0.4947 - val_accuracy: 3.0000e-04 - val_mse: 0.7243 - val_rmse: 0.8510 - 1s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 2s - loss: 0.6179 - cat_acc: 0.4941 - accuracy: 2.4375e-04 - mse: 0.7247 - rmse: 0.8513 - val_loss: 0.6181 - val_cat_acc: 0.4944 - val_accuracy: 3.1250e-04 - val_mse: 0.7259 - val_rmse: 0.8520 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 2s - loss: 0.6168 - cat_acc: 0.4941 - accuracy: 2.7500e-04 - mse: 0.7267 - rmse: 0.8525 - val_loss: 0.6167 - val_cat_acc: 0.4947 - val_accuracy: 3.6250e-04 - val_mse: 0.7277 - val_rmse: 0.8531 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 2s - loss: 0.6157 - cat_acc: 0.4942 - accuracy: 3.7812e-04 - mse: 0.7284 - rmse: 0.8535 - val_loss: 0.6156 - val_cat_acc: 0.4953 - val_accuracy: 5.0000e-04 - val_mse: 0.7286 - val_rmse: 0.8536 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.6148 - cat_acc: 0.4945 - accuracy: 5.3125e-04 - mse: 0.7297 - rmse: 0.8543 - val_loss: 0.6150 - val_cat_acc: 0.4951 - val_accuracy: 6.8750e-04 - val_mse: 0.7307 - val_rmse: 0.8548 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.6140 - cat_acc: 0.4943 - accuracy: 7.5937e-04 - mse: 0.7312 - rmse: 0.8551 - val_loss: 0.6140 - val_cat_acc: 0.4946 - val_accuracy: 9.0000e-04 - val_mse: 0.7321 - val_rmse: 0.8556 - 1s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.6134 - cat_acc: 0.4943 - accuracy: 0.0011 - mse: 0.7323 - rmse: 0.8557 - val_loss: 0.6144 - val_cat_acc: 0.4947 - val_accuracy: 0.0015 - val_mse: 0.7333 - val_rmse: 0.8563 - 1s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.6127 - cat_acc: 0.4944 - accuracy: 0.0015 - mse: 0.7334 - rmse: 0.8564 - val_loss: 0.6129 - val_cat_acc: 0.4945 - val_accuracy: 0.0018 - val_mse: 0.7343 - val_rmse: 0.8569 - 1s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.6122 - cat_acc: 0.4945 - accuracy: 0.0022 - mse: 0.7343 - rmse: 0.8569 - val_loss: 0.6127 - val_cat_acc: 0.4946 - val_accuracy: 0.0024 - val_mse: 0.7351 - val_rmse: 0.8574 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.6116 - cat_acc: 0.4943 - accuracy: 0.0028 - mse: 0.7352 - rmse: 0.8574 - val_loss: 0.6118 - val_cat_acc: 0.4951 - val_accuracy: 0.0034 - val_mse: 0.7357 - val_rmse: 0.8577 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.6112 - cat_acc: 0.4943 - accuracy: 0.0036 - mse: 0.7360 - rmse: 0.8579 - val_loss: 0.6113 - val_cat_acc: 0.4946 - val_accuracy: 0.0036 - val_mse: 0.7373 - val_rmse: 0.8587 - 1s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.6109 - cat_acc: 0.4944 - accuracy: 0.0046 - mse: 0.7367 - rmse: 0.8583 - val_loss: 0.6110 - val_cat_acc: 0.4954 - val_accuracy: 0.0056 - val_mse: 0.7360 - val_rmse: 0.8579 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.6104 - cat_acc: 0.4945 - accuracy: 0.0057 - mse: 0.7372 - rmse: 0.8586 - val_loss: 0.6108 - val_cat_acc: 0.4951 - val_accuracy: 0.0066 - val_mse: 0.7375 - val_rmse: 0.8588 - 1s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.6100 - cat_acc: 0.4946 - accuracy: 0.0068 - mse: 0.7377 - rmse: 0.8589 - val_loss: 0.6120 - val_cat_acc: 0.4946 - val_accuracy: 0.0085 - val_mse: 0.7373 - val_rmse: 0.8587 - 1s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.6098 - cat_acc: 0.4945 - accuracy: 0.0080 - mse: 0.7384 - rmse: 0.8593 - val_loss: 0.6099 - val_cat_acc: 0.4951 - val_accuracy: 0.0082 - val_mse: 0.7393 - val_rmse: 0.8598 - 1s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.6095 - cat_acc: 0.4947 - accuracy: 0.0092 - mse: 0.7388 - rmse: 0.8595 - val_loss: 0.6099 - val_cat_acc: 0.4951 - val_accuracy: 0.0101 - val_mse: 0.7393 - val_rmse: 0.8598 - 1s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.6092 - cat_acc: 0.4946 - accuracy: 0.0106 - mse: 0.7392 - rmse: 0.8598 - val_loss: 0.6096 - val_cat_acc: 0.4954 - val_accuracy: 0.0124 - val_mse: 0.7392 - val_rmse: 0.8598 - 1s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.6089 - cat_acc: 0.4947 - accuracy: 0.0120 - mse: 0.7396 - rmse: 0.8600 - val_loss: 0.6091 - val_cat_acc: 0.4952 - val_accuracy: 0.0125 - val_mse: 0.7406 - val_rmse: 0.8606 - 1s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.6087 - cat_acc: 0.4946 - accuracy: 0.0134 - mse: 0.7402 - rmse: 0.8604 - val_loss: 0.6092 - val_cat_acc: 0.4945 - val_accuracy: 0.0134 - val_mse: 0.7411 - val_rmse: 0.8609 - 1s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.6085 - cat_acc: 0.4945 - accuracy: 0.0149 - mse: 0.7406 - rmse: 0.8606 - val_loss: 0.6088 - val_cat_acc: 0.4956 - val_accuracy: 0.0166 - val_mse: 0.7410 - val_rmse: 0.8608 - 1s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.6083 - cat_acc: 0.4947 - accuracy: 0.0163 - mse: 0.7409 - rmse: 0.8608 - val_loss: 0.6085 - val_cat_acc: 0.4952 - val_accuracy: 0.0173 - val_mse: 0.7412 - val_rmse: 0.8609 - 1s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.6083 - cat_acc: 0.4947 - accuracy: 0.0180 - mse: 0.7410 - rmse: 0.8608 - val_loss: 0.6085 - val_cat_acc: 0.4951 - val_accuracy: 0.0186 - val_mse: 0.7418 - val_rmse: 0.8613 - 1s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.6079 - cat_acc: 0.4947 - accuracy: 0.0193 - mse: 0.7416 - rmse: 0.8611 - val_loss: 0.6083 - val_cat_acc: 0.4951 - val_accuracy: 0.0202 - val_mse: 0.7419 - val_rmse: 0.8613 - 1s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.6077 - cat_acc: 0.4946 - accuracy: 0.0210 - mse: 0.7417 - rmse: 0.8612 - val_loss: 0.6082 - val_cat_acc: 0.4953 - val_accuracy: 0.0214 - val_mse: 0.7420 - val_rmse: 0.8614 - 1s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.6076 - cat_acc: 0.4947 - accuracy: 0.0225 - mse: 0.7419 - rmse: 0.8614 - val_loss: 0.6082 - val_cat_acc: 0.4950 - val_accuracy: 0.0231 - val_mse: 0.7423 - val_rmse: 0.8616 - 1s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.6075 - cat_acc: 0.4948 - accuracy: 0.0238 - mse: 0.7423 - rmse: 0.8615 - val_loss: 0.6082 - val_cat_acc: 0.4954 - val_accuracy: 0.0248 - val_mse: 0.7424 - val_rmse: 0.8616 - 1s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.6073 - cat_acc: 0.4947 - accuracy: 0.0251 - mse: 0.7427 - rmse: 0.8618 - val_loss: 0.6080 - val_cat_acc: 0.4957 - val_accuracy: 0.0283 - val_mse: 0.7417 - val_rmse: 0.8612 - 1s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.6072 - cat_acc: 0.4947 - accuracy: 0.0268 - mse: 0.7428 - rmse: 0.8619 - val_loss: 0.6075 - val_cat_acc: 0.4956 - val_accuracy: 0.0290 - val_mse: 0.7426 - val_rmse: 0.8617 - 1s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 2s - loss: 0.6070 - cat_acc: 0.4947 - accuracy: 0.0285 - mse: 0.7429 - rmse: 0.8619 - val_loss: 0.6074 - val_cat_acc: 0.4952 - val_accuracy: 0.0287 - val_mse: 0.7433 - val_rmse: 0.8622 - 2s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.6069 - cat_acc: 0.4947 - accuracy: 0.0297 - mse: 0.7433 - rmse: 0.8621 - val_loss: 0.6072 - val_cat_acc: 0.4952 - val_accuracy: 0.0308 - val_mse: 0.7436 - val_rmse: 0.8623 - 1s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.6069 - cat_acc: 0.4947 - accuracy: 0.0315 - mse: 0.7434 - rmse: 0.8622 - val_loss: 0.6074 - val_cat_acc: 0.4957 - val_accuracy: 0.0340 - val_mse: 0.7434 - val_rmse: 0.8622 - 1s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.6067 - cat_acc: 0.4949 - accuracy: 0.0330 - mse: 0.7436 - rmse: 0.8623 - val_loss: 0.6070 - val_cat_acc: 0.4952 - val_accuracy: 0.0318 - val_mse: 0.7446 - val_rmse: 0.8629 - 1s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.6067 - cat_acc: 0.4947 - accuracy: 0.0341 - mse: 0.7439 - rmse: 0.8625 - val_loss: 0.6070 - val_cat_acc: 0.4953 - val_accuracy: 0.0346 - val_mse: 0.7441 - val_rmse: 0.8626 - 1s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.6066 - cat_acc: 0.4947 - accuracy: 0.0356 - mse: 0.7440 - rmse: 0.8626 - val_loss: 0.6067 - val_cat_acc: 0.4955 - val_accuracy: 0.0349 - val_mse: 0.7450 - val_rmse: 0.8631 - 1s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.6064 - cat_acc: 0.4948 - accuracy: 0.0369 - mse: 0.7443 - rmse: 0.8627 - val_loss: 0.6075 - val_cat_acc: 0.4949 - val_accuracy: 0.0378 - val_mse: 0.7436 - val_rmse: 0.8623 - 1s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.6063 - cat_acc: 0.4949 - accuracy: 0.0384 - mse: 0.7443 - rmse: 0.8627 - val_loss: 0.6071 - val_cat_acc: 0.4951 - val_accuracy: 0.0379 - val_mse: 0.7441 - val_rmse: 0.8626 - 1s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.6062 - cat_acc: 0.4948 - accuracy: 0.0397 - mse: 0.7444 - rmse: 0.8628 - val_loss: 0.6068 - val_cat_acc: 0.4951 - val_accuracy: 0.0374 - val_mse: 0.7456 - val_rmse: 0.8635 - 1s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.6062 - cat_acc: 0.4948 - accuracy: 0.0409 - mse: 0.7447 - rmse: 0.8629 - val_loss: 0.6066 - val_cat_acc: 0.4954 - val_accuracy: 0.0419 - val_mse: 0.7449 - val_rmse: 0.8631 - 1s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.6061 - cat_acc: 0.4948 - accuracy: 0.0419 - mse: 0.7448 - rmse: 0.8630 - val_loss: 0.6063 - val_cat_acc: 0.4957 - val_accuracy: 0.0436 - val_mse: 0.7448 - val_rmse: 0.8630 - 1s/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.6059 - cat_acc: 0.4949 - accuracy: 0.0432 - mse: 0.7449 - rmse: 0.8631 - val_loss: 0.6070 - val_cat_acc: 0.4948 - val_accuracy: 0.0404 - val_mse: 0.7462 - val_rmse: 0.8638 - 1s/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 2s - loss: 0.6060 - cat_acc: 0.4948 - accuracy: 0.0443 - mse: 0.7450 - rmse: 0.8632 - val_loss: 0.6062 - val_cat_acc: 0.4956 - val_accuracy: 0.0443 - val_mse: 0.7456 - val_rmse: 0.8635 - 2s/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 1s - loss: 0.6058 - cat_acc: 0.4949 - accuracy: 0.0453 - mse: 0.7452 - rmse: 0.8632 - val_loss: 0.6064 - val_cat_acc: 0.4956 - val_accuracy: 0.0459 - val_mse: 0.7451 - val_rmse: 0.8632 - 1s/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 1s - loss: 0.6058 - cat_acc: 0.4948 - accuracy: 0.0465 - mse: 0.7453 - rmse: 0.8633 - val_loss: 0.6061 - val_cat_acc: 0.4956 - val_accuracy: 0.0466 - val_mse: 0.7459 - val_rmse: 0.8637 - 1s/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 2s - loss: 0.6057 - cat_acc: 0.4948 - accuracy: 0.0477 - mse: 0.7454 - rmse: 0.8633 - val_loss: 0.6060 - val_cat_acc: 0.4955 - val_accuracy: 0.0472 - val_mse: 0.7460 - val_rmse: 0.8637 - 2s/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "800/800 - 1s - loss: 0.6057 - cat_acc: 0.4947 - accuracy: 0.0487 - mse: 0.7455 - rmse: 0.8634 - val_loss: 0.6072 - val_cat_acc: 0.4953 - val_accuracy: 0.0501 - val_mse: 0.7452 - val_rmse: 0.8632 - 1s/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "800/800 - 1s - loss: 0.6055 - cat_acc: 0.4949 - accuracy: 0.0497 - mse: 0.7455 - rmse: 0.8634 - val_loss: 0.6067 - val_cat_acc: 0.4951 - val_accuracy: 0.0481 - val_mse: 0.7468 - val_rmse: 0.8642 - 1s/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "800/800 - 1s - loss: 0.6056 - cat_acc: 0.4947 - accuracy: 0.0504 - mse: 0.7460 - rmse: 0.8637 - val_loss: 0.6067 - val_cat_acc: 0.4954 - val_accuracy: 0.0517 - val_mse: 0.7459 - val_rmse: 0.8637 - 1s/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "800/800 - 1s - loss: 0.6055 - cat_acc: 0.4949 - accuracy: 0.0518 - mse: 0.7457 - rmse: 0.8636 - val_loss: 0.6060 - val_cat_acc: 0.4954 - val_accuracy: 0.0492 - val_mse: 0.7476 - val_rmse: 0.8646 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "800/800 - 1s - loss: 0.6055 - cat_acc: 0.4949 - accuracy: 0.0525 - mse: 0.7460 - rmse: 0.8637 - val_loss: 0.6058 - val_cat_acc: 0.4954 - val_accuracy: 0.0529 - val_mse: 0.7464 - val_rmse: 0.8640 - 1s/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "800/800 - 1s - loss: 0.6054 - cat_acc: 0.4949 - accuracy: 0.0532 - mse: 0.7461 - rmse: 0.8638 - val_loss: 0.6057 - val_cat_acc: 0.4951 - val_accuracy: 0.0542 - val_mse: 0.7461 - val_rmse: 0.8638 - 1s/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "800/800 - 2s - loss: 0.6053 - cat_acc: 0.4949 - accuracy: 0.0539 - mse: 0.7462 - rmse: 0.8639 - val_loss: 0.6058 - val_cat_acc: 0.4958 - val_accuracy: 0.0565 - val_mse: 0.7467 - val_rmse: 0.8641 - 2s/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "800/800 - 1s - loss: 0.6053 - cat_acc: 0.4949 - accuracy: 0.0554 - mse: 0.7463 - rmse: 0.8639 - val_loss: 0.6055 - val_cat_acc: 0.4953 - val_accuracy: 0.0518 - val_mse: 0.7476 - val_rmse: 0.8646 - 1s/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "800/800 - 1s - loss: 0.6051 - cat_acc: 0.4948 - accuracy: 0.0562 - mse: 0.7463 - rmse: 0.8639 - val_loss: 0.6054 - val_cat_acc: 0.4952 - val_accuracy: 0.0552 - val_mse: 0.7470 - val_rmse: 0.8643 - 1s/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "800/800 - 1s - loss: 0.6051 - cat_acc: 0.4948 - accuracy: 0.0568 - mse: 0.7466 - rmse: 0.8640 - val_loss: 0.6058 - val_cat_acc: 0.4955 - val_accuracy: 0.0573 - val_mse: 0.7462 - val_rmse: 0.8638 - 1s/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "800/800 - 1s - loss: 0.6051 - cat_acc: 0.4948 - accuracy: 0.0575 - mse: 0.7466 - rmse: 0.8641 - val_loss: 0.6057 - val_cat_acc: 0.4957 - val_accuracy: 0.0600 - val_mse: 0.7465 - val_rmse: 0.8640 - 1s/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "800/800 - 1s - loss: 0.6050 - cat_acc: 0.4949 - accuracy: 0.0584 - mse: 0.7467 - rmse: 0.8641 - val_loss: 0.6053 - val_cat_acc: 0.4955 - val_accuracy: 0.0604 - val_mse: 0.7467 - val_rmse: 0.8641 - 1s/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "800/800 - 1s - loss: 0.6050 - cat_acc: 0.4949 - accuracy: 0.0598 - mse: 0.7467 - rmse: 0.8641 - val_loss: 0.6052 - val_cat_acc: 0.4958 - val_accuracy: 0.0585 - val_mse: 0.7475 - val_rmse: 0.8646 - 1s/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "800/800 - 1s - loss: 0.6050 - cat_acc: 0.4950 - accuracy: 0.0605 - mse: 0.7468 - rmse: 0.8642 - val_loss: 0.6053 - val_cat_acc: 0.4956 - val_accuracy: 0.0583 - val_mse: 0.7474 - val_rmse: 0.8645 - 1s/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "800/800 - 1s - loss: 0.6049 - cat_acc: 0.4950 - accuracy: 0.0611 - mse: 0.7469 - rmse: 0.8642 - val_loss: 0.6075 - val_cat_acc: 0.4938 - val_accuracy: 0.0568 - val_mse: 0.7467 - val_rmse: 0.8641 - 1s/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "800/800 - 1s - loss: 0.6049 - cat_acc: 0.4948 - accuracy: 0.0615 - mse: 0.7471 - rmse: 0.8643 - val_loss: 0.6056 - val_cat_acc: 0.4954 - val_accuracy: 0.0617 - val_mse: 0.7476 - val_rmse: 0.8646 - 1s/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "800/800 - 1s - loss: 0.6048 - cat_acc: 0.4951 - accuracy: 0.0624 - mse: 0.7471 - rmse: 0.8643 - val_loss: 0.6055 - val_cat_acc: 0.4951 - val_accuracy: 0.0601 - val_mse: 0.7473 - val_rmse: 0.8645 - 1s/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "800/800 - 1s - loss: 0.6049 - cat_acc: 0.4949 - accuracy: 0.0633 - mse: 0.7471 - rmse: 0.8644 - val_loss: 0.6057 - val_cat_acc: 0.4951 - val_accuracy: 0.0635 - val_mse: 0.7472 - val_rmse: 0.8644 - 1s/epoch - 1ms/step\n",
      "Epoch 83: early stopping\n",
      "3125/3125 [==============================] - 3s 919us/step\n",
      "INFO:tensorflow:Assets written to: ram://ad522184-ef93-4f25-b6a0-b95a61305bd8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://ad522184-ef93-4f25-b6a0-b95a61305bd8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 1.1879 - cat_acc: 0.4917 - accuracy: 0.0000e+00 - mse: 0.2353 - rmse: 0.4850 - val_loss: 1.0498 - val_cat_acc: 0.5515 - val_accuracy: 0.0000e+00 - val_mse: 0.3075 - val_rmse: 0.5545 - 2s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 1.0127 - cat_acc: 0.5111 - accuracy: 0.0000e+00 - mse: 0.4020 - rmse: 0.6341 - val_loss: 0.9908 - val_cat_acc: 0.4951 - val_accuracy: 0.0000e+00 - val_mse: 0.4802 - val_rmse: 0.6929 - 1s/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.9790 - cat_acc: 0.4956 - accuracy: 0.0000e+00 - mse: 0.5295 - rmse: 0.7277 - val_loss: 0.9710 - val_cat_acc: 0.4937 - val_accuracy: 0.0000e+00 - val_mse: 0.5688 - val_rmse: 0.7542 - 1s/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.9586 - cat_acc: 0.4886 - accuracy: 0.0000e+00 - mse: 0.5780 - rmse: 0.7602 - val_loss: 0.9423 - val_cat_acc: 0.4819 - val_accuracy: 0.0000e+00 - val_mse: 0.5776 - val_rmse: 0.7600 - 1s/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.9161 - cat_acc: 0.4801 - accuracy: 0.0000e+00 - mse: 0.5746 - rmse: 0.7580 - val_loss: 0.8960 - val_cat_acc: 0.4794 - val_accuracy: 0.0000e+00 - val_mse: 0.5832 - val_rmse: 0.7637 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.8801 - cat_acc: 0.4815 - accuracy: 0.0000e+00 - mse: 0.5954 - rmse: 0.7716 - val_loss: 0.8691 - val_cat_acc: 0.4811 - val_accuracy: 0.0000e+00 - val_mse: 0.6092 - val_rmse: 0.7805 - 1s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.8583 - cat_acc: 0.4834 - accuracy: 0.0000e+00 - mse: 0.6183 - rmse: 0.7864 - val_loss: 0.8512 - val_cat_acc: 0.4841 - val_accuracy: 0.0000e+00 - val_mse: 0.6270 - val_rmse: 0.7918 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.8427 - cat_acc: 0.4848 - accuracy: 0.0000e+00 - mse: 0.6345 - rmse: 0.7965 - val_loss: 0.8372 - val_cat_acc: 0.4857 - val_accuracy: 0.0000e+00 - val_mse: 0.6400 - val_rmse: 0.8000 - 1s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.8291 - cat_acc: 0.4861 - accuracy: 0.0000e+00 - mse: 0.6413 - rmse: 0.8008 - val_loss: 0.8235 - val_cat_acc: 0.4870 - val_accuracy: 0.0000e+00 - val_mse: 0.6391 - val_rmse: 0.7995 - 1s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.8148 - cat_acc: 0.4871 - accuracy: 0.0000e+00 - mse: 0.6399 - rmse: 0.8000 - val_loss: 0.8097 - val_cat_acc: 0.4863 - val_accuracy: 0.0000e+00 - val_mse: 0.6409 - val_rmse: 0.8005 - 1s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.8025 - cat_acc: 0.4872 - accuracy: 0.0000e+00 - mse: 0.6435 - rmse: 0.8022 - val_loss: 0.7988 - val_cat_acc: 0.4863 - val_accuracy: 0.0000e+00 - val_mse: 0.6450 - val_rmse: 0.8031 - 1s/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.7932 - cat_acc: 0.4871 - accuracy: 0.0000e+00 - mse: 0.6493 - rmse: 0.8058 - val_loss: 0.7908 - val_cat_acc: 0.4854 - val_accuracy: 0.0000e+00 - val_mse: 0.6536 - val_rmse: 0.8085 - 1s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.7858 - cat_acc: 0.4874 - accuracy: 0.0000e+00 - mse: 0.6557 - rmse: 0.8098 - val_loss: 0.7837 - val_cat_acc: 0.4872 - val_accuracy: 0.0000e+00 - val_mse: 0.6584 - val_rmse: 0.8114 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.7797 - cat_acc: 0.4876 - accuracy: 0.0000e+00 - mse: 0.6615 - rmse: 0.8133 - val_loss: 0.7782 - val_cat_acc: 0.4872 - val_accuracy: 0.0000e+00 - val_mse: 0.6649 - val_rmse: 0.8154 - 1s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.7748 - cat_acc: 0.4876 - accuracy: 6.2500e-06 - mse: 0.6669 - rmse: 0.8166 - val_loss: 0.7739 - val_cat_acc: 0.4867 - val_accuracy: 3.7500e-05 - val_mse: 0.6697 - val_rmse: 0.8184 - 1s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.7706 - cat_acc: 0.4875 - accuracy: 3.1250e-05 - mse: 0.6718 - rmse: 0.8196 - val_loss: 0.7702 - val_cat_acc: 0.4861 - val_accuracy: 1.0000e-04 - val_mse: 0.6731 - val_rmse: 0.8204 - 1s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.7671 - cat_acc: 0.4877 - accuracy: 7.8125e-05 - mse: 0.6760 - rmse: 0.8222 - val_loss: 0.7667 - val_cat_acc: 0.4873 - val_accuracy: 1.3750e-04 - val_mse: 0.6775 - val_rmse: 0.8231 - 1s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.7641 - cat_acc: 0.4878 - accuracy: 1.1250e-04 - mse: 0.6800 - rmse: 0.8246 - val_loss: 0.7641 - val_cat_acc: 0.4874 - val_accuracy: 1.8750e-04 - val_mse: 0.6798 - val_rmse: 0.8245 - 1s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.7616 - cat_acc: 0.4878 - accuracy: 1.3125e-04 - mse: 0.6833 - rmse: 0.8266 - val_loss: 0.7618 - val_cat_acc: 0.4864 - val_accuracy: 2.0000e-04 - val_mse: 0.6837 - val_rmse: 0.8269 - 1s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.7594 - cat_acc: 0.4879 - accuracy: 1.6562e-04 - mse: 0.6864 - rmse: 0.8285 - val_loss: 0.7597 - val_cat_acc: 0.4870 - val_accuracy: 2.3750e-04 - val_mse: 0.6896 - val_rmse: 0.8304 - 1s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.7574 - cat_acc: 0.4878 - accuracy: 2.0313e-04 - mse: 0.6892 - rmse: 0.8302 - val_loss: 0.7582 - val_cat_acc: 0.4889 - val_accuracy: 3.0000e-04 - val_mse: 0.6921 - val_rmse: 0.8319 - 1s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 2s - loss: 0.7558 - cat_acc: 0.4878 - accuracy: 2.4375e-04 - mse: 0.6918 - rmse: 0.8317 - val_loss: 0.7566 - val_cat_acc: 0.4874 - val_accuracy: 3.6250e-04 - val_mse: 0.6943 - val_rmse: 0.8332 - 2s/epoch - 3ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.7543 - cat_acc: 0.4879 - accuracy: 2.9687e-04 - mse: 0.6939 - rmse: 0.8330 - val_loss: 0.7547 - val_cat_acc: 0.4882 - val_accuracy: 4.6250e-04 - val_mse: 0.6947 - val_rmse: 0.8335 - 1s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.7530 - cat_acc: 0.4878 - accuracy: 3.8750e-04 - mse: 0.6959 - rmse: 0.8342 - val_loss: 0.7536 - val_cat_acc: 0.4874 - val_accuracy: 6.6250e-04 - val_mse: 0.6991 - val_rmse: 0.8361 - 1s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.7518 - cat_acc: 0.4878 - accuracy: 4.7500e-04 - mse: 0.6978 - rmse: 0.8353 - val_loss: 0.7526 - val_cat_acc: 0.4866 - val_accuracy: 6.1250e-04 - val_mse: 0.6996 - val_rmse: 0.8364 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.7507 - cat_acc: 0.4878 - accuracy: 5.9687e-04 - mse: 0.6997 - rmse: 0.8365 - val_loss: 0.7519 - val_cat_acc: 0.4876 - val_accuracy: 9.7500e-04 - val_mse: 0.7000 - val_rmse: 0.8366 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.7498 - cat_acc: 0.4878 - accuracy: 6.9062e-04 - mse: 0.7010 - rmse: 0.8373 - val_loss: 0.7509 - val_cat_acc: 0.4877 - val_accuracy: 0.0010 - val_mse: 0.7036 - val_rmse: 0.8388 - 1s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.7489 - cat_acc: 0.4879 - accuracy: 8.3437e-04 - mse: 0.7025 - rmse: 0.8381 - val_loss: 0.7504 - val_cat_acc: 0.4856 - val_accuracy: 8.8750e-04 - val_mse: 0.7010 - val_rmse: 0.8372 - 1s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.7481 - cat_acc: 0.4877 - accuracy: 9.5625e-04 - mse: 0.7041 - rmse: 0.8391 - val_loss: 0.7495 - val_cat_acc: 0.4863 - val_accuracy: 0.0012 - val_mse: 0.7034 - val_rmse: 0.8387 - 1s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.7474 - cat_acc: 0.4879 - accuracy: 0.0011 - mse: 0.7051 - rmse: 0.8397 - val_loss: 0.7488 - val_cat_acc: 0.4852 - val_accuracy: 0.0011 - val_mse: 0.7049 - val_rmse: 0.8396 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.7467 - cat_acc: 0.4877 - accuracy: 0.0013 - mse: 0.7061 - rmse: 0.8403 - val_loss: 0.7483 - val_cat_acc: 0.4857 - val_accuracy: 0.0013 - val_mse: 0.7075 - val_rmse: 0.8411 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.7461 - cat_acc: 0.4877 - accuracy: 0.0015 - mse: 0.7076 - rmse: 0.8412 - val_loss: 0.7472 - val_cat_acc: 0.4866 - val_accuracy: 0.0017 - val_mse: 0.7066 - val_rmse: 0.8406 - 1s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.7455 - cat_acc: 0.4879 - accuracy: 0.0018 - mse: 0.7081 - rmse: 0.8415 - val_loss: 0.7470 - val_cat_acc: 0.4861 - val_accuracy: 0.0018 - val_mse: 0.7098 - val_rmse: 0.8425 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.7450 - cat_acc: 0.4878 - accuracy: 0.0020 - mse: 0.7094 - rmse: 0.8423 - val_loss: 0.7466 - val_cat_acc: 0.4866 - val_accuracy: 0.0021 - val_mse: 0.7104 - val_rmse: 0.8429 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.7444 - cat_acc: 0.4879 - accuracy: 0.0021 - mse: 0.7103 - rmse: 0.8428 - val_loss: 0.7461 - val_cat_acc: 0.4861 - val_accuracy: 0.0023 - val_mse: 0.7113 - val_rmse: 0.8434 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.7441 - cat_acc: 0.4879 - accuracy: 0.0024 - mse: 0.7110 - rmse: 0.8432 - val_loss: 0.7453 - val_cat_acc: 0.4865 - val_accuracy: 0.0023 - val_mse: 0.7118 - val_rmse: 0.8437 - 1s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.7436 - cat_acc: 0.4877 - accuracy: 0.0027 - mse: 0.7119 - rmse: 0.8437 - val_loss: 0.7452 - val_cat_acc: 0.4879 - val_accuracy: 0.0032 - val_mse: 0.7109 - val_rmse: 0.8431 - 1s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.7431 - cat_acc: 0.4880 - accuracy: 0.0030 - mse: 0.7125 - rmse: 0.8441 - val_loss: 0.7444 - val_cat_acc: 0.4863 - val_accuracy: 0.0029 - val_mse: 0.7148 - val_rmse: 0.8455 - 1s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.7428 - cat_acc: 0.4875 - accuracy: 0.0032 - mse: 0.7134 - rmse: 0.8446 - val_loss: 0.7444 - val_cat_acc: 0.4865 - val_accuracy: 0.0034 - val_mse: 0.7111 - val_rmse: 0.8433 - 1s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.7426 - cat_acc: 0.4878 - accuracy: 0.0034 - mse: 0.7138 - rmse: 0.8449 - val_loss: 0.7440 - val_cat_acc: 0.4859 - val_accuracy: 0.0038 - val_mse: 0.7152 - val_rmse: 0.8457 - 1s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.7420 - cat_acc: 0.4877 - accuracy: 0.0037 - mse: 0.7145 - rmse: 0.8453 - val_loss: 0.7433 - val_cat_acc: 0.4866 - val_accuracy: 0.0038 - val_mse: 0.7168 - val_rmse: 0.8466 - 1s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.7418 - cat_acc: 0.4878 - accuracy: 0.0041 - mse: 0.7153 - rmse: 0.8457 - val_loss: 0.7428 - val_cat_acc: 0.4873 - val_accuracy: 0.0043 - val_mse: 0.7161 - val_rmse: 0.8462 - 1s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.7414 - cat_acc: 0.4877 - accuracy: 0.0044 - mse: 0.7157 - rmse: 0.8460 - val_loss: 0.7430 - val_cat_acc: 0.4886 - val_accuracy: 0.0050 - val_mse: 0.7197 - val_rmse: 0.8484 - 1s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.7412 - cat_acc: 0.4880 - accuracy: 0.0047 - mse: 0.7165 - rmse: 0.8464 - val_loss: 0.7426 - val_cat_acc: 0.4888 - val_accuracy: 0.0054 - val_mse: 0.7190 - val_rmse: 0.8479 - 1s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.7409 - cat_acc: 0.4877 - accuracy: 0.0051 - mse: 0.7171 - rmse: 0.8468 - val_loss: 0.7422 - val_cat_acc: 0.4861 - val_accuracy: 0.0054 - val_mse: 0.7169 - val_rmse: 0.8467 - 1s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.7406 - cat_acc: 0.4879 - accuracy: 0.0054 - mse: 0.7172 - rmse: 0.8469 - val_loss: 0.7446 - val_cat_acc: 0.4830 - val_accuracy: 0.0052 - val_mse: 0.7176 - val_rmse: 0.8471 - 1s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.7404 - cat_acc: 0.4876 - accuracy: 0.0057 - mse: 0.7181 - rmse: 0.8474 - val_loss: 0.7417 - val_cat_acc: 0.4874 - val_accuracy: 0.0062 - val_mse: 0.7181 - val_rmse: 0.8474 - 1s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.7402 - cat_acc: 0.4877 - accuracy: 0.0061 - mse: 0.7184 - rmse: 0.8476 - val_loss: 0.7416 - val_cat_acc: 0.4872 - val_accuracy: 0.0072 - val_mse: 0.7172 - val_rmse: 0.8469 - 1s/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.7399 - cat_acc: 0.4879 - accuracy: 0.0064 - mse: 0.7188 - rmse: 0.8478 - val_loss: 0.7415 - val_cat_acc: 0.4878 - val_accuracy: 0.0070 - val_mse: 0.7213 - val_rmse: 0.8493 - 1s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.7399 - cat_acc: 0.4878 - accuracy: 0.0066 - mse: 0.7191 - rmse: 0.8480 - val_loss: 0.7410 - val_cat_acc: 0.4868 - val_accuracy: 0.0070 - val_mse: 0.7224 - val_rmse: 0.8499 - 1s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.7397 - cat_acc: 0.4875 - accuracy: 0.0071 - mse: 0.7199 - rmse: 0.8485 - val_loss: 0.7409 - val_cat_acc: 0.4870 - val_accuracy: 0.0081 - val_mse: 0.7209 - val_rmse: 0.8491 - 1s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.7394 - cat_acc: 0.4880 - accuracy: 0.0076 - mse: 0.7199 - rmse: 0.8485 - val_loss: 0.7407 - val_cat_acc: 0.4853 - val_accuracy: 0.0074 - val_mse: 0.7206 - val_rmse: 0.8489 - 1s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.7392 - cat_acc: 0.4877 - accuracy: 0.0078 - mse: 0.7205 - rmse: 0.8488 - val_loss: 0.7407 - val_cat_acc: 0.4856 - val_accuracy: 0.0077 - val_mse: 0.7223 - val_rmse: 0.8499 - 1s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.7390 - cat_acc: 0.4876 - accuracy: 0.0081 - mse: 0.7208 - rmse: 0.8490 - val_loss: 0.7410 - val_cat_acc: 0.4877 - val_accuracy: 0.0088 - val_mse: 0.7214 - val_rmse: 0.8494 - 1s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.7388 - cat_acc: 0.4878 - accuracy: 0.0085 - mse: 0.7214 - rmse: 0.8493 - val_loss: 0.7401 - val_cat_acc: 0.4879 - val_accuracy: 0.0095 - val_mse: 0.7224 - val_rmse: 0.8499 - 1s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.7387 - cat_acc: 0.4877 - accuracy: 0.0088 - mse: 0.7216 - rmse: 0.8495 - val_loss: 0.7406 - val_cat_acc: 0.4880 - val_accuracy: 0.0095 - val_mse: 0.7228 - val_rmse: 0.8502 - 1s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.7385 - cat_acc: 0.4878 - accuracy: 0.0092 - mse: 0.7221 - rmse: 0.8497 - val_loss: 0.7396 - val_cat_acc: 0.4866 - val_accuracy: 0.0099 - val_mse: 0.7218 - val_rmse: 0.8496 - 1s/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.7385 - cat_acc: 0.4877 - accuracy: 0.0096 - mse: 0.7223 - rmse: 0.8499 - val_loss: 0.7401 - val_cat_acc: 0.4862 - val_accuracy: 0.0099 - val_mse: 0.7223 - val_rmse: 0.8499 - 1s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.7382 - cat_acc: 0.4877 - accuracy: 0.0100 - mse: 0.7226 - rmse: 0.8500 - val_loss: 0.7393 - val_cat_acc: 0.4869 - val_accuracy: 0.0104 - val_mse: 0.7250 - val_rmse: 0.8514 - 1s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.7382 - cat_acc: 0.4875 - accuracy: 0.0105 - mse: 0.7230 - rmse: 0.8503 - val_loss: 0.7395 - val_cat_acc: 0.4857 - val_accuracy: 0.0110 - val_mse: 0.7228 - val_rmse: 0.8502 - 1s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.7380 - cat_acc: 0.4878 - accuracy: 0.0108 - mse: 0.7233 - rmse: 0.8505 - val_loss: 0.7393 - val_cat_acc: 0.4879 - val_accuracy: 0.0110 - val_mse: 0.7267 - val_rmse: 0.8525 - 1s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 1s - loss: 0.7377 - cat_acc: 0.4878 - accuracy: 0.0112 - mse: 0.7236 - rmse: 0.8506 - val_loss: 0.7390 - val_cat_acc: 0.4882 - val_accuracy: 0.0119 - val_mse: 0.7247 - val_rmse: 0.8513 - 1s/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 1s - loss: 0.7376 - cat_acc: 0.4877 - accuracy: 0.0116 - mse: 0.7239 - rmse: 0.8508 - val_loss: 0.7397 - val_cat_acc: 0.4845 - val_accuracy: 0.0121 - val_mse: 0.7235 - val_rmse: 0.8506 - 1s/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 1s - loss: 0.7374 - cat_acc: 0.4875 - accuracy: 0.0118 - mse: 0.7242 - rmse: 0.8510 - val_loss: 0.7401 - val_cat_acc: 0.4857 - val_accuracy: 0.0139 - val_mse: 0.7226 - val_rmse: 0.8501 - 1s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 1s - loss: 0.7374 - cat_acc: 0.4877 - accuracy: 0.0125 - mse: 0.7244 - rmse: 0.8511 - val_loss: 0.7394 - val_cat_acc: 0.4868 - val_accuracy: 0.0125 - val_mse: 0.7245 - val_rmse: 0.8512 - 1s/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "800/800 - 1s - loss: 0.7373 - cat_acc: 0.4876 - accuracy: 0.0126 - mse: 0.7248 - rmse: 0.8514 - val_loss: 0.7393 - val_cat_acc: 0.4854 - val_accuracy: 0.0130 - val_mse: 0.7255 - val_rmse: 0.8518 - 1s/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "800/800 - 1s - loss: 0.7372 - cat_acc: 0.4876 - accuracy: 0.0131 - mse: 0.7248 - rmse: 0.8514 - val_loss: 0.7382 - val_cat_acc: 0.4866 - val_accuracy: 0.0135 - val_mse: 0.7253 - val_rmse: 0.8516 - 1s/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "800/800 - 1s - loss: 0.7370 - cat_acc: 0.4877 - accuracy: 0.0135 - mse: 0.7251 - rmse: 0.8515 - val_loss: 0.7385 - val_cat_acc: 0.4864 - val_accuracy: 0.0144 - val_mse: 0.7250 - val_rmse: 0.8515 - 1s/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "800/800 - 1s - loss: 0.7369 - cat_acc: 0.4875 - accuracy: 0.0137 - mse: 0.7255 - rmse: 0.8518 - val_loss: 0.7380 - val_cat_acc: 0.4879 - val_accuracy: 0.0150 - val_mse: 0.7261 - val_rmse: 0.8521 - 1s/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "800/800 - 1s - loss: 0.7368 - cat_acc: 0.4877 - accuracy: 0.0142 - mse: 0.7256 - rmse: 0.8518 - val_loss: 0.7385 - val_cat_acc: 0.4868 - val_accuracy: 0.0150 - val_mse: 0.7244 - val_rmse: 0.8511 - 1s/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "800/800 - 1s - loss: 0.7368 - cat_acc: 0.4876 - accuracy: 0.0144 - mse: 0.7259 - rmse: 0.8520 - val_loss: 0.7379 - val_cat_acc: 0.4868 - val_accuracy: 0.0143 - val_mse: 0.7272 - val_rmse: 0.8528 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "800/800 - 1s - loss: 0.7367 - cat_acc: 0.4877 - accuracy: 0.0149 - mse: 0.7260 - rmse: 0.8521 - val_loss: 0.7384 - val_cat_acc: 0.4865 - val_accuracy: 0.0153 - val_mse: 0.7286 - val_rmse: 0.8536 - 1s/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "800/800 - 1s - loss: 0.7365 - cat_acc: 0.4877 - accuracy: 0.0153 - mse: 0.7262 - rmse: 0.8522 - val_loss: 0.7382 - val_cat_acc: 0.4861 - val_accuracy: 0.0160 - val_mse: 0.7260 - val_rmse: 0.8520 - 1s/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "800/800 - 1s - loss: 0.7365 - cat_acc: 0.4877 - accuracy: 0.0154 - mse: 0.7265 - rmse: 0.8523 - val_loss: 0.7377 - val_cat_acc: 0.4871 - val_accuracy: 0.0159 - val_mse: 0.7282 - val_rmse: 0.8533 - 1s/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "800/800 - 1s - loss: 0.7364 - cat_acc: 0.4874 - accuracy: 0.0159 - mse: 0.7265 - rmse: 0.8524 - val_loss: 0.7379 - val_cat_acc: 0.4870 - val_accuracy: 0.0167 - val_mse: 0.7283 - val_rmse: 0.8534 - 1s/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "800/800 - 1s - loss: 0.7363 - cat_acc: 0.4878 - accuracy: 0.0161 - mse: 0.7270 - rmse: 0.8527 - val_loss: 0.7381 - val_cat_acc: 0.4862 - val_accuracy: 0.0181 - val_mse: 0.7259 - val_rmse: 0.8520 - 1s/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "800/800 - 1s - loss: 0.7363 - cat_acc: 0.4875 - accuracy: 0.0168 - mse: 0.7268 - rmse: 0.8525 - val_loss: 0.7381 - val_cat_acc: 0.4854 - val_accuracy: 0.0164 - val_mse: 0.7272 - val_rmse: 0.8528 - 1s/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "800/800 - 1s - loss: 0.7362 - cat_acc: 0.4876 - accuracy: 0.0170 - mse: 0.7272 - rmse: 0.8528 - val_loss: 0.7378 - val_cat_acc: 0.4878 - val_accuracy: 0.0171 - val_mse: 0.7293 - val_rmse: 0.8540 - 1s/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "800/800 - 1s - loss: 0.7361 - cat_acc: 0.4875 - accuracy: 0.0172 - mse: 0.7278 - rmse: 0.8531 - val_loss: 0.7376 - val_cat_acc: 0.4877 - val_accuracy: 0.0181 - val_mse: 0.7296 - val_rmse: 0.8542 - 1s/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "800/800 - 1s - loss: 0.7360 - cat_acc: 0.4879 - accuracy: 0.0177 - mse: 0.7275 - rmse: 0.8529 - val_loss: 0.7370 - val_cat_acc: 0.4866 - val_accuracy: 0.0178 - val_mse: 0.7297 - val_rmse: 0.8542 - 1s/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "800/800 - 1s - loss: 0.7361 - cat_acc: 0.4873 - accuracy: 0.0179 - mse: 0.7280 - rmse: 0.8532 - val_loss: 0.7369 - val_cat_acc: 0.4867 - val_accuracy: 0.0176 - val_mse: 0.7305 - val_rmse: 0.8547 - 1s/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "800/800 - 2s - loss: 0.7357 - cat_acc: 0.4876 - accuracy: 0.0182 - mse: 0.7282 - rmse: 0.8534 - val_loss: 0.7381 - val_cat_acc: 0.4856 - val_accuracy: 0.0189 - val_mse: 0.7292 - val_rmse: 0.8539 - 2s/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "800/800 - 1s - loss: 0.7356 - cat_acc: 0.4875 - accuracy: 0.0183 - mse: 0.7283 - rmse: 0.8534 - val_loss: 0.7372 - val_cat_acc: 0.4881 - val_accuracy: 0.0193 - val_mse: 0.7299 - val_rmse: 0.8544 - 1s/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "800/800 - 1s - loss: 0.7357 - cat_acc: 0.4879 - accuracy: 0.0189 - mse: 0.7286 - rmse: 0.8536 - val_loss: 0.7368 - val_cat_acc: 0.4871 - val_accuracy: 0.0196 - val_mse: 0.7295 - val_rmse: 0.8541 - 1s/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "800/800 - 1s - loss: 0.7355 - cat_acc: 0.4878 - accuracy: 0.0191 - mse: 0.7290 - rmse: 0.8538 - val_loss: 0.7377 - val_cat_acc: 0.4879 - val_accuracy: 0.0208 - val_mse: 0.7293 - val_rmse: 0.8540 - 1s/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "800/800 - 1s - loss: 0.7356 - cat_acc: 0.4875 - accuracy: 0.0196 - mse: 0.7288 - rmse: 0.8537 - val_loss: 0.7371 - val_cat_acc: 0.4855 - val_accuracy: 0.0189 - val_mse: 0.7311 - val_rmse: 0.8551 - 1s/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "800/800 - 2s - loss: 0.7355 - cat_acc: 0.4875 - accuracy: 0.0196 - mse: 0.7289 - rmse: 0.8538 - val_loss: 0.7372 - val_cat_acc: 0.4854 - val_accuracy: 0.0205 - val_mse: 0.7285 - val_rmse: 0.8535 - 2s/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "800/800 - 1s - loss: 0.7354 - cat_acc: 0.4877 - accuracy: 0.0200 - mse: 0.7291 - rmse: 0.8538 - val_loss: 0.7368 - val_cat_acc: 0.4869 - val_accuracy: 0.0203 - val_mse: 0.7305 - val_rmse: 0.8547 - 1s/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "800/800 - 1s - loss: 0.7355 - cat_acc: 0.4877 - accuracy: 0.0203 - mse: 0.7292 - rmse: 0.8540 - val_loss: 0.7373 - val_cat_acc: 0.4855 - val_accuracy: 0.0212 - val_mse: 0.7286 - val_rmse: 0.8536 - 1s/epoch - 2ms/step\n",
      "Epoch 89: early stopping\n",
      "3125/3125 [==============================] - 3s 974us/step\n",
      "INFO:tensorflow:Assets written to: ram://e6da2b6e-c7c3-4686-9c07-60eddd1b1255/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e6da2b6e-c7c3-4686-9c07-60eddd1b1255/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 neuron in [1, 10, 100]\n",
      "Training for 1 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.6683 - cat_acc: 0.9570 - accuracy: 0.0000e+00 - mse: 0.3255 - rmse: 0.5705 - val_loss: 0.4367 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.5074 - val_rmse: 0.7123 - 2s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.3951 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.6204 - rmse: 0.7877 - val_loss: 0.3749 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.6946 - val_rmse: 0.8335 - 1s/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.3675 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7156 - rmse: 0.8460 - val_loss: 0.3660 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7309 - val_rmse: 0.8549 - 1s/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3624 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7369 - rmse: 0.8584 - val_loss: 0.3631 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7432 - val_rmse: 0.8621 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3604 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7454 - rmse: 0.8634 - val_loss: 0.3617 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7490 - val_rmse: 0.8655 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.3592 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7497 - rmse: 0.8658 - val_loss: 0.3608 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7521 - val_rmse: 0.8672 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3585 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7520 - rmse: 0.8672 - val_loss: 0.3601 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7538 - val_rmse: 0.8682 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3579 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7534 - rmse: 0.8680 - val_loss: 0.3596 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7550 - val_rmse: 0.8689 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.3574 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7544 - rmse: 0.8686 - val_loss: 0.3592 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7558 - val_rmse: 0.8694 - 1s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3570 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7551 - rmse: 0.8689 - val_loss: 0.3588 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7563 - val_rmse: 0.8697 - 1s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3567 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7556 - rmse: 0.8692 - val_loss: 0.3586 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7568 - val_rmse: 0.8699 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3565 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7559 - rmse: 0.8694 - val_loss: 0.3584 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7569 - val_rmse: 0.8700 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 2s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7562 - rmse: 0.8696 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7574 - val_rmse: 0.8703 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7575 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 9.3750e-06 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 5.9375e-05 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 7.5000e-05 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 1.7813e-04 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 1.0000e-04 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 4.8125e-04 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 7.6250e-04 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 9.1563e-04 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 8.1250e-04 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0012 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0015 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0028 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0037 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0033 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0047 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0057 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0055 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0072 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0043 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0094 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0090 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0119 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0187 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0143 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0122 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0232 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0283 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0249 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0181 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0235 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0229 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0304 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0370 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0328 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0215 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0286 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0289 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0346 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0343 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0369 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0395 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0457 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0676 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0494 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0373 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0408 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0368 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0385 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0346 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0616 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0828 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0577 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0347 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0658 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0601 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0500 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0398 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0412 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0578 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0567 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0564 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0681 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0696 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0527 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0552 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0730 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0636 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0525 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0656 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0564 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0500 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0472 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0644 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0790 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0746 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0567 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.1000 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0894 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0670 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0652 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0622 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0541 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0481 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0893 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0877 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0679 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0483 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.1002 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1076 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0838 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0751 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0576 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0531 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0652 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0489 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0635 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0929 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.1222 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1139 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0924 - mse: 0.7572 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0762 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0586 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0707 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0567 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0438 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0814 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0983 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0760 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0701 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0743 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0655 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0656 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0626 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0558 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0519 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0864 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1139 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.1007 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0925 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0888 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0763 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0953 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0800 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0784 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0553 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0615 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3573 - val_cat_acc: 0.9918 - val_accuracy: 0.0598 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "800/800 - 2s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0856 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0963 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0826 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0711 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0925 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0798 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0681 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0814 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "800/800 - 2s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0642 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0971 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 3ms/step\n",
      "Epoch 85: early stopping\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "INFO:tensorflow:Assets written to: ram://7ed89fae-7d97-4612-a206-b8e6c952d599/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7ed89fae-7d97-4612-a206-b8e6c952d599/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.6843 - cat_acc: 0.9513 - accuracy: 0.0000e+00 - mse: 0.3508 - rmse: 0.5923 - val_loss: 0.4247 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.5462 - val_rmse: 0.7391 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 2s - loss: 0.3872 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.6485 - rmse: 0.8053 - val_loss: 0.3721 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7076 - val_rmse: 0.8412 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.3657 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7246 - rmse: 0.8512 - val_loss: 0.3648 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7372 - val_rmse: 0.8586 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3616 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7418 - rmse: 0.8613 - val_loss: 0.3625 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7470 - val_rmse: 0.8643 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3599 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7484 - rmse: 0.8651 - val_loss: 0.3613 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7513 - val_rmse: 0.8668 - 1s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.3590 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7515 - rmse: 0.8669 - val_loss: 0.3606 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7535 - val_rmse: 0.8681 - 1s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3583 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7532 - rmse: 0.8679 - val_loss: 0.3600 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7547 - val_rmse: 0.8687 - 1s/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3578 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7542 - rmse: 0.8684 - val_loss: 0.3595 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7556 - val_rmse: 0.8692 - 1s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.3574 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7548 - rmse: 0.8688 - val_loss: 0.3591 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7561 - val_rmse: 0.8696 - 1s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3570 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7553 - rmse: 0.8691 - val_loss: 0.3589 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7563 - val_rmse: 0.8697 - 1s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3567 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7557 - rmse: 0.8693 - val_loss: 0.3586 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7569 - val_rmse: 0.8700 - 1s/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3565 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7560 - rmse: 0.8695 - val_loss: 0.3584 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7572 - val_rmse: 0.8702 - 1s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7563 - rmse: 0.8696 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7575 - val_rmse: 0.8704 - 1s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7566 - rmse: 0.8698 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7577 - val_rmse: 0.8704 - 1s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 3.4375e-05 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 7.5000e-05 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 1.2813e-04 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 1.6250e-04 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 3.5000e-04 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 2.8750e-04 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 5.2500e-04 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 9.6250e-04 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 8.9375e-04 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 3.6250e-04 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0014 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0015 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0023 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0098 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0037 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0032 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0040 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0045 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0058 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0054 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0104 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0093 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0082 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0101 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0081 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0103 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0111 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0073 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0106 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0143 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0135 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0091 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0201 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0178 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0156 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0284 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0266 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0181 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0191 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0115 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0291 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0460 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0267 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0253 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0237 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0228 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0215 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0261 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0261 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0456 - val_mse: 0.7577 - val_rmse: 0.8704 - 1s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0367 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0285 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0312 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0722 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0568 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0334 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0303 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0286 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0357 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0344 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0299 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0281 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0480 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0539 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0474 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0346 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0374 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0510 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0425 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0337 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0598 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0475 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 51: early stopping\n",
      "3125/3125 [==============================] - 3s 905us/step\n",
      "INFO:tensorflow:Assets written to: ram://a4a6a665-09f9-4b84-b28b-1fb159b931fc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a4a6a665-09f9-4b84-b28b-1fb159b931fc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100 neuron in [1, 10, 100]\n",
      "Training for 1 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.4553 - cat_acc: 0.9804 - accuracy: 0.0000e+00 - mse: 0.6224 - rmse: 0.7889 - val_loss: 0.3640 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7471 - val_rmse: 0.8643 - 2s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.3607 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7508 - rmse: 0.8665 - val_loss: 0.3619 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7543 - val_rmse: 0.8685 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.3596 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7540 - rmse: 0.8684 - val_loss: 0.3611 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7556 - val_rmse: 0.8693 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3588 - cat_acc: 0.9928 - accuracy: 6.2500e-06 - mse: 0.7549 - rmse: 0.8688 - val_loss: 0.3605 - val_cat_acc: 0.9918 - val_accuracy: 6.2500e-05 - val_mse: 0.7560 - val_rmse: 0.8695 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3583 - cat_acc: 0.9928 - accuracy: 7.1875e-05 - mse: 0.7552 - rmse: 0.8690 - val_loss: 0.3601 - val_cat_acc: 0.9918 - val_accuracy: 2.3750e-04 - val_mse: 0.7560 - val_rmse: 0.8695 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.3579 - cat_acc: 0.9928 - accuracy: 2.3125e-04 - mse: 0.7555 - rmse: 0.8692 - val_loss: 0.3596 - val_cat_acc: 0.9918 - val_accuracy: 2.3750e-04 - val_mse: 0.7568 - val_rmse: 0.8700 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3575 - cat_acc: 0.9928 - accuracy: 4.9688e-04 - mse: 0.7558 - rmse: 0.8693 - val_loss: 0.3596 - val_cat_acc: 0.9918 - val_accuracy: 0.0014 - val_mse: 0.7563 - val_rmse: 0.8697 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3572 - cat_acc: 0.9928 - accuracy: 0.0013 - mse: 0.7561 - rmse: 0.8695 - val_loss: 0.3590 - val_cat_acc: 0.9918 - val_accuracy: 0.0014 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.3570 - cat_acc: 0.9928 - accuracy: 0.0019 - mse: 0.7562 - rmse: 0.8696 - val_loss: 0.3587 - val_cat_acc: 0.9918 - val_accuracy: 0.0014 - val_mse: 0.7573 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3568 - cat_acc: 0.9928 - accuracy: 0.0027 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3585 - val_cat_acc: 0.9918 - val_accuracy: 0.0028 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3566 - cat_acc: 0.9928 - accuracy: 0.0035 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3587 - val_cat_acc: 0.9918 - val_accuracy: 0.0146 - val_mse: 0.7570 - val_rmse: 0.8701 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3565 - cat_acc: 0.9928 - accuracy: 0.0058 - mse: 0.7566 - rmse: 0.8698 - val_loss: 0.3583 - val_cat_acc: 0.9918 - val_accuracy: 0.0021 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3564 - cat_acc: 0.9928 - accuracy: 0.0072 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0063 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0068 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3583 - val_cat_acc: 0.9918 - val_accuracy: 0.0139 - val_mse: 0.7575 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0087 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3583 - val_cat_acc: 0.9918 - val_accuracy: 0.0084 - val_mse: 0.7571 - val_rmse: 0.8701 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0113 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0063 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0112 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0068 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0103 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0057 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0150 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0159 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0181 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0167 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0249 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0239 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0228 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0169 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0250 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0759 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0347 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0199 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0945 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0681 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0631 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0644 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0498 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0277 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0412 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0369 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0381 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0351 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0236 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0537 - val_mse: 0.7573 - val_rmse: 0.8702 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0813 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0507 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0344 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0345 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0509 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0548 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0354 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0303 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0252 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0227 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0264 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0237 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0463 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0506 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0452 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0272 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0863 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.1108 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0996 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0921 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0765 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0774 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0611 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0457 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0420 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0336 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 43: early stopping\n",
      "3125/3125 [==============================] - 3s 916us/step\n",
      "INFO:tensorflow:Assets written to: ram://fdcbd179-b8d7-4493-a42b-307e4e29ed27/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://fdcbd179-b8d7-4493-a42b-307e4e29ed27/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.4565 - cat_acc: 0.9765 - accuracy: 0.0000e+00 - mse: 0.6228 - rmse: 0.7892 - val_loss: 0.3638 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7473 - val_rmse: 0.8645 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.3606 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7509 - rmse: 0.8665 - val_loss: 0.3618 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7543 - val_rmse: 0.8685 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.3595 - cat_acc: 0.9928 - accuracy: 3.1250e-06 - mse: 0.7541 - rmse: 0.8684 - val_loss: 0.3610 - val_cat_acc: 0.9918 - val_accuracy: 1.2500e-05 - val_mse: 0.7557 - val_rmse: 0.8693 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3588 - cat_acc: 0.9928 - accuracy: 1.5625e-05 - mse: 0.7549 - rmse: 0.8688 - val_loss: 0.3604 - val_cat_acc: 0.9918 - val_accuracy: 8.7500e-05 - val_mse: 0.7561 - val_rmse: 0.8696 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3582 - cat_acc: 0.9928 - accuracy: 9.0625e-05 - mse: 0.7553 - rmse: 0.8691 - val_loss: 0.3599 - val_cat_acc: 0.9918 - val_accuracy: 2.0000e-04 - val_mse: 0.7564 - val_rmse: 0.8697 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.3578 - cat_acc: 0.9928 - accuracy: 2.9687e-04 - mse: 0.7556 - rmse: 0.8692 - val_loss: 0.3596 - val_cat_acc: 0.9918 - val_accuracy: 3.1250e-04 - val_mse: 0.7568 - val_rmse: 0.8699 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3575 - cat_acc: 0.9928 - accuracy: 6.1250e-04 - mse: 0.7558 - rmse: 0.8694 - val_loss: 0.3593 - val_cat_acc: 0.9918 - val_accuracy: 6.6250e-04 - val_mse: 0.7573 - val_rmse: 0.8702 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3572 - cat_acc: 0.9928 - accuracy: 0.0011 - mse: 0.7561 - rmse: 0.8695 - val_loss: 0.3590 - val_cat_acc: 0.9918 - val_accuracy: 0.0018 - val_mse: 0.7571 - val_rmse: 0.8701 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.3569 - cat_acc: 0.9928 - accuracy: 0.0014 - mse: 0.7563 - rmse: 0.8696 - val_loss: 0.3587 - val_cat_acc: 0.9918 - val_accuracy: 0.0022 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 2s - loss: 0.3567 - cat_acc: 0.9928 - accuracy: 0.0025 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3591 - val_cat_acc: 0.9918 - val_accuracy: 0.0091 - val_mse: 0.7559 - val_rmse: 0.8694 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3566 - cat_acc: 0.9928 - accuracy: 0.0036 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3585 - val_cat_acc: 0.9918 - val_accuracy: 0.0022 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3565 - cat_acc: 0.9928 - accuracy: 0.0061 - mse: 0.7566 - rmse: 0.8698 - val_loss: 0.3583 - val_cat_acc: 0.9918 - val_accuracy: 0.0029 - val_mse: 0.7577 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0049 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0039 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0099 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0069 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0066 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0060 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0118 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0064 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0126 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0123 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0086 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3587 - val_cat_acc: 0.9918 - val_accuracy: 0.0326 - val_mse: 0.7565 - val_rmse: 0.8698 - 1s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0226 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0146 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0161 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0218 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0160 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0180 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0238 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0205 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0183 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0265 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0209 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0234 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0306 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0373 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0356 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0179 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0257 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0223 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0335 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0402 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0271 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0436 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.1235 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0900 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0643 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0660 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0591 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0575 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 2s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0425 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0226 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0355 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0704 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0595 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0468 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0361 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0299 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0502 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0688 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0499 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0387 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 38: early stopping\n",
      "3125/3125 [==============================] - 3s 900us/step\n",
      "INFO:tensorflow:Assets written to: ram://6789e240-e597-45df-a2d3-3280096f2c34/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://6789e240-e597-45df-a2d3-3280096f2c34/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 2 fold of 5 folds\n",
      "Training for 1 neuron in [1, 10, 100]\n",
      "Training for 1 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 1.1178 - cat_acc: 0.4892 - accuracy: 0.0000e+00 - mse: 0.2452 - rmse: 0.4952 - val_loss: 0.9496 - val_cat_acc: 0.4969 - val_accuracy: 0.0000e+00 - val_mse: 0.3417 - val_rmse: 0.5846 - 2s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.9055 - cat_acc: 0.4973 - accuracy: 0.0000e+00 - mse: 0.4397 - rmse: 0.6631 - val_loss: 0.8802 - val_cat_acc: 0.4970 - val_accuracy: 0.0000e+00 - val_mse: 0.5189 - val_rmse: 0.7203 - 1s/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.8659 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.5677 - rmse: 0.7535 - val_loss: 0.8581 - val_cat_acc: 0.4971 - val_accuracy: 0.0000e+00 - val_mse: 0.6092 - val_rmse: 0.7805 - 1s/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.8506 - cat_acc: 0.4975 - accuracy: 0.0000e+00 - mse: 0.6356 - rmse: 0.7973 - val_loss: 0.8477 - val_cat_acc: 0.4972 - val_accuracy: 0.0000e+00 - val_mse: 0.6596 - val_rmse: 0.8121 - 1s/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.8427 - cat_acc: 0.4975 - accuracy: 0.0000e+00 - mse: 0.6740 - rmse: 0.8210 - val_loss: 0.8416 - val_cat_acc: 0.4972 - val_accuracy: 0.0000e+00 - val_mse: 0.6870 - val_rmse: 0.8289 - 1s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.8343 - cat_acc: 0.4965 - accuracy: 0.0000e+00 - mse: 0.6792 - rmse: 0.8241 - val_loss: 0.8236 - val_cat_acc: 0.4950 - val_accuracy: 0.0000e+00 - val_mse: 0.6533 - val_rmse: 0.8083 - 1s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.8005 - cat_acc: 0.4936 - accuracy: 0.0000e+00 - mse: 0.6279 - rmse: 0.7924 - val_loss: 0.7839 - val_cat_acc: 0.4939 - val_accuracy: 0.0000e+00 - val_mse: 0.6235 - val_rmse: 0.7896 - 1s/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.7655 - cat_acc: 0.4938 - accuracy: 0.0000e+00 - mse: 0.6250 - rmse: 0.7906 - val_loss: 0.7510 - val_cat_acc: 0.4927 - val_accuracy: 0.0000e+00 - val_mse: 0.6259 - val_rmse: 0.7911 - 1s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.7322 - cat_acc: 0.4910 - accuracy: 0.0000e+00 - mse: 0.6255 - rmse: 0.7909 - val_loss: 0.7203 - val_cat_acc: 0.4895 - val_accuracy: 0.0000e+00 - val_mse: 0.6307 - val_rmse: 0.7942 - 1s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.7078 - cat_acc: 0.4887 - accuracy: 0.0000e+00 - mse: 0.6364 - rmse: 0.7978 - val_loss: 0.7011 - val_cat_acc: 0.4884 - val_accuracy: 0.0000e+00 - val_mse: 0.6441 - val_rmse: 0.8025 - 1s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.6920 - cat_acc: 0.4884 - accuracy: 0.0000e+00 - mse: 0.6501 - rmse: 0.8063 - val_loss: 0.6888 - val_cat_acc: 0.4863 - val_accuracy: 0.0000e+00 - val_mse: 0.6571 - val_rmse: 0.8106 - 1s/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.6802 - cat_acc: 0.4878 - accuracy: 0.0000e+00 - mse: 0.6625 - rmse: 0.8139 - val_loss: 0.6776 - val_cat_acc: 0.4888 - val_accuracy: 0.0000e+00 - val_mse: 0.6675 - val_rmse: 0.8170 - 1s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.6709 - cat_acc: 0.4881 - accuracy: 0.0000e+00 - mse: 0.6726 - rmse: 0.8201 - val_loss: 0.6692 - val_cat_acc: 0.4884 - val_accuracy: 0.0000e+00 - val_mse: 0.6784 - val_rmse: 0.8237 - 1s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.6637 - cat_acc: 0.4882 - accuracy: 0.0000e+00 - mse: 0.6816 - rmse: 0.8256 - val_loss: 0.6630 - val_cat_acc: 0.4881 - val_accuracy: 0.0000e+00 - val_mse: 0.6855 - val_rmse: 0.8280 - 1s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.6577 - cat_acc: 0.4886 - accuracy: 0.0000e+00 - mse: 0.6892 - rmse: 0.8302 - val_loss: 0.6568 - val_cat_acc: 0.4886 - val_accuracy: 0.0000e+00 - val_mse: 0.6925 - val_rmse: 0.8322 - 1s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.6527 - cat_acc: 0.4885 - accuracy: 0.0000e+00 - mse: 0.6956 - rmse: 0.8340 - val_loss: 0.6524 - val_cat_acc: 0.4895 - val_accuracy: 0.0000e+00 - val_mse: 0.6979 - val_rmse: 0.8354 - 1s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.6487 - cat_acc: 0.4886 - accuracy: 0.0000e+00 - mse: 0.7010 - rmse: 0.8373 - val_loss: 0.6487 - val_cat_acc: 0.4888 - val_accuracy: 0.0000e+00 - val_mse: 0.7038 - val_rmse: 0.8390 - 1s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.6451 - cat_acc: 0.4889 - accuracy: 0.0000e+00 - mse: 0.7057 - rmse: 0.8401 - val_loss: 0.6457 - val_cat_acc: 0.4888 - val_accuracy: 0.0000e+00 - val_mse: 0.7068 - val_rmse: 0.8407 - 1s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.6423 - cat_acc: 0.4888 - accuracy: 3.1250e-06 - mse: 0.7098 - rmse: 0.8425 - val_loss: 0.6425 - val_cat_acc: 0.4906 - val_accuracy: 0.0000e+00 - val_mse: 0.7106 - val_rmse: 0.8430 - 1s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.6397 - cat_acc: 0.4891 - accuracy: 5.6250e-05 - mse: 0.7131 - rmse: 0.8445 - val_loss: 0.6408 - val_cat_acc: 0.4891 - val_accuracy: 7.5000e-05 - val_mse: 0.7140 - val_rmse: 0.8450 - 1s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.6377 - cat_acc: 0.4891 - accuracy: 1.3438e-04 - mse: 0.7160 - rmse: 0.8462 - val_loss: 0.6384 - val_cat_acc: 0.4893 - val_accuracy: 1.2500e-04 - val_mse: 0.7176 - val_rmse: 0.8471 - 1s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.6358 - cat_acc: 0.4893 - accuracy: 2.5937e-04 - mse: 0.7187 - rmse: 0.8478 - val_loss: 0.6370 - val_cat_acc: 0.4892 - val_accuracy: 2.0000e-04 - val_mse: 0.7192 - val_rmse: 0.8480 - 1s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.6342 - cat_acc: 0.4893 - accuracy: 4.2500e-04 - mse: 0.7209 - rmse: 0.8490 - val_loss: 0.6350 - val_cat_acc: 0.4902 - val_accuracy: 5.5000e-04 - val_mse: 0.7210 - val_rmse: 0.8491 - 1s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.6329 - cat_acc: 0.4896 - accuracy: 6.9375e-04 - mse: 0.7227 - rmse: 0.8501 - val_loss: 0.6339 - val_cat_acc: 0.4902 - val_accuracy: 8.6250e-04 - val_mse: 0.7230 - val_rmse: 0.8503 - 1s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.6316 - cat_acc: 0.4897 - accuracy: 0.0011 - mse: 0.7244 - rmse: 0.8511 - val_loss: 0.6336 - val_cat_acc: 0.4882 - val_accuracy: 0.0010 - val_mse: 0.7255 - val_rmse: 0.8518 - 1s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.6307 - cat_acc: 0.4895 - accuracy: 0.0015 - mse: 0.7263 - rmse: 0.8522 - val_loss: 0.6317 - val_cat_acc: 0.4902 - val_accuracy: 0.0019 - val_mse: 0.7266 - val_rmse: 0.8524 - 1s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.6296 - cat_acc: 0.4898 - accuracy: 0.0021 - mse: 0.7274 - rmse: 0.8529 - val_loss: 0.6308 - val_cat_acc: 0.4892 - val_accuracy: 0.0023 - val_mse: 0.7284 - val_rmse: 0.8535 - 1s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.6288 - cat_acc: 0.4896 - accuracy: 0.0027 - mse: 0.7285 - rmse: 0.8535 - val_loss: 0.6296 - val_cat_acc: 0.4908 - val_accuracy: 0.0032 - val_mse: 0.7285 - val_rmse: 0.8535 - 1s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.6281 - cat_acc: 0.4898 - accuracy: 0.0035 - mse: 0.7297 - rmse: 0.8542 - val_loss: 0.6297 - val_cat_acc: 0.4891 - val_accuracy: 0.0038 - val_mse: 0.7302 - val_rmse: 0.8545 - 1s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.6273 - cat_acc: 0.4897 - accuracy: 0.0043 - mse: 0.7308 - rmse: 0.8549 - val_loss: 0.6284 - val_cat_acc: 0.4903 - val_accuracy: 0.0046 - val_mse: 0.7313 - val_rmse: 0.8552 - 1s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.6268 - cat_acc: 0.4898 - accuracy: 0.0054 - mse: 0.7315 - rmse: 0.8553 - val_loss: 0.6281 - val_cat_acc: 0.4906 - val_accuracy: 0.0059 - val_mse: 0.7316 - val_rmse: 0.8554 - 1s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.6262 - cat_acc: 0.4897 - accuracy: 0.0065 - mse: 0.7322 - rmse: 0.8557 - val_loss: 0.6270 - val_cat_acc: 0.4909 - val_accuracy: 0.0074 - val_mse: 0.7319 - val_rmse: 0.8555 - 1s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.6258 - cat_acc: 0.4900 - accuracy: 0.0077 - mse: 0.7329 - rmse: 0.8561 - val_loss: 0.6272 - val_cat_acc: 0.4906 - val_accuracy: 0.0089 - val_mse: 0.7321 - val_rmse: 0.8556 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.6252 - cat_acc: 0.4902 - accuracy: 0.0089 - mse: 0.7335 - rmse: 0.8565 - val_loss: 0.6267 - val_cat_acc: 0.4902 - val_accuracy: 0.0105 - val_mse: 0.7330 - val_rmse: 0.8561 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.6248 - cat_acc: 0.4902 - accuracy: 0.0102 - mse: 0.7342 - rmse: 0.8569 - val_loss: 0.6261 - val_cat_acc: 0.4904 - val_accuracy: 0.0110 - val_mse: 0.7341 - val_rmse: 0.8568 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.6245 - cat_acc: 0.4900 - accuracy: 0.0115 - mse: 0.7349 - rmse: 0.8573 - val_loss: 0.6256 - val_cat_acc: 0.4904 - val_accuracy: 0.0117 - val_mse: 0.7353 - val_rmse: 0.8575 - 1s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.6240 - cat_acc: 0.4902 - accuracy: 0.0127 - mse: 0.7354 - rmse: 0.8575 - val_loss: 0.6249 - val_cat_acc: 0.4909 - val_accuracy: 0.0135 - val_mse: 0.7354 - val_rmse: 0.8575 - 1s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.6237 - cat_acc: 0.4901 - accuracy: 0.0141 - mse: 0.7359 - rmse: 0.8579 - val_loss: 0.6248 - val_cat_acc: 0.4908 - val_accuracy: 0.0158 - val_mse: 0.7354 - val_rmse: 0.8576 - 1s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.6234 - cat_acc: 0.4902 - accuracy: 0.0155 - mse: 0.7363 - rmse: 0.8581 - val_loss: 0.6248 - val_cat_acc: 0.4898 - val_accuracy: 0.0155 - val_mse: 0.7368 - val_rmse: 0.8584 - 1s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.6231 - cat_acc: 0.4902 - accuracy: 0.0170 - mse: 0.7367 - rmse: 0.8583 - val_loss: 0.6248 - val_cat_acc: 0.4913 - val_accuracy: 0.0186 - val_mse: 0.7360 - val_rmse: 0.8579 - 1s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.6229 - cat_acc: 0.4902 - accuracy: 0.0186 - mse: 0.7370 - rmse: 0.8585 - val_loss: 0.6239 - val_cat_acc: 0.4900 - val_accuracy: 0.0179 - val_mse: 0.7383 - val_rmse: 0.8592 - 1s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.6226 - cat_acc: 0.4903 - accuracy: 0.0199 - mse: 0.7375 - rmse: 0.8588 - val_loss: 0.6247 - val_cat_acc: 0.4897 - val_accuracy: 0.0224 - val_mse: 0.7364 - val_rmse: 0.8582 - 1s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.6223 - cat_acc: 0.4902 - accuracy: 0.0214 - mse: 0.7378 - rmse: 0.8590 - val_loss: 0.6237 - val_cat_acc: 0.4910 - val_accuracy: 0.0236 - val_mse: 0.7379 - val_rmse: 0.8590 - 1s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.6220 - cat_acc: 0.4905 - accuracy: 0.0229 - mse: 0.7381 - rmse: 0.8591 - val_loss: 0.6249 - val_cat_acc: 0.4877 - val_accuracy: 0.0216 - val_mse: 0.7399 - val_rmse: 0.8602 - 1s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.6218 - cat_acc: 0.4903 - accuracy: 0.0240 - mse: 0.7386 - rmse: 0.8594 - val_loss: 0.6228 - val_cat_acc: 0.4906 - val_accuracy: 0.0247 - val_mse: 0.7389 - val_rmse: 0.8596 - 1s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.6217 - cat_acc: 0.4903 - accuracy: 0.0253 - mse: 0.7390 - rmse: 0.8596 - val_loss: 0.6235 - val_cat_acc: 0.4893 - val_accuracy: 0.0262 - val_mse: 0.7393 - val_rmse: 0.8598 - 1s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.6215 - cat_acc: 0.4904 - accuracy: 0.0271 - mse: 0.7391 - rmse: 0.8597 - val_loss: 0.6226 - val_cat_acc: 0.4908 - val_accuracy: 0.0272 - val_mse: 0.7391 - val_rmse: 0.8597 - 1s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.6213 - cat_acc: 0.4904 - accuracy: 0.0281 - mse: 0.7395 - rmse: 0.8599 - val_loss: 0.6227 - val_cat_acc: 0.4902 - val_accuracy: 0.0301 - val_mse: 0.7389 - val_rmse: 0.8596 - 1s/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.6211 - cat_acc: 0.4904 - accuracy: 0.0294 - mse: 0.7396 - rmse: 0.8600 - val_loss: 0.6226 - val_cat_acc: 0.4895 - val_accuracy: 0.0290 - val_mse: 0.7406 - val_rmse: 0.8606 - 1s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.6210 - cat_acc: 0.4904 - accuracy: 0.0303 - mse: 0.7401 - rmse: 0.8603 - val_loss: 0.6223 - val_cat_acc: 0.4905 - val_accuracy: 0.0313 - val_mse: 0.7395 - val_rmse: 0.8600 - 1s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.6209 - cat_acc: 0.4903 - accuracy: 0.0318 - mse: 0.7402 - rmse: 0.8604 - val_loss: 0.6220 - val_cat_acc: 0.4909 - val_accuracy: 0.0347 - val_mse: 0.7401 - val_rmse: 0.8603 - 1s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.6207 - cat_acc: 0.4902 - accuracy: 0.0332 - mse: 0.7404 - rmse: 0.8605 - val_loss: 0.6223 - val_cat_acc: 0.4909 - val_accuracy: 0.0336 - val_mse: 0.7410 - val_rmse: 0.8608 - 1s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.6205 - cat_acc: 0.4905 - accuracy: 0.0341 - mse: 0.7405 - rmse: 0.8605 - val_loss: 0.6216 - val_cat_acc: 0.4908 - val_accuracy: 0.0363 - val_mse: 0.7403 - val_rmse: 0.8604 - 1s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.6203 - cat_acc: 0.4906 - accuracy: 0.0353 - mse: 0.7407 - rmse: 0.8606 - val_loss: 0.6217 - val_cat_acc: 0.4906 - val_accuracy: 0.0364 - val_mse: 0.7408 - val_rmse: 0.8607 - 1s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.6202 - cat_acc: 0.4904 - accuracy: 0.0364 - mse: 0.7410 - rmse: 0.8608 - val_loss: 0.6216 - val_cat_acc: 0.4900 - val_accuracy: 0.0370 - val_mse: 0.7415 - val_rmse: 0.8611 - 1s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.6201 - cat_acc: 0.4905 - accuracy: 0.0375 - mse: 0.7412 - rmse: 0.8609 - val_loss: 0.6212 - val_cat_acc: 0.4908 - val_accuracy: 0.0397 - val_mse: 0.7409 - val_rmse: 0.8608 - 1s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.6199 - cat_acc: 0.4906 - accuracy: 0.0384 - mse: 0.7413 - rmse: 0.8610 - val_loss: 0.6220 - val_cat_acc: 0.4916 - val_accuracy: 0.0409 - val_mse: 0.7407 - val_rmse: 0.8606 - 1s/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.6199 - cat_acc: 0.4905 - accuracy: 0.0396 - mse: 0.7415 - rmse: 0.8611 - val_loss: 0.6209 - val_cat_acc: 0.4911 - val_accuracy: 0.0405 - val_mse: 0.7415 - val_rmse: 0.8611 - 1s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.6198 - cat_acc: 0.4903 - accuracy: 0.0405 - mse: 0.7419 - rmse: 0.8613 - val_loss: 0.6208 - val_cat_acc: 0.4908 - val_accuracy: 0.0404 - val_mse: 0.7418 - val_rmse: 0.8613 - 1s/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.6196 - cat_acc: 0.4905 - accuracy: 0.0415 - mse: 0.7419 - rmse: 0.8613 - val_loss: 0.6205 - val_cat_acc: 0.4913 - val_accuracy: 0.0435 - val_mse: 0.7419 - val_rmse: 0.8613 - 1s/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.6197 - cat_acc: 0.4906 - accuracy: 0.0426 - mse: 0.7421 - rmse: 0.8614 - val_loss: 0.6208 - val_cat_acc: 0.4904 - val_accuracy: 0.0444 - val_mse: 0.7428 - val_rmse: 0.8619 - 1s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 1s - loss: 0.6195 - cat_acc: 0.4907 - accuracy: 0.0436 - mse: 0.7421 - rmse: 0.8615 - val_loss: 0.6210 - val_cat_acc: 0.4913 - val_accuracy: 0.0443 - val_mse: 0.7428 - val_rmse: 0.8618 - 1s/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 1s - loss: 0.6193 - cat_acc: 0.4905 - accuracy: 0.0440 - mse: 0.7425 - rmse: 0.8617 - val_loss: 0.6207 - val_cat_acc: 0.4922 - val_accuracy: 0.0487 - val_mse: 0.7408 - val_rmse: 0.8607 - 1s/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 1s - loss: 0.6193 - cat_acc: 0.4905 - accuracy: 0.0453 - mse: 0.7425 - rmse: 0.8617 - val_loss: 0.6202 - val_cat_acc: 0.4913 - val_accuracy: 0.0477 - val_mse: 0.7424 - val_rmse: 0.8616 - 1s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 1s - loss: 0.6191 - cat_acc: 0.4906 - accuracy: 0.0464 - mse: 0.7425 - rmse: 0.8617 - val_loss: 0.6200 - val_cat_acc: 0.4911 - val_accuracy: 0.0475 - val_mse: 0.7426 - val_rmse: 0.8618 - 1s/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "800/800 - 1s - loss: 0.6191 - cat_acc: 0.4905 - accuracy: 0.0472 - mse: 0.7428 - rmse: 0.8618 - val_loss: 0.6211 - val_cat_acc: 0.4908 - val_accuracy: 0.0491 - val_mse: 0.7432 - val_rmse: 0.8621 - 1s/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "800/800 - 1s - loss: 0.6191 - cat_acc: 0.4906 - accuracy: 0.0480 - mse: 0.7428 - rmse: 0.8618 - val_loss: 0.6198 - val_cat_acc: 0.4908 - val_accuracy: 0.0468 - val_mse: 0.7434 - val_rmse: 0.8622 - 1s/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "800/800 - 1s - loss: 0.6189 - cat_acc: 0.4906 - accuracy: 0.0487 - mse: 0.7431 - rmse: 0.8620 - val_loss: 0.6206 - val_cat_acc: 0.4913 - val_accuracy: 0.0540 - val_mse: 0.7428 - val_rmse: 0.8619 - 1s/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "800/800 - 1s - loss: 0.6188 - cat_acc: 0.4908 - accuracy: 0.0496 - mse: 0.7430 - rmse: 0.8620 - val_loss: 0.6200 - val_cat_acc: 0.4911 - val_accuracy: 0.0498 - val_mse: 0.7441 - val_rmse: 0.8626 - 1s/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "800/800 - 1s - loss: 0.6187 - cat_acc: 0.4908 - accuracy: 0.0506 - mse: 0.7433 - rmse: 0.8621 - val_loss: 0.6199 - val_cat_acc: 0.4909 - val_accuracy: 0.0505 - val_mse: 0.7430 - val_rmse: 0.8620 - 1s/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "800/800 - 1s - loss: 0.6187 - cat_acc: 0.4905 - accuracy: 0.0515 - mse: 0.7433 - rmse: 0.8622 - val_loss: 0.6198 - val_cat_acc: 0.4918 - val_accuracy: 0.0546 - val_mse: 0.7424 - val_rmse: 0.8616 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "800/800 - 1s - loss: 0.6186 - cat_acc: 0.4907 - accuracy: 0.0519 - mse: 0.7435 - rmse: 0.8622 - val_loss: 0.6197 - val_cat_acc: 0.4917 - val_accuracy: 0.0543 - val_mse: 0.7429 - val_rmse: 0.8619 - 1s/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "800/800 - 1s - loss: 0.6185 - cat_acc: 0.4909 - accuracy: 0.0525 - mse: 0.7436 - rmse: 0.8623 - val_loss: 0.6201 - val_cat_acc: 0.4915 - val_accuracy: 0.0537 - val_mse: 0.7437 - val_rmse: 0.8624 - 1s/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "800/800 - 1s - loss: 0.6185 - cat_acc: 0.4907 - accuracy: 0.0530 - mse: 0.7437 - rmse: 0.8624 - val_loss: 0.6198 - val_cat_acc: 0.4906 - val_accuracy: 0.0512 - val_mse: 0.7439 - val_rmse: 0.8625 - 1s/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "800/800 - 1s - loss: 0.6184 - cat_acc: 0.4907 - accuracy: 0.0535 - mse: 0.7439 - rmse: 0.8625 - val_loss: 0.6197 - val_cat_acc: 0.4913 - val_accuracy: 0.0546 - val_mse: 0.7438 - val_rmse: 0.8624 - 1s/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "800/800 - 1s - loss: 0.6184 - cat_acc: 0.4908 - accuracy: 0.0544 - mse: 0.7439 - rmse: 0.8625 - val_loss: 0.6195 - val_cat_acc: 0.4908 - val_accuracy: 0.0539 - val_mse: 0.7441 - val_rmse: 0.8626 - 1s/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "800/800 - 1s - loss: 0.6183 - cat_acc: 0.4906 - accuracy: 0.0550 - mse: 0.7441 - rmse: 0.8626 - val_loss: 0.6203 - val_cat_acc: 0.4919 - val_accuracy: 0.0565 - val_mse: 0.7438 - val_rmse: 0.8624 - 1s/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "800/800 - 1s - loss: 0.6183 - cat_acc: 0.4908 - accuracy: 0.0558 - mse: 0.7442 - rmse: 0.8627 - val_loss: 0.6197 - val_cat_acc: 0.4911 - val_accuracy: 0.0580 - val_mse: 0.7445 - val_rmse: 0.8628 - 1s/epoch - 1ms/step\n",
      "Epoch 79/100\n",
      "800/800 - 1s - loss: 0.6182 - cat_acc: 0.4907 - accuracy: 0.0567 - mse: 0.7442 - rmse: 0.8627 - val_loss: 0.6191 - val_cat_acc: 0.4913 - val_accuracy: 0.0568 - val_mse: 0.7445 - val_rmse: 0.8629 - 1s/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "800/800 - 1s - loss: 0.6181 - cat_acc: 0.4907 - accuracy: 0.0569 - mse: 0.7443 - rmse: 0.8627 - val_loss: 0.6195 - val_cat_acc: 0.4913 - val_accuracy: 0.0578 - val_mse: 0.7443 - val_rmse: 0.8627 - 1s/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "800/800 - 1s - loss: 0.6180 - cat_acc: 0.4907 - accuracy: 0.0578 - mse: 0.7444 - rmse: 0.8628 - val_loss: 0.6193 - val_cat_acc: 0.4913 - val_accuracy: 0.0567 - val_mse: 0.7445 - val_rmse: 0.8629 - 1s/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "800/800 - 1s - loss: 0.6180 - cat_acc: 0.4907 - accuracy: 0.0582 - mse: 0.7445 - rmse: 0.8628 - val_loss: 0.6201 - val_cat_acc: 0.4920 - val_accuracy: 0.0593 - val_mse: 0.7440 - val_rmse: 0.8625 - 1s/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "800/800 - 1s - loss: 0.6179 - cat_acc: 0.4909 - accuracy: 0.0591 - mse: 0.7445 - rmse: 0.8628 - val_loss: 0.6198 - val_cat_acc: 0.4901 - val_accuracy: 0.0600 - val_mse: 0.7451 - val_rmse: 0.8632 - 1s/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "800/800 - 1s - loss: 0.6179 - cat_acc: 0.4906 - accuracy: 0.0594 - mse: 0.7447 - rmse: 0.8629 - val_loss: 0.6194 - val_cat_acc: 0.4918 - val_accuracy: 0.0622 - val_mse: 0.7448 - val_rmse: 0.8630 - 1s/epoch - 1ms/step\n",
      "Epoch 84: early stopping\n",
      "3125/3125 [==============================] - 3s 991us/step\n",
      "INFO:tensorflow:Assets written to: ram://8b0eda17-2fd9-4bda-8d50-b62a1cd871aa/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://8b0eda17-2fd9-4bda-8d50-b62a1cd871aa/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 1.1184 - cat_acc: 0.4894 - accuracy: 0.0000e+00 - mse: 0.2452 - rmse: 0.4951 - val_loss: 0.9498 - val_cat_acc: 0.4963 - val_accuracy: 0.0000e+00 - val_mse: 0.3416 - val_rmse: 0.5845 - 2s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.9055 - cat_acc: 0.4972 - accuracy: 0.0000e+00 - mse: 0.4397 - rmse: 0.6631 - val_loss: 0.8801 - val_cat_acc: 0.4970 - val_accuracy: 0.0000e+00 - val_mse: 0.5190 - val_rmse: 0.7204 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 2s - loss: 0.8658 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.5679 - rmse: 0.7536 - val_loss: 0.8580 - val_cat_acc: 0.4970 - val_accuracy: 0.0000e+00 - val_mse: 0.6093 - val_rmse: 0.7806 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.8506 - cat_acc: 0.4975 - accuracy: 0.0000e+00 - mse: 0.6358 - rmse: 0.7974 - val_loss: 0.8477 - val_cat_acc: 0.4972 - val_accuracy: 0.0000e+00 - val_mse: 0.6598 - val_rmse: 0.8123 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.8427 - cat_acc: 0.4975 - accuracy: 0.0000e+00 - mse: 0.6742 - rmse: 0.8211 - val_loss: 0.8416 - val_cat_acc: 0.4972 - val_accuracy: 0.0000e+00 - val_mse: 0.6874 - val_rmse: 0.8291 - 1s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.8343 - cat_acc: 0.4966 - accuracy: 0.0000e+00 - mse: 0.6794 - rmse: 0.8243 - val_loss: 0.8237 - val_cat_acc: 0.4942 - val_accuracy: 0.0000e+00 - val_mse: 0.6510 - val_rmse: 0.8068 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.8005 - cat_acc: 0.4936 - accuracy: 0.0000e+00 - mse: 0.6273 - rmse: 0.7920 - val_loss: 0.7838 - val_cat_acc: 0.4929 - val_accuracy: 0.0000e+00 - val_mse: 0.6224 - val_rmse: 0.7889 - 1s/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.7648 - cat_acc: 0.4938 - accuracy: 0.0000e+00 - mse: 0.6238 - rmse: 0.7898 - val_loss: 0.7498 - val_cat_acc: 0.4927 - val_accuracy: 0.0000e+00 - val_mse: 0.6243 - val_rmse: 0.7902 - 1s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.7313 - cat_acc: 0.4904 - accuracy: 0.0000e+00 - mse: 0.6245 - rmse: 0.7902 - val_loss: 0.7196 - val_cat_acc: 0.4896 - val_accuracy: 0.0000e+00 - val_mse: 0.6298 - val_rmse: 0.7936 - 1s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.7075 - cat_acc: 0.4887 - accuracy: 0.0000e+00 - mse: 0.6362 - rmse: 0.7976 - val_loss: 0.7009 - val_cat_acc: 0.4884 - val_accuracy: 0.0000e+00 - val_mse: 0.6443 - val_rmse: 0.8027 - 1s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.6918 - cat_acc: 0.4879 - accuracy: 0.0000e+00 - mse: 0.6503 - rmse: 0.8064 - val_loss: 0.6874 - val_cat_acc: 0.4877 - val_accuracy: 0.0000e+00 - val_mse: 0.6573 - val_rmse: 0.8108 - 1s/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.6801 - cat_acc: 0.4881 - accuracy: 0.0000e+00 - mse: 0.6624 - rmse: 0.8139 - val_loss: 0.6772 - val_cat_acc: 0.4881 - val_accuracy: 0.0000e+00 - val_mse: 0.6677 - val_rmse: 0.8172 - 1s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.6710 - cat_acc: 0.4883 - accuracy: 0.0000e+00 - mse: 0.6729 - rmse: 0.8203 - val_loss: 0.6691 - val_cat_acc: 0.4878 - val_accuracy: 0.0000e+00 - val_mse: 0.6773 - val_rmse: 0.8230 - 1s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.6636 - cat_acc: 0.4882 - accuracy: 0.0000e+00 - mse: 0.6816 - rmse: 0.8256 - val_loss: 0.6634 - val_cat_acc: 0.4893 - val_accuracy: 0.0000e+00 - val_mse: 0.6854 - val_rmse: 0.8279 - 1s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.6576 - cat_acc: 0.4888 - accuracy: 0.0000e+00 - mse: 0.6891 - rmse: 0.8301 - val_loss: 0.6577 - val_cat_acc: 0.4875 - val_accuracy: 0.0000e+00 - val_mse: 0.6924 - val_rmse: 0.8321 - 1s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.6526 - cat_acc: 0.4885 - accuracy: 0.0000e+00 - mse: 0.6956 - rmse: 0.8340 - val_loss: 0.6525 - val_cat_acc: 0.4894 - val_accuracy: 0.0000e+00 - val_mse: 0.6979 - val_rmse: 0.8354 - 1s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.6486 - cat_acc: 0.4887 - accuracy: 0.0000e+00 - mse: 0.7010 - rmse: 0.8373 - val_loss: 0.6485 - val_cat_acc: 0.4891 - val_accuracy: 0.0000e+00 - val_mse: 0.7033 - val_rmse: 0.8386 - 1s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.6451 - cat_acc: 0.4888 - accuracy: 0.0000e+00 - mse: 0.7059 - rmse: 0.8402 - val_loss: 0.6454 - val_cat_acc: 0.4890 - val_accuracy: 0.0000e+00 - val_mse: 0.7072 - val_rmse: 0.8410 - 1s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.6423 - cat_acc: 0.4892 - accuracy: 0.0000e+00 - mse: 0.7097 - rmse: 0.8424 - val_loss: 0.6435 - val_cat_acc: 0.4893 - val_accuracy: 0.0000e+00 - val_mse: 0.7096 - val_rmse: 0.8424 - 1s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.6398 - cat_acc: 0.4892 - accuracy: 5.3125e-05 - mse: 0.7131 - rmse: 0.8445 - val_loss: 0.6404 - val_cat_acc: 0.4898 - val_accuracy: 7.5000e-05 - val_mse: 0.7138 - val_rmse: 0.8449 - 1s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.6375 - cat_acc: 0.4892 - accuracy: 1.3438e-04 - mse: 0.7161 - rmse: 0.8462 - val_loss: 0.6385 - val_cat_acc: 0.4902 - val_accuracy: 1.1250e-04 - val_mse: 0.7167 - val_rmse: 0.8466 - 1s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.6358 - cat_acc: 0.4894 - accuracy: 2.3437e-04 - mse: 0.7187 - rmse: 0.8478 - val_loss: 0.6368 - val_cat_acc: 0.4891 - val_accuracy: 2.0000e-04 - val_mse: 0.7205 - val_rmse: 0.8488 - 1s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.6342 - cat_acc: 0.4893 - accuracy: 4.1875e-04 - mse: 0.7209 - rmse: 0.8490 - val_loss: 0.6353 - val_cat_acc: 0.4901 - val_accuracy: 4.7500e-04 - val_mse: 0.7218 - val_rmse: 0.8496 - 1s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.6328 - cat_acc: 0.4895 - accuracy: 7.0625e-04 - mse: 0.7229 - rmse: 0.8502 - val_loss: 0.6337 - val_cat_acc: 0.4900 - val_accuracy: 8.2500e-04 - val_mse: 0.7230 - val_rmse: 0.8503 - 1s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.6316 - cat_acc: 0.4894 - accuracy: 0.0011 - mse: 0.7247 - rmse: 0.8513 - val_loss: 0.6324 - val_cat_acc: 0.4906 - val_accuracy: 0.0014 - val_mse: 0.7246 - val_rmse: 0.8512 - 1s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.6305 - cat_acc: 0.4897 - accuracy: 0.0015 - mse: 0.7261 - rmse: 0.8521 - val_loss: 0.6314 - val_cat_acc: 0.4907 - val_accuracy: 0.0019 - val_mse: 0.7256 - val_rmse: 0.8518 - 1s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.6297 - cat_acc: 0.4897 - accuracy: 0.0021 - mse: 0.7274 - rmse: 0.8529 - val_loss: 0.6311 - val_cat_acc: 0.4907 - val_accuracy: 0.0026 - val_mse: 0.7277 - val_rmse: 0.8530 - 1s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.6289 - cat_acc: 0.4898 - accuracy: 0.0028 - mse: 0.7286 - rmse: 0.8536 - val_loss: 0.6303 - val_cat_acc: 0.4889 - val_accuracy: 0.0029 - val_mse: 0.7297 - val_rmse: 0.8542 - 1s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.6281 - cat_acc: 0.4897 - accuracy: 0.0035 - mse: 0.7300 - rmse: 0.8544 - val_loss: 0.6296 - val_cat_acc: 0.4910 - val_accuracy: 0.0045 - val_mse: 0.7292 - val_rmse: 0.8539 - 1s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.6275 - cat_acc: 0.4898 - accuracy: 0.0045 - mse: 0.7306 - rmse: 0.8548 - val_loss: 0.6288 - val_cat_acc: 0.4904 - val_accuracy: 0.0053 - val_mse: 0.7300 - val_rmse: 0.8544 - 1s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.6269 - cat_acc: 0.4898 - accuracy: 0.0056 - mse: 0.7315 - rmse: 0.8553 - val_loss: 0.6282 - val_cat_acc: 0.4909 - val_accuracy: 0.0070 - val_mse: 0.7305 - val_rmse: 0.8547 - 1s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.6262 - cat_acc: 0.4900 - accuracy: 0.0067 - mse: 0.7324 - rmse: 0.8558 - val_loss: 0.6276 - val_cat_acc: 0.4897 - val_accuracy: 0.0072 - val_mse: 0.7322 - val_rmse: 0.8557 - 1s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.6256 - cat_acc: 0.4900 - accuracy: 0.0078 - mse: 0.7330 - rmse: 0.8562 - val_loss: 0.6269 - val_cat_acc: 0.4910 - val_accuracy: 0.0086 - val_mse: 0.7327 - val_rmse: 0.8560 - 1s/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.6252 - cat_acc: 0.4901 - accuracy: 0.0090 - mse: 0.7336 - rmse: 0.8565 - val_loss: 0.6266 - val_cat_acc: 0.4900 - val_accuracy: 0.0095 - val_mse: 0.7339 - val_rmse: 0.8567 - 1s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.6249 - cat_acc: 0.4899 - accuracy: 0.0102 - mse: 0.7345 - rmse: 0.8570 - val_loss: 0.6260 - val_cat_acc: 0.4908 - val_accuracy: 0.0115 - val_mse: 0.7339 - val_rmse: 0.8567 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.6244 - cat_acc: 0.4901 - accuracy: 0.0116 - mse: 0.7349 - rmse: 0.8573 - val_loss: 0.6264 - val_cat_acc: 0.4891 - val_accuracy: 0.0120 - val_mse: 0.7349 - val_rmse: 0.8573 - 1s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.6241 - cat_acc: 0.4901 - accuracy: 0.0128 - mse: 0.7355 - rmse: 0.8576 - val_loss: 0.6257 - val_cat_acc: 0.4897 - val_accuracy: 0.0138 - val_mse: 0.7355 - val_rmse: 0.8576 - 1s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.6237 - cat_acc: 0.4900 - accuracy: 0.0142 - mse: 0.7360 - rmse: 0.8579 - val_loss: 0.6251 - val_cat_acc: 0.4906 - val_accuracy: 0.0158 - val_mse: 0.7356 - val_rmse: 0.8577 - 1s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.6234 - cat_acc: 0.4903 - accuracy: 0.0156 - mse: 0.7362 - rmse: 0.8580 - val_loss: 0.6245 - val_cat_acc: 0.4904 - val_accuracy: 0.0162 - val_mse: 0.7364 - val_rmse: 0.8582 - 1s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.6231 - cat_acc: 0.4901 - accuracy: 0.0172 - mse: 0.7369 - rmse: 0.8584 - val_loss: 0.6246 - val_cat_acc: 0.4902 - val_accuracy: 0.0181 - val_mse: 0.7371 - val_rmse: 0.8585 - 1s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.6228 - cat_acc: 0.4902 - accuracy: 0.0185 - mse: 0.7372 - rmse: 0.8586 - val_loss: 0.6242 - val_cat_acc: 0.4909 - val_accuracy: 0.0214 - val_mse: 0.7365 - val_rmse: 0.8582 - 1s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.6226 - cat_acc: 0.4902 - accuracy: 0.0202 - mse: 0.7374 - rmse: 0.8587 - val_loss: 0.6236 - val_cat_acc: 0.4913 - val_accuracy: 0.0227 - val_mse: 0.7367 - val_rmse: 0.8583 - 1s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.6223 - cat_acc: 0.4902 - accuracy: 0.0215 - mse: 0.7379 - rmse: 0.8590 - val_loss: 0.6235 - val_cat_acc: 0.4907 - val_accuracy: 0.0217 - val_mse: 0.7382 - val_rmse: 0.8592 - 1s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.6220 - cat_acc: 0.4903 - accuracy: 0.0229 - mse: 0.7382 - rmse: 0.8592 - val_loss: 0.6237 - val_cat_acc: 0.4902 - val_accuracy: 0.0230 - val_mse: 0.7384 - val_rmse: 0.8593 - 1s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.6219 - cat_acc: 0.4904 - accuracy: 0.0240 - mse: 0.7387 - rmse: 0.8595 - val_loss: 0.6228 - val_cat_acc: 0.4913 - val_accuracy: 0.0252 - val_mse: 0.7386 - val_rmse: 0.8594 - 1s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.6217 - cat_acc: 0.4903 - accuracy: 0.0254 - mse: 0.7389 - rmse: 0.8596 - val_loss: 0.6231 - val_cat_acc: 0.4904 - val_accuracy: 0.0265 - val_mse: 0.7390 - val_rmse: 0.8596 - 1s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 2s - loss: 0.6215 - cat_acc: 0.4903 - accuracy: 0.0268 - mse: 0.7393 - rmse: 0.8598 - val_loss: 0.6227 - val_cat_acc: 0.4910 - val_accuracy: 0.0299 - val_mse: 0.7383 - val_rmse: 0.8592 - 2s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 4s - loss: 0.6214 - cat_acc: 0.4903 - accuracy: 0.0280 - mse: 0.7394 - rmse: 0.8599 - val_loss: 0.6223 - val_cat_acc: 0.4906 - val_accuracy: 0.0291 - val_mse: 0.7393 - val_rmse: 0.8598 - 4s/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 2s - loss: 0.6211 - cat_acc: 0.4904 - accuracy: 0.0292 - mse: 0.7396 - rmse: 0.8600 - val_loss: 0.6223 - val_cat_acc: 0.4912 - val_accuracy: 0.0316 - val_mse: 0.7393 - val_rmse: 0.8598 - 2s/epoch - 3ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.6209 - cat_acc: 0.4904 - accuracy: 0.0304 - mse: 0.7400 - rmse: 0.8602 - val_loss: 0.6226 - val_cat_acc: 0.4906 - val_accuracy: 0.0310 - val_mse: 0.7394 - val_rmse: 0.8599 - 1s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.6208 - cat_acc: 0.4904 - accuracy: 0.0318 - mse: 0.7403 - rmse: 0.8604 - val_loss: 0.6219 - val_cat_acc: 0.4902 - val_accuracy: 0.0328 - val_mse: 0.7406 - val_rmse: 0.8606 - 1s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.6206 - cat_acc: 0.4904 - accuracy: 0.0329 - mse: 0.7402 - rmse: 0.8604 - val_loss: 0.6217 - val_cat_acc: 0.4900 - val_accuracy: 0.0313 - val_mse: 0.7412 - val_rmse: 0.8609 - 1s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.6205 - cat_acc: 0.4904 - accuracy: 0.0340 - mse: 0.7405 - rmse: 0.8605 - val_loss: 0.6225 - val_cat_acc: 0.4898 - val_accuracy: 0.0333 - val_mse: 0.7406 - val_rmse: 0.8606 - 1s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.6203 - cat_acc: 0.4904 - accuracy: 0.0352 - mse: 0.7407 - rmse: 0.8606 - val_loss: 0.6219 - val_cat_acc: 0.4898 - val_accuracy: 0.0346 - val_mse: 0.7413 - val_rmse: 0.8610 - 1s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.6202 - cat_acc: 0.4907 - accuracy: 0.0364 - mse: 0.7410 - rmse: 0.8608 - val_loss: 0.6214 - val_cat_acc: 0.4902 - val_accuracy: 0.0368 - val_mse: 0.7411 - val_rmse: 0.8609 - 1s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.6201 - cat_acc: 0.4905 - accuracy: 0.0372 - mse: 0.7412 - rmse: 0.8609 - val_loss: 0.6211 - val_cat_acc: 0.4910 - val_accuracy: 0.0381 - val_mse: 0.7414 - val_rmse: 0.8610 - 1s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.6199 - cat_acc: 0.4907 - accuracy: 0.0383 - mse: 0.7413 - rmse: 0.8610 - val_loss: 0.6213 - val_cat_acc: 0.4900 - val_accuracy: 0.0381 - val_mse: 0.7414 - val_rmse: 0.8610 - 1s/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.6199 - cat_acc: 0.4905 - accuracy: 0.0391 - mse: 0.7418 - rmse: 0.8612 - val_loss: 0.6209 - val_cat_acc: 0.4911 - val_accuracy: 0.0422 - val_mse: 0.7414 - val_rmse: 0.8611 - 1s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.6198 - cat_acc: 0.4905 - accuracy: 0.0405 - mse: 0.7418 - rmse: 0.8613 - val_loss: 0.6207 - val_cat_acc: 0.4913 - val_accuracy: 0.0411 - val_mse: 0.7413 - val_rmse: 0.8610 - 1s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.6197 - cat_acc: 0.4906 - accuracy: 0.0415 - mse: 0.7418 - rmse: 0.8613 - val_loss: 0.6206 - val_cat_acc: 0.4913 - val_accuracy: 0.0418 - val_mse: 0.7414 - val_rmse: 0.8611 - 1s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.6195 - cat_acc: 0.4905 - accuracy: 0.0423 - mse: 0.7419 - rmse: 0.8613 - val_loss: 0.6207 - val_cat_acc: 0.4909 - val_accuracy: 0.0442 - val_mse: 0.7425 - val_rmse: 0.8617 - 1s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 1s - loss: 0.6194 - cat_acc: 0.4905 - accuracy: 0.0432 - mse: 0.7422 - rmse: 0.8615 - val_loss: 0.6203 - val_cat_acc: 0.4906 - val_accuracy: 0.0440 - val_mse: 0.7429 - val_rmse: 0.8619 - 1s/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 1s - loss: 0.6193 - cat_acc: 0.4908 - accuracy: 0.0439 - mse: 0.7423 - rmse: 0.8616 - val_loss: 0.6204 - val_cat_acc: 0.4906 - val_accuracy: 0.0444 - val_mse: 0.7424 - val_rmse: 0.8617 - 1s/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 1s - loss: 0.6193 - cat_acc: 0.4905 - accuracy: 0.0449 - mse: 0.7426 - rmse: 0.8617 - val_loss: 0.6209 - val_cat_acc: 0.4909 - val_accuracy: 0.0478 - val_mse: 0.7421 - val_rmse: 0.8614 - 1s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 1s - loss: 0.6191 - cat_acc: 0.4906 - accuracy: 0.0461 - mse: 0.7425 - rmse: 0.8617 - val_loss: 0.6204 - val_cat_acc: 0.4908 - val_accuracy: 0.0464 - val_mse: 0.7432 - val_rmse: 0.8621 - 1s/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "800/800 - 1s - loss: 0.6191 - cat_acc: 0.4907 - accuracy: 0.0467 - mse: 0.7426 - rmse: 0.8618 - val_loss: 0.6207 - val_cat_acc: 0.4897 - val_accuracy: 0.0467 - val_mse: 0.7434 - val_rmse: 0.8622 - 1s/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "800/800 - 1s - loss: 0.6189 - cat_acc: 0.4905 - accuracy: 0.0471 - mse: 0.7430 - rmse: 0.8620 - val_loss: 0.6203 - val_cat_acc: 0.4913 - val_accuracy: 0.0523 - val_mse: 0.7428 - val_rmse: 0.8618 - 1s/epoch - 1ms/step\n",
      "Epoch 67: early stopping\n",
      "3125/3125 [==============================] - 3s 936us/step\n",
      "INFO:tensorflow:Assets written to: ram://81caa298-92e9-4dec-98cf-fcf27d8be857/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://81caa298-92e9-4dec-98cf-fcf27d8be857/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 neuron in [1, 10, 100]\n",
      "Training for 1 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.6690 - cat_acc: 0.9647 - accuracy: 0.0000e+00 - mse: 0.3413 - rmse: 0.5843 - val_loss: 0.4185 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.5523 - val_rmse: 0.7432 - 2s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.3832 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.6562 - rmse: 0.8101 - val_loss: 0.3713 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7066 - val_rmse: 0.8406 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.3655 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7219 - rmse: 0.8496 - val_loss: 0.3649 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7342 - val_rmse: 0.8568 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3617 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7391 - rmse: 0.8597 - val_loss: 0.3626 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7447 - val_rmse: 0.8630 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3600 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7465 - rmse: 0.8640 - val_loss: 0.3614 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7497 - val_rmse: 0.8659 - 1s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.3591 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7502 - rmse: 0.8662 - val_loss: 0.3606 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7525 - val_rmse: 0.8675 - 1s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3584 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7524 - rmse: 0.8674 - val_loss: 0.3600 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7542 - val_rmse: 0.8684 - 1s/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3578 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7538 - rmse: 0.8682 - val_loss: 0.3595 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7553 - val_rmse: 0.8691 - 1s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.3574 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7546 - rmse: 0.8687 - val_loss: 0.3591 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7559 - val_rmse: 0.8695 - 1s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3570 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7552 - rmse: 0.8690 - val_loss: 0.3588 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7565 - val_rmse: 0.8697 - 1s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3567 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7556 - rmse: 0.8693 - val_loss: 0.3586 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7568 - val_rmse: 0.8700 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3565 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7560 - rmse: 0.8695 - val_loss: 0.3584 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7571 - val_rmse: 0.8701 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7562 - rmse: 0.8696 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7573 - val_rmse: 0.8702 - 1s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 3.1250e-06 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 1.2500e-05 - mse: 0.7566 - rmse: 0.8698 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 1.0000e-04 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 7.5000e-05 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 1.2500e-04 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 2.1562e-04 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 2.0000e-04 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 5.8437e-04 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0012 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0010 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0023 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0015 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0029 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0024 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0012 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0035 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0025 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0044 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0043 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0057 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0074 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0074 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0070 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0091 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0093 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0103 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0076 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0097 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0095 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 2s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0121 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0162 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 2s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0248 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0149 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0170 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0171 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0228 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0286 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0287 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0273 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0275 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0280 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0242 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0318 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0360 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0320 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0327 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0558 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0487 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0519 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0390 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0320 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0437 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0316 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0505 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0393 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0472 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0375 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0399 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0362 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0399 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0358 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0389 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0568 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0636 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0720 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0569 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0404 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0475 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0425 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0498 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0942 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0825 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0659 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0577 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0544 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0494 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0727 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0852 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0681 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0594 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0516 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0656 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0649 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0599 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0840 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0762 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0872 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0677 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0671 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0831 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0834 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0681 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0752 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0729 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0809 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0707 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0709 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0621 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0799 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0821 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0729 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0738 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0716 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0914 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1088 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0854 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0930 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0748 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0639 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0833 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0633 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0766 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0947 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0875 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0754 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0922 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0739 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0749 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0785 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0993 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1294 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.1170 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1019 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0850 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3573 - val_cat_acc: 0.9918 - val_accuracy: 0.0712 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 77/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0831 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0741 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0802 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1313 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.1111 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0938 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 80/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0788 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0873 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0829 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3573 - val_cat_acc: 0.9918 - val_accuracy: 0.0710 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0974 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3573 - val_cat_acc: 0.9918 - val_accuracy: 0.0897 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0868 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3573 - val_cat_acc: 0.9918 - val_accuracy: 0.0716 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0935 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1019 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.1060 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1112 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.1139 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1681 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.1495 - mse: 0.7572 - rmse: 0.8702 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1265 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 87: early stopping\n",
      "3125/3125 [==============================] - 3s 910us/step\n",
      "INFO:tensorflow:Assets written to: ram://76322b03-4265-49e5-a434-2f9936a0e072/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://76322b03-4265-49e5-a434-2f9936a0e072/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.6549 - cat_acc: 0.9675 - accuracy: 0.0000e+00 - mse: 0.3436 - rmse: 0.5862 - val_loss: 0.4256 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.5384 - val_rmse: 0.7338 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.3911 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.6285 - rmse: 0.7928 - val_loss: 0.3754 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.6877 - val_rmse: 0.8293 - 1s/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.3681 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7091 - rmse: 0.8421 - val_loss: 0.3665 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7257 - val_rmse: 0.8519 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3628 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7326 - rmse: 0.8559 - val_loss: 0.3634 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7399 - val_rmse: 0.8602 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3607 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7426 - rmse: 0.8617 - val_loss: 0.3619 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7467 - val_rmse: 0.8641 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.3595 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7477 - rmse: 0.8647 - val_loss: 0.3610 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7505 - val_rmse: 0.8663 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3587 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7506 - rmse: 0.8664 - val_loss: 0.3603 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7528 - val_rmse: 0.8676 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3581 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7524 - rmse: 0.8674 - val_loss: 0.3597 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7542 - val_rmse: 0.8684 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.3576 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7536 - rmse: 0.8681 - val_loss: 0.3593 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7552 - val_rmse: 0.8690 - 1s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3572 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7545 - rmse: 0.8686 - val_loss: 0.3590 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7559 - val_rmse: 0.8695 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3569 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7552 - rmse: 0.8690 - val_loss: 0.3587 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7565 - val_rmse: 0.8697 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3566 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7556 - rmse: 0.8693 - val_loss: 0.3585 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7568 - val_rmse: 0.8700 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3564 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7560 - rmse: 0.8695 - val_loss: 0.3583 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7572 - val_rmse: 0.8702 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7562 - rmse: 0.8696 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 6.2500e-06 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 9.3750e-06 - mse: 0.7566 - rmse: 0.8698 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 5.3125e-05 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 1.5000e-04 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 2.0625e-04 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 1.2500e-04 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 5.8125e-04 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 7.7500e-04 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0010 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0022 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0017 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0013 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0025 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0020 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0038 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0029 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0045 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0074 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0110 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0076 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0077 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0060 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0089 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0091 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0099 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0074 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0103 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0107 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0151 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0153 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0142 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0250 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0180 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0179 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0203 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0300 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0237 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0261 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0192 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0476 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0279 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0238 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0198 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0163 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0256 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0450 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0391 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0385 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0285 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0444 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0313 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0310 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0343 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0300 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0264 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0358 - val_mse: 0.7572 - val_rmse: 0.8702 - 1s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0633 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0375 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0399 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0320 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0357 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0371 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0462 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0312 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0286 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0586 - val_mse: 0.7567 - val_rmse: 0.8699 - 1s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0668 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0408 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0418 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0321 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0355 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0652 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0685 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0463 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0407 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0406 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0404 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0349 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0471 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0303 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0495 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0550 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0645 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0707 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0575 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0602 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0599 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0849 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0631 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0477 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0417 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0362 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0802 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0730 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0574 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0591 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0826 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0947 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0733 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0663 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0601 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0452 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0526 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0743 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0712 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0721 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0812 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0944 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0724 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0668 - val_mse: 0.7575 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0732 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1355 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0991 - mse: 0.7572 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0701 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0680 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0674 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0623 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0849 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0970 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0800 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0790 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1202 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0875 - mse: 0.7572 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0808 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0894 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0960 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 78: early stopping\n",
      "3125/3125 [==============================] - 3s 948us/step\n",
      "INFO:tensorflow:Assets written to: ram://bda39e29-8676-4e34-b10e-a6abd683293e/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://bda39e29-8676-4e34-b10e-a6abd683293e/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100 neuron in [1, 10, 100]\n",
      "Training for 1 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.4542 - cat_acc: 0.9798 - accuracy: 0.0000e+00 - mse: 0.6230 - rmse: 0.7893 - val_loss: 0.3639 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7472 - val_rmse: 0.8644 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 2s - loss: 0.3607 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7509 - rmse: 0.8666 - val_loss: 0.3619 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7543 - val_rmse: 0.8685 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.3595 - cat_acc: 0.9928 - accuracy: 3.1250e-06 - mse: 0.7541 - rmse: 0.8684 - val_loss: 0.3611 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7558 - val_rmse: 0.8694 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3588 - cat_acc: 0.9928 - accuracy: 2.1875e-05 - mse: 0.7549 - rmse: 0.8688 - val_loss: 0.3604 - val_cat_acc: 0.9918 - val_accuracy: 5.0000e-05 - val_mse: 0.7562 - val_rmse: 0.8696 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3583 - cat_acc: 0.9928 - accuracy: 9.0625e-05 - mse: 0.7552 - rmse: 0.8691 - val_loss: 0.3600 - val_cat_acc: 0.9918 - val_accuracy: 1.6250e-04 - val_mse: 0.7564 - val_rmse: 0.8697 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.3578 - cat_acc: 0.9928 - accuracy: 3.5938e-04 - mse: 0.7556 - rmse: 0.8692 - val_loss: 0.3596 - val_cat_acc: 0.9918 - val_accuracy: 6.8750e-04 - val_mse: 0.7568 - val_rmse: 0.8699 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3575 - cat_acc: 0.9928 - accuracy: 6.4375e-04 - mse: 0.7558 - rmse: 0.8694 - val_loss: 0.3592 - val_cat_acc: 0.9918 - val_accuracy: 0.0010 - val_mse: 0.7568 - val_rmse: 0.8700 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3572 - cat_acc: 0.9928 - accuracy: 9.3125e-04 - mse: 0.7561 - rmse: 0.8695 - val_loss: 0.3590 - val_cat_acc: 0.9918 - val_accuracy: 5.0000e-04 - val_mse: 0.7572 - val_rmse: 0.8701 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.3569 - cat_acc: 0.9928 - accuracy: 0.0016 - mse: 0.7562 - rmse: 0.8696 - val_loss: 0.3587 - val_cat_acc: 0.9918 - val_accuracy: 0.0010 - val_mse: 0.7575 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3567 - cat_acc: 0.9928 - accuracy: 0.0026 - mse: 0.7563 - rmse: 0.8697 - val_loss: 0.3586 - val_cat_acc: 0.9918 - val_accuracy: 0.0034 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3566 - cat_acc: 0.9928 - accuracy: 0.0048 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3584 - val_cat_acc: 0.9918 - val_accuracy: 0.0022 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3564 - cat_acc: 0.9928 - accuracy: 0.0031 - mse: 0.7566 - rmse: 0.8698 - val_loss: 0.3583 - val_cat_acc: 0.9918 - val_accuracy: 0.0040 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0046 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0034 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0047 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0030 - val_mse: 0.7579 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0072 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0062 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0086 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0067 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0097 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0162 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0157 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0166 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0143 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0092 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0211 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0221 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0154 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0166 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0134 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0110 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0196 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0179 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 2s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0516 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0825 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0503 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0368 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0429 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0406 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0358 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3585 - val_cat_acc: 0.9918 - val_accuracy: 0.0571 - val_mse: 0.7561 - val_rmse: 0.8695 - 1s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0393 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0181 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0183 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0173 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0295 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0248 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0342 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0203 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0188 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3607 - val_cat_acc: 0.9915 - val_accuracy: 0.1094 - val_mse: 0.7562 - val_rmse: 0.8696 - 1s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.1158 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.1011 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0825 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0640 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0573 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0431 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0501 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0520 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0329 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0345 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0339 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0283 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 2s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0282 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0688 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 39: early stopping\n",
      "3125/3125 [==============================] - 3s 943us/step\n",
      "INFO:tensorflow:Assets written to: ram://26fd280a-a207-4ac1-a145-b979d7e2c001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://26fd280a-a207-4ac1-a145-b979d7e2c001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 7s - loss: 0.4581 - cat_acc: 0.9751 - accuracy: 0.0000e+00 - mse: 0.6212 - rmse: 0.7882 - val_loss: 0.3639 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7476 - val_rmse: 0.8646 - 7s/epoch - 9ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 3s - loss: 0.3607 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7510 - rmse: 0.8666 - val_loss: 0.3619 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7544 - val_rmse: 0.8686 - 3s/epoch - 4ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 3s - loss: 0.3595 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7541 - rmse: 0.8684 - val_loss: 0.3611 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7558 - val_rmse: 0.8694 - 3s/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 2s - loss: 0.3588 - cat_acc: 0.9928 - accuracy: 2.1875e-05 - mse: 0.7549 - rmse: 0.8688 - val_loss: 0.3604 - val_cat_acc: 0.9918 - val_accuracy: 5.0000e-05 - val_mse: 0.7563 - val_rmse: 0.8696 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3582 - cat_acc: 0.9928 - accuracy: 7.5000e-05 - mse: 0.7553 - rmse: 0.8691 - val_loss: 0.3600 - val_cat_acc: 0.9918 - val_accuracy: 5.1250e-04 - val_mse: 0.7560 - val_rmse: 0.8695 - 1s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.3578 - cat_acc: 0.9928 - accuracy: 2.1250e-04 - mse: 0.7556 - rmse: 0.8692 - val_loss: 0.3596 - val_cat_acc: 0.9918 - val_accuracy: 3.0000e-04 - val_mse: 0.7567 - val_rmse: 0.8699 - 1s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3575 - cat_acc: 0.9928 - accuracy: 5.5000e-04 - mse: 0.7558 - rmse: 0.8694 - val_loss: 0.3593 - val_cat_acc: 0.9918 - val_accuracy: 0.0014 - val_mse: 0.7568 - val_rmse: 0.8700 - 1s/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3572 - cat_acc: 0.9928 - accuracy: 0.0012 - mse: 0.7561 - rmse: 0.8695 - val_loss: 0.3591 - val_cat_acc: 0.9918 - val_accuracy: 0.0021 - val_mse: 0.7567 - val_rmse: 0.8699 - 1s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.3570 - cat_acc: 0.9928 - accuracy: 0.0020 - mse: 0.7562 - rmse: 0.8696 - val_loss: 0.3588 - val_cat_acc: 0.9918 - val_accuracy: 0.0015 - val_mse: 0.7573 - val_rmse: 0.8702 - 1s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3567 - cat_acc: 0.9928 - accuracy: 0.0032 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3586 - val_cat_acc: 0.9918 - val_accuracy: 0.0023 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3566 - cat_acc: 0.9928 - accuracy: 0.0030 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3586 - val_cat_acc: 0.9918 - val_accuracy: 0.0069 - val_mse: 0.7571 - val_rmse: 0.8701 - 1s/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3565 - cat_acc: 0.9928 - accuracy: 0.0058 - mse: 0.7566 - rmse: 0.8698 - val_loss: 0.3585 - val_cat_acc: 0.9918 - val_accuracy: 0.0031 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0050 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0019 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 2s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0089 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0072 - val_mse: 0.7579 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0088 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0046 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0090 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0081 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0119 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0084 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0136 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0122 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0126 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0084 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0213 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0276 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0243 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0215 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0257 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0608 - val_mse: 0.7575 - val_rmse: 0.8704 - 1s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0369 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0214 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0212 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0218 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0498 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0432 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0275 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0146 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0552 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0394 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0338 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0456 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0369 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0267 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0361 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0342 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0289 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3586 - val_cat_acc: 0.9918 - val_accuracy: 0.0400 - val_mse: 0.7577 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0551 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0343 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 2s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0277 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0488 - val_mse: 0.7578 - val_rmse: 0.8705 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0847 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.1445 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 34: early stopping\n",
      "3125/3125 [==============================] - 3s 843us/step\n",
      "INFO:tensorflow:Assets written to: ram://0684adfa-c9f8-4413-b620-a157cb27213b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://0684adfa-c9f8-4413-b620-a157cb27213b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 3 fold of 5 folds\n",
      "Training for 1 neuron in [1, 10, 100]\n",
      "Training for 1 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 1.1189 - cat_acc: 0.4774 - accuracy: 0.0000e+00 - mse: 0.2444 - rmse: 0.4944 - val_loss: 0.9509 - val_cat_acc: 0.4969 - val_accuracy: 0.0000e+00 - val_mse: 0.3400 - val_rmse: 0.5831 - 2s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 2s - loss: 0.9064 - cat_acc: 0.4973 - accuracy: 0.0000e+00 - mse: 0.4374 - rmse: 0.6614 - val_loss: 0.8809 - val_cat_acc: 0.4970 - val_accuracy: 0.0000e+00 - val_mse: 0.5163 - val_rmse: 0.7185 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.8664 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.5658 - rmse: 0.7522 - val_loss: 0.8585 - val_cat_acc: 0.4971 - val_accuracy: 0.0000e+00 - val_mse: 0.6074 - val_rmse: 0.7794 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 2s - loss: 0.8509 - cat_acc: 0.4975 - accuracy: 0.0000e+00 - mse: 0.6343 - rmse: 0.7964 - val_loss: 0.8480 - val_cat_acc: 0.4972 - val_accuracy: 0.0000e+00 - val_mse: 0.6583 - val_rmse: 0.8114 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 2s - loss: 0.8429 - cat_acc: 0.4975 - accuracy: 0.0000e+00 - mse: 0.6734 - rmse: 0.8206 - val_loss: 0.8419 - val_cat_acc: 0.4972 - val_accuracy: 0.0000e+00 - val_mse: 0.6874 - val_rmse: 0.8291 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 2s - loss: 0.8354 - cat_acc: 0.4967 - accuracy: 0.0000e+00 - mse: 0.6821 - rmse: 0.8259 - val_loss: 0.8262 - val_cat_acc: 0.4946 - val_accuracy: 0.0000e+00 - val_mse: 0.6553 - val_rmse: 0.8095 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 2s - loss: 0.8028 - cat_acc: 0.4934 - accuracy: 0.0000e+00 - mse: 0.6296 - rmse: 0.7935 - val_loss: 0.7855 - val_cat_acc: 0.4931 - val_accuracy: 0.0000e+00 - val_mse: 0.6237 - val_rmse: 0.7898 - 2s/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 2s - loss: 0.7668 - cat_acc: 0.4938 - accuracy: 0.0000e+00 - mse: 0.6249 - rmse: 0.7905 - val_loss: 0.7519 - val_cat_acc: 0.4930 - val_accuracy: 0.0000e+00 - val_mse: 0.6254 - val_rmse: 0.7908 - 2s/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 3s - loss: 0.7332 - cat_acc: 0.4910 - accuracy: 0.0000e+00 - mse: 0.6252 - rmse: 0.7907 - val_loss: 0.7209 - val_cat_acc: 0.4894 - val_accuracy: 0.0000e+00 - val_mse: 0.6297 - val_rmse: 0.7935 - 3s/epoch - 4ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 2s - loss: 0.7086 - cat_acc: 0.4886 - accuracy: 0.0000e+00 - mse: 0.6360 - rmse: 0.7975 - val_loss: 0.7021 - val_cat_acc: 0.4886 - val_accuracy: 0.0000e+00 - val_mse: 0.6437 - val_rmse: 0.8023 - 2s/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 2s - loss: 0.6925 - cat_acc: 0.4881 - accuracy: 0.0000e+00 - mse: 0.6497 - rmse: 0.8060 - val_loss: 0.6882 - val_cat_acc: 0.4885 - val_accuracy: 0.0000e+00 - val_mse: 0.6564 - val_rmse: 0.8102 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.6806 - cat_acc: 0.4881 - accuracy: 0.0000e+00 - mse: 0.6619 - rmse: 0.8136 - val_loss: 0.6777 - val_cat_acc: 0.4885 - val_accuracy: 0.0000e+00 - val_mse: 0.6675 - val_rmse: 0.8170 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.6714 - cat_acc: 0.4882 - accuracy: 0.0000e+00 - mse: 0.6723 - rmse: 0.8199 - val_loss: 0.6695 - val_cat_acc: 0.4875 - val_accuracy: 0.0000e+00 - val_mse: 0.6774 - val_rmse: 0.8230 - 1s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.6640 - cat_acc: 0.4883 - accuracy: 0.0000e+00 - mse: 0.6813 - rmse: 0.8254 - val_loss: 0.6629 - val_cat_acc: 0.4891 - val_accuracy: 0.0000e+00 - val_mse: 0.6849 - val_rmse: 0.8276 - 1s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.6581 - cat_acc: 0.4884 - accuracy: 0.0000e+00 - mse: 0.6888 - rmse: 0.8299 - val_loss: 0.6576 - val_cat_acc: 0.4884 - val_accuracy: 0.0000e+00 - val_mse: 0.6925 - val_rmse: 0.8322 - 1s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.6529 - cat_acc: 0.4885 - accuracy: 0.0000e+00 - mse: 0.6953 - rmse: 0.8339 - val_loss: 0.6528 - val_cat_acc: 0.4889 - val_accuracy: 0.0000e+00 - val_mse: 0.6978 - val_rmse: 0.8354 - 1s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.6489 - cat_acc: 0.4885 - accuracy: 0.0000e+00 - mse: 0.7007 - rmse: 0.8371 - val_loss: 0.6489 - val_cat_acc: 0.4895 - val_accuracy: 0.0000e+00 - val_mse: 0.7024 - val_rmse: 0.8381 - 1s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.6453 - cat_acc: 0.4888 - accuracy: 0.0000e+00 - mse: 0.7054 - rmse: 0.8399 - val_loss: 0.6458 - val_cat_acc: 0.4884 - val_accuracy: 0.0000e+00 - val_mse: 0.7078 - val_rmse: 0.8413 - 1s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.6424 - cat_acc: 0.4890 - accuracy: 3.1250e-06 - mse: 0.7094 - rmse: 0.8423 - val_loss: 0.6430 - val_cat_acc: 0.4884 - val_accuracy: 0.0000e+00 - val_mse: 0.7113 - val_rmse: 0.8434 - 1s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.6399 - cat_acc: 0.4889 - accuracy: 6.2500e-05 - mse: 0.7130 - rmse: 0.8444 - val_loss: 0.6405 - val_cat_acc: 0.4895 - val_accuracy: 7.5000e-05 - val_mse: 0.7138 - val_rmse: 0.8449 - 1s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.6377 - cat_acc: 0.4890 - accuracy: 1.2187e-04 - mse: 0.7160 - rmse: 0.8462 - val_loss: 0.6393 - val_cat_acc: 0.4895 - val_accuracy: 1.2500e-04 - val_mse: 0.7177 - val_rmse: 0.8472 - 984ms/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.6358 - cat_acc: 0.4895 - accuracy: 2.4687e-04 - mse: 0.7185 - rmse: 0.8477 - val_loss: 0.6368 - val_cat_acc: 0.4885 - val_accuracy: 2.1250e-04 - val_mse: 0.7202 - val_rmse: 0.8486 - 1s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.6343 - cat_acc: 0.4895 - accuracy: 4.3437e-04 - mse: 0.7208 - rmse: 0.8490 - val_loss: 0.6352 - val_cat_acc: 0.4899 - val_accuracy: 4.7500e-04 - val_mse: 0.7217 - val_rmse: 0.8495 - 1s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.6328 - cat_acc: 0.4896 - accuracy: 6.9062e-04 - mse: 0.7229 - rmse: 0.8502 - val_loss: 0.6339 - val_cat_acc: 0.4913 - val_accuracy: 9.5000e-04 - val_mse: 0.7227 - val_rmse: 0.8501 - 1s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.6318 - cat_acc: 0.4897 - accuracy: 0.0010 - mse: 0.7247 - rmse: 0.8513 - val_loss: 0.6328 - val_cat_acc: 0.4895 - val_accuracy: 0.0012 - val_mse: 0.7253 - val_rmse: 0.8516 - 1s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.6307 - cat_acc: 0.4896 - accuracy: 0.0015 - mse: 0.7261 - rmse: 0.8521 - val_loss: 0.6319 - val_cat_acc: 0.4898 - val_accuracy: 0.0016 - val_mse: 0.7260 - val_rmse: 0.8521 - 1s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.6297 - cat_acc: 0.4897 - accuracy: 0.0021 - mse: 0.7273 - rmse: 0.8528 - val_loss: 0.6308 - val_cat_acc: 0.4893 - val_accuracy: 0.0024 - val_mse: 0.7276 - val_rmse: 0.8530 - 1s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.6289 - cat_acc: 0.4896 - accuracy: 0.0028 - mse: 0.7286 - rmse: 0.8536 - val_loss: 0.6297 - val_cat_acc: 0.4906 - val_accuracy: 0.0033 - val_mse: 0.7280 - val_rmse: 0.8532 - 1s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.6281 - cat_acc: 0.4898 - accuracy: 0.0035 - mse: 0.7295 - rmse: 0.8541 - val_loss: 0.6297 - val_cat_acc: 0.4888 - val_accuracy: 0.0036 - val_mse: 0.7307 - val_rmse: 0.8548 - 957ms/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.6274 - cat_acc: 0.4899 - accuracy: 0.0044 - mse: 0.7306 - rmse: 0.8548 - val_loss: 0.6285 - val_cat_acc: 0.4897 - val_accuracy: 0.0044 - val_mse: 0.7318 - val_rmse: 0.8555 - 1s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.6268 - cat_acc: 0.4895 - accuracy: 0.0054 - mse: 0.7318 - rmse: 0.8555 - val_loss: 0.6283 - val_cat_acc: 0.4909 - val_accuracy: 0.0059 - val_mse: 0.7315 - val_rmse: 0.8553 - 1s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.6263 - cat_acc: 0.4898 - accuracy: 0.0064 - mse: 0.7323 - rmse: 0.8558 - val_loss: 0.6273 - val_cat_acc: 0.4908 - val_accuracy: 0.0075 - val_mse: 0.7318 - val_rmse: 0.8554 - 980ms/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.6257 - cat_acc: 0.4900 - accuracy: 0.0077 - mse: 0.7330 - rmse: 0.8561 - val_loss: 0.6269 - val_cat_acc: 0.4899 - val_accuracy: 0.0084 - val_mse: 0.7328 - val_rmse: 0.8561 - 1s/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.6253 - cat_acc: 0.4902 - accuracy: 0.0089 - mse: 0.7336 - rmse: 0.8565 - val_loss: 0.6264 - val_cat_acc: 0.4899 - val_accuracy: 0.0092 - val_mse: 0.7342 - val_rmse: 0.8568 - 1s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.6249 - cat_acc: 0.4900 - accuracy: 0.0100 - mse: 0.7344 - rmse: 0.8570 - val_loss: 0.6258 - val_cat_acc: 0.4904 - val_accuracy: 0.0108 - val_mse: 0.7342 - val_rmse: 0.8568 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.6244 - cat_acc: 0.4900 - accuracy: 0.0114 - mse: 0.7348 - rmse: 0.8572 - val_loss: 0.6254 - val_cat_acc: 0.4901 - val_accuracy: 0.0120 - val_mse: 0.7351 - val_rmse: 0.8574 - 1s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.6240 - cat_acc: 0.4899 - accuracy: 0.0126 - mse: 0.7353 - rmse: 0.8575 - val_loss: 0.6255 - val_cat_acc: 0.4915 - val_accuracy: 0.0144 - val_mse: 0.7349 - val_rmse: 0.8573 - 998ms/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.6237 - cat_acc: 0.4900 - accuracy: 0.0143 - mse: 0.7357 - rmse: 0.8578 - val_loss: 0.6253 - val_cat_acc: 0.4906 - val_accuracy: 0.0161 - val_mse: 0.7353 - val_rmse: 0.8575 - 1s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.6234 - cat_acc: 0.4902 - accuracy: 0.0156 - mse: 0.7363 - rmse: 0.8581 - val_loss: 0.6249 - val_cat_acc: 0.4897 - val_accuracy: 0.0165 - val_mse: 0.7367 - val_rmse: 0.8583 - 1s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.6231 - cat_acc: 0.4902 - accuracy: 0.0170 - mse: 0.7367 - rmse: 0.8583 - val_loss: 0.6244 - val_cat_acc: 0.4908 - val_accuracy: 0.0168 - val_mse: 0.7376 - val_rmse: 0.8588 - 1s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.6229 - cat_acc: 0.4901 - accuracy: 0.0184 - mse: 0.7372 - rmse: 0.8586 - val_loss: 0.6243 - val_cat_acc: 0.4905 - val_accuracy: 0.0196 - val_mse: 0.7369 - val_rmse: 0.8584 - 1s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.6226 - cat_acc: 0.4902 - accuracy: 0.0196 - mse: 0.7376 - rmse: 0.8588 - val_loss: 0.6239 - val_cat_acc: 0.4904 - val_accuracy: 0.0215 - val_mse: 0.7374 - val_rmse: 0.8587 - 987ms/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.6224 - cat_acc: 0.4901 - accuracy: 0.0214 - mse: 0.7379 - rmse: 0.8590 - val_loss: 0.6233 - val_cat_acc: 0.4909 - val_accuracy: 0.0220 - val_mse: 0.7382 - val_rmse: 0.8592 - 1s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.6221 - cat_acc: 0.4905 - accuracy: 0.0226 - mse: 0.7382 - rmse: 0.8592 - val_loss: 0.6233 - val_cat_acc: 0.4903 - val_accuracy: 0.0218 - val_mse: 0.7388 - val_rmse: 0.8595 - 1s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.6219 - cat_acc: 0.4904 - accuracy: 0.0239 - mse: 0.7384 - rmse: 0.8593 - val_loss: 0.6241 - val_cat_acc: 0.4890 - val_accuracy: 0.0244 - val_mse: 0.7389 - val_rmse: 0.8596 - 1s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.6217 - cat_acc: 0.4905 - accuracy: 0.0253 - mse: 0.7390 - rmse: 0.8596 - val_loss: 0.6227 - val_cat_acc: 0.4903 - val_accuracy: 0.0255 - val_mse: 0.7396 - val_rmse: 0.8600 - 1s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.6214 - cat_acc: 0.4905 - accuracy: 0.0266 - mse: 0.7391 - rmse: 0.8597 - val_loss: 0.6231 - val_cat_acc: 0.4916 - val_accuracy: 0.0291 - val_mse: 0.7385 - val_rmse: 0.8593 - 983ms/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.6214 - cat_acc: 0.4904 - accuracy: 0.0282 - mse: 0.7394 - rmse: 0.8599 - val_loss: 0.6223 - val_cat_acc: 0.4905 - val_accuracy: 0.0287 - val_mse: 0.7400 - val_rmse: 0.8602 - 998ms/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.6212 - cat_acc: 0.4904 - accuracy: 0.0291 - mse: 0.7398 - rmse: 0.8601 - val_loss: 0.6225 - val_cat_acc: 0.4897 - val_accuracy: 0.0288 - val_mse: 0.7405 - val_rmse: 0.8605 - 1s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.6210 - cat_acc: 0.4904 - accuracy: 0.0303 - mse: 0.7400 - rmse: 0.8602 - val_loss: 0.6228 - val_cat_acc: 0.4909 - val_accuracy: 0.0310 - val_mse: 0.7397 - val_rmse: 0.8601 - 995ms/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.6208 - cat_acc: 0.4906 - accuracy: 0.0315 - mse: 0.7403 - rmse: 0.8604 - val_loss: 0.6224 - val_cat_acc: 0.4913 - val_accuracy: 0.0326 - val_mse: 0.7401 - val_rmse: 0.8603 - 1s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.6208 - cat_acc: 0.4904 - accuracy: 0.0329 - mse: 0.7404 - rmse: 0.8604 - val_loss: 0.6218 - val_cat_acc: 0.4903 - val_accuracy: 0.0329 - val_mse: 0.7406 - val_rmse: 0.8606 - 1s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.6205 - cat_acc: 0.4905 - accuracy: 0.0340 - mse: 0.7406 - rmse: 0.8606 - val_loss: 0.6222 - val_cat_acc: 0.4904 - val_accuracy: 0.0336 - val_mse: 0.7408 - val_rmse: 0.8607 - 1s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.6204 - cat_acc: 0.4907 - accuracy: 0.0349 - mse: 0.7410 - rmse: 0.8608 - val_loss: 0.6217 - val_cat_acc: 0.4905 - val_accuracy: 0.0349 - val_mse: 0.7403 - val_rmse: 0.8604 - 1s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.6202 - cat_acc: 0.4904 - accuracy: 0.0359 - mse: 0.7412 - rmse: 0.8609 - val_loss: 0.6223 - val_cat_acc: 0.4927 - val_accuracy: 0.0408 - val_mse: 0.7394 - val_rmse: 0.8599 - 1s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.6201 - cat_acc: 0.4905 - accuracy: 0.0372 - mse: 0.7411 - rmse: 0.8609 - val_loss: 0.6228 - val_cat_acc: 0.4897 - val_accuracy: 0.0382 - val_mse: 0.7410 - val_rmse: 0.8608 - 1s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.6201 - cat_acc: 0.4906 - accuracy: 0.0384 - mse: 0.7414 - rmse: 0.8611 - val_loss: 0.6213 - val_cat_acc: 0.4915 - val_accuracy: 0.0395 - val_mse: 0.7418 - val_rmse: 0.8613 - 1s/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.6199 - cat_acc: 0.4905 - accuracy: 0.0392 - mse: 0.7416 - rmse: 0.8612 - val_loss: 0.6211 - val_cat_acc: 0.4916 - val_accuracy: 0.0418 - val_mse: 0.7412 - val_rmse: 0.8610 - 1s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.6197 - cat_acc: 0.4906 - accuracy: 0.0401 - mse: 0.7416 - rmse: 0.8612 - val_loss: 0.6211 - val_cat_acc: 0.4909 - val_accuracy: 0.0432 - val_mse: 0.7421 - val_rmse: 0.8615 - 1s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.6197 - cat_acc: 0.4906 - accuracy: 0.0413 - mse: 0.7420 - rmse: 0.8614 - val_loss: 0.6206 - val_cat_acc: 0.4909 - val_accuracy: 0.0436 - val_mse: 0.7420 - val_rmse: 0.8614 - 1s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.6196 - cat_acc: 0.4906 - accuracy: 0.0418 - mse: 0.7422 - rmse: 0.8615 - val_loss: 0.6207 - val_cat_acc: 0.4915 - val_accuracy: 0.0450 - val_mse: 0.7418 - val_rmse: 0.8613 - 1s/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 1s - loss: 0.6195 - cat_acc: 0.4907 - accuracy: 0.0430 - mse: 0.7422 - rmse: 0.8615 - val_loss: 0.6205 - val_cat_acc: 0.4909 - val_accuracy: 0.0445 - val_mse: 0.7428 - val_rmse: 0.8619 - 1s/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 1s - loss: 0.6194 - cat_acc: 0.4908 - accuracy: 0.0439 - mse: 0.7424 - rmse: 0.8616 - val_loss: 0.6207 - val_cat_acc: 0.4904 - val_accuracy: 0.0444 - val_mse: 0.7423 - val_rmse: 0.8616 - 1s/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 1s - loss: 0.6193 - cat_acc: 0.4906 - accuracy: 0.0444 - mse: 0.7425 - rmse: 0.8617 - val_loss: 0.6206 - val_cat_acc: 0.4911 - val_accuracy: 0.0478 - val_mse: 0.7422 - val_rmse: 0.8615 - 1s/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 1s - loss: 0.6192 - cat_acc: 0.4906 - accuracy: 0.0456 - mse: 0.7427 - rmse: 0.8618 - val_loss: 0.6212 - val_cat_acc: 0.4893 - val_accuracy: 0.0462 - val_mse: 0.7434 - val_rmse: 0.8622 - 1s/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "800/800 - 1s - loss: 0.6191 - cat_acc: 0.4904 - accuracy: 0.0465 - mse: 0.7428 - rmse: 0.8619 - val_loss: 0.6199 - val_cat_acc: 0.4907 - val_accuracy: 0.0462 - val_mse: 0.7432 - val_rmse: 0.8621 - 1s/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "800/800 - 1s - loss: 0.6190 - cat_acc: 0.4906 - accuracy: 0.0469 - mse: 0.7429 - rmse: 0.8619 - val_loss: 0.6210 - val_cat_acc: 0.4910 - val_accuracy: 0.0458 - val_mse: 0.7427 - val_rmse: 0.8618 - 1s/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "800/800 - 1s - loss: 0.6189 - cat_acc: 0.4907 - accuracy: 0.0480 - mse: 0.7430 - rmse: 0.8619 - val_loss: 0.6200 - val_cat_acc: 0.4911 - val_accuracy: 0.0497 - val_mse: 0.7434 - val_rmse: 0.8622 - 1s/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "800/800 - 1s - loss: 0.6188 - cat_acc: 0.4907 - accuracy: 0.0494 - mse: 0.7430 - rmse: 0.8619 - val_loss: 0.6198 - val_cat_acc: 0.4915 - val_accuracy: 0.0502 - val_mse: 0.7431 - val_rmse: 0.8620 - 1s/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "800/800 - 1s - loss: 0.6187 - cat_acc: 0.4906 - accuracy: 0.0498 - mse: 0.7432 - rmse: 0.8621 - val_loss: 0.6202 - val_cat_acc: 0.4915 - val_accuracy: 0.0519 - val_mse: 0.7425 - val_rmse: 0.8617 - 1s/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "800/800 - 1s - loss: 0.6186 - cat_acc: 0.4906 - accuracy: 0.0508 - mse: 0.7432 - rmse: 0.8621 - val_loss: 0.6199 - val_cat_acc: 0.4908 - val_accuracy: 0.0503 - val_mse: 0.7441 - val_rmse: 0.8626 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "800/800 - 1s - loss: 0.6186 - cat_acc: 0.4907 - accuracy: 0.0515 - mse: 0.7434 - rmse: 0.8622 - val_loss: 0.6201 - val_cat_acc: 0.4900 - val_accuracy: 0.0490 - val_mse: 0.7446 - val_rmse: 0.8629 - 1s/epoch - 1ms/step\n",
      "Epoch 73/100\n",
      "800/800 - 1s - loss: 0.6185 - cat_acc: 0.4907 - accuracy: 0.0518 - mse: 0.7435 - rmse: 0.8622 - val_loss: 0.6194 - val_cat_acc: 0.4912 - val_accuracy: 0.0519 - val_mse: 0.7439 - val_rmse: 0.8625 - 1s/epoch - 1ms/step\n",
      "Epoch 74/100\n",
      "800/800 - 1s - loss: 0.6185 - cat_acc: 0.4907 - accuracy: 0.0527 - mse: 0.7437 - rmse: 0.8624 - val_loss: 0.6198 - val_cat_acc: 0.4906 - val_accuracy: 0.0565 - val_mse: 0.7437 - val_rmse: 0.8624 - 1s/epoch - 1ms/step\n",
      "Epoch 75/100\n",
      "800/800 - 1s - loss: 0.6184 - cat_acc: 0.4908 - accuracy: 0.0534 - mse: 0.7437 - rmse: 0.8624 - val_loss: 0.6209 - val_cat_acc: 0.4924 - val_accuracy: 0.0563 - val_mse: 0.7433 - val_rmse: 0.8622 - 1s/epoch - 1ms/step\n",
      "Epoch 76/100\n",
      "800/800 - 1s - loss: 0.6184 - cat_acc: 0.4906 - accuracy: 0.0542 - mse: 0.7438 - rmse: 0.8624 - val_loss: 0.6201 - val_cat_acc: 0.4902 - val_accuracy: 0.0514 - val_mse: 0.7442 - val_rmse: 0.8627 - 1s/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "800/800 - 1s - loss: 0.6182 - cat_acc: 0.4908 - accuracy: 0.0547 - mse: 0.7439 - rmse: 0.8625 - val_loss: 0.6198 - val_cat_acc: 0.4904 - val_accuracy: 0.0558 - val_mse: 0.7436 - val_rmse: 0.8624 - 1s/epoch - 1ms/step\n",
      "Epoch 78/100\n",
      "800/800 - 1s - loss: 0.6182 - cat_acc: 0.4906 - accuracy: 0.0552 - mse: 0.7442 - rmse: 0.8627 - val_loss: 0.6197 - val_cat_acc: 0.4911 - val_accuracy: 0.0566 - val_mse: 0.7445 - val_rmse: 0.8628 - 1s/epoch - 1ms/step\n",
      "Epoch 78: early stopping\n",
      "3125/3125 [==============================] - 3s 980us/step\n",
      "INFO:tensorflow:Assets written to: ram://9e14d615-6dd5-4666-acab-49e3cdd07d5e/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://9e14d615-6dd5-4666-acab-49e3cdd07d5e/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 1.1201 - cat_acc: 0.4979 - accuracy: 0.0000e+00 - mse: 0.2447 - rmse: 0.4946 - val_loss: 0.9505 - val_cat_acc: 0.4969 - val_accuracy: 0.0000e+00 - val_mse: 0.3401 - val_rmse: 0.5832 - 2s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.9061 - cat_acc: 0.4973 - accuracy: 0.0000e+00 - mse: 0.4380 - rmse: 0.6618 - val_loss: 0.8806 - val_cat_acc: 0.4970 - val_accuracy: 0.0000e+00 - val_mse: 0.5174 - val_rmse: 0.7193 - 1s/epoch - 1ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.8662 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.5665 - rmse: 0.7526 - val_loss: 0.8583 - val_cat_acc: 0.4970 - val_accuracy: 0.0000e+00 - val_mse: 0.6081 - val_rmse: 0.7798 - 1s/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.8508 - cat_acc: 0.4975 - accuracy: 0.0000e+00 - mse: 0.6347 - rmse: 0.7967 - val_loss: 0.8479 - val_cat_acc: 0.4972 - val_accuracy: 0.0000e+00 - val_mse: 0.6592 - val_rmse: 0.8119 - 1s/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.8429 - cat_acc: 0.4975 - accuracy: 0.0000e+00 - mse: 0.6741 - rmse: 0.8211 - val_loss: 0.8419 - val_cat_acc: 0.4972 - val_accuracy: 0.0000e+00 - val_mse: 0.6876 - val_rmse: 0.8292 - 1s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.8362 - cat_acc: 0.4971 - accuracy: 0.0000e+00 - mse: 0.6868 - rmse: 0.8287 - val_loss: 0.8297 - val_cat_acc: 0.4939 - val_accuracy: 0.0000e+00 - val_mse: 0.6613 - val_rmse: 0.8132 - 1s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.8053 - cat_acc: 0.4934 - accuracy: 0.0000e+00 - mse: 0.6332 - rmse: 0.7958 - val_loss: 0.7876 - val_cat_acc: 0.4920 - val_accuracy: 0.0000e+00 - val_mse: 0.6237 - val_rmse: 0.7898 - 1s/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.7680 - cat_acc: 0.4936 - accuracy: 0.0000e+00 - mse: 0.6243 - rmse: 0.7901 - val_loss: 0.7533 - val_cat_acc: 0.4936 - val_accuracy: 0.0000e+00 - val_mse: 0.6275 - val_rmse: 0.7922 - 1s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.7339 - cat_acc: 0.4909 - accuracy: 0.0000e+00 - mse: 0.6245 - rmse: 0.7903 - val_loss: 0.7213 - val_cat_acc: 0.4900 - val_accuracy: 0.0000e+00 - val_mse: 0.6292 - val_rmse: 0.7932 - 1s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.7089 - cat_acc: 0.4888 - accuracy: 0.0000e+00 - mse: 0.6356 - rmse: 0.7972 - val_loss: 0.7022 - val_cat_acc: 0.4887 - val_accuracy: 0.0000e+00 - val_mse: 0.6433 - val_rmse: 0.8021 - 1s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.6927 - cat_acc: 0.4882 - accuracy: 0.0000e+00 - mse: 0.6495 - rmse: 0.8059 - val_loss: 0.6886 - val_cat_acc: 0.4881 - val_accuracy: 0.0000e+00 - val_mse: 0.6558 - val_rmse: 0.8098 - 1s/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.6808 - cat_acc: 0.4879 - accuracy: 0.0000e+00 - mse: 0.6616 - rmse: 0.8134 - val_loss: 0.6780 - val_cat_acc: 0.4890 - val_accuracy: 0.0000e+00 - val_mse: 0.6681 - val_rmse: 0.8174 - 1s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.6715 - cat_acc: 0.4882 - accuracy: 0.0000e+00 - mse: 0.6723 - rmse: 0.8199 - val_loss: 0.6698 - val_cat_acc: 0.4886 - val_accuracy: 0.0000e+00 - val_mse: 0.6770 - val_rmse: 0.8228 - 1s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.6641 - cat_acc: 0.4881 - accuracy: 0.0000e+00 - mse: 0.6813 - rmse: 0.8254 - val_loss: 0.6631 - val_cat_acc: 0.4885 - val_accuracy: 0.0000e+00 - val_mse: 0.6855 - val_rmse: 0.8279 - 1s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.6580 - cat_acc: 0.4884 - accuracy: 0.0000e+00 - mse: 0.6888 - rmse: 0.8300 - val_loss: 0.6573 - val_cat_acc: 0.4880 - val_accuracy: 0.0000e+00 - val_mse: 0.6924 - val_rmse: 0.8321 - 1s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.6529 - cat_acc: 0.4886 - accuracy: 0.0000e+00 - mse: 0.6952 - rmse: 0.8338 - val_loss: 0.6526 - val_cat_acc: 0.4891 - val_accuracy: 0.0000e+00 - val_mse: 0.6974 - val_rmse: 0.8351 - 1s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.6489 - cat_acc: 0.4886 - accuracy: 0.0000e+00 - mse: 0.7008 - rmse: 0.8371 - val_loss: 0.6489 - val_cat_acc: 0.4897 - val_accuracy: 0.0000e+00 - val_mse: 0.7029 - val_rmse: 0.8384 - 1s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.6453 - cat_acc: 0.4888 - accuracy: 0.0000e+00 - mse: 0.7054 - rmse: 0.8399 - val_loss: 0.6455 - val_cat_acc: 0.4886 - val_accuracy: 0.0000e+00 - val_mse: 0.7075 - val_rmse: 0.8411 - 1s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.6422 - cat_acc: 0.4891 - accuracy: 0.0000e+00 - mse: 0.7094 - rmse: 0.8423 - val_loss: 0.6430 - val_cat_acc: 0.4890 - val_accuracy: 0.0000e+00 - val_mse: 0.7116 - val_rmse: 0.8436 - 1s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.6399 - cat_acc: 0.4890 - accuracy: 5.3125e-05 - mse: 0.7130 - rmse: 0.8444 - val_loss: 0.6406 - val_cat_acc: 0.4902 - val_accuracy: 7.5000e-05 - val_mse: 0.7131 - val_rmse: 0.8445 - 1s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.6377 - cat_acc: 0.4890 - accuracy: 1.4375e-04 - mse: 0.7159 - rmse: 0.8461 - val_loss: 0.6383 - val_cat_acc: 0.4904 - val_accuracy: 1.1250e-04 - val_mse: 0.7163 - val_rmse: 0.8464 - 1s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.6359 - cat_acc: 0.4893 - accuracy: 2.6250e-04 - mse: 0.7184 - rmse: 0.8476 - val_loss: 0.6367 - val_cat_acc: 0.4900 - val_accuracy: 2.1250e-04 - val_mse: 0.7195 - val_rmse: 0.8483 - 1s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.6343 - cat_acc: 0.4892 - accuracy: 4.4375e-04 - mse: 0.7207 - rmse: 0.8490 - val_loss: 0.6354 - val_cat_acc: 0.4898 - val_accuracy: 5.1250e-04 - val_mse: 0.7215 - val_rmse: 0.8494 - 1s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.6329 - cat_acc: 0.4895 - accuracy: 7.0313e-04 - mse: 0.7228 - rmse: 0.8502 - val_loss: 0.6340 - val_cat_acc: 0.4900 - val_accuracy: 7.8750e-04 - val_mse: 0.7232 - val_rmse: 0.8504 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 2s - loss: 0.6317 - cat_acc: 0.4894 - accuracy: 0.0011 - mse: 0.7245 - rmse: 0.8512 - val_loss: 0.6323 - val_cat_acc: 0.4907 - val_accuracy: 0.0012 - val_mse: 0.7245 - val_rmse: 0.8512 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.6306 - cat_acc: 0.4898 - accuracy: 0.0015 - mse: 0.7259 - rmse: 0.8520 - val_loss: 0.6314 - val_cat_acc: 0.4904 - val_accuracy: 0.0019 - val_mse: 0.7259 - val_rmse: 0.8520 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.6297 - cat_acc: 0.4899 - accuracy: 0.0021 - mse: 0.7273 - rmse: 0.8528 - val_loss: 0.6306 - val_cat_acc: 0.4904 - val_accuracy: 0.0024 - val_mse: 0.7283 - val_rmse: 0.8534 - 1s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.6289 - cat_acc: 0.4896 - accuracy: 0.0028 - mse: 0.7286 - rmse: 0.8536 - val_loss: 0.6299 - val_cat_acc: 0.4905 - val_accuracy: 0.0033 - val_mse: 0.7287 - val_rmse: 0.8536 - 1s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.6281 - cat_acc: 0.4896 - accuracy: 0.0035 - mse: 0.7298 - rmse: 0.8543 - val_loss: 0.6293 - val_cat_acc: 0.4902 - val_accuracy: 0.0038 - val_mse: 0.7298 - val_rmse: 0.8543 - 1s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.6274 - cat_acc: 0.4899 - accuracy: 0.0045 - mse: 0.7307 - rmse: 0.8548 - val_loss: 0.6283 - val_cat_acc: 0.4904 - val_accuracy: 0.0048 - val_mse: 0.7308 - val_rmse: 0.8549 - 1s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.6267 - cat_acc: 0.4900 - accuracy: 0.0055 - mse: 0.7314 - rmse: 0.8552 - val_loss: 0.6280 - val_cat_acc: 0.4900 - val_accuracy: 0.0059 - val_mse: 0.7319 - val_rmse: 0.8555 - 1s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.6263 - cat_acc: 0.4897 - accuracy: 0.0065 - mse: 0.7325 - rmse: 0.8558 - val_loss: 0.6273 - val_cat_acc: 0.4911 - val_accuracy: 0.0076 - val_mse: 0.7317 - val_rmse: 0.8554 - 1s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.6256 - cat_acc: 0.4900 - accuracy: 0.0078 - mse: 0.7330 - rmse: 0.8562 - val_loss: 0.6271 - val_cat_acc: 0.4908 - val_accuracy: 0.0092 - val_mse: 0.7318 - val_rmse: 0.8555 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.6253 - cat_acc: 0.4900 - accuracy: 0.0090 - mse: 0.7338 - rmse: 0.8566 - val_loss: 0.6269 - val_cat_acc: 0.4895 - val_accuracy: 0.0098 - val_mse: 0.7335 - val_rmse: 0.8564 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 2s - loss: 0.6248 - cat_acc: 0.4902 - accuracy: 0.0101 - mse: 0.7343 - rmse: 0.8569 - val_loss: 0.6265 - val_cat_acc: 0.4908 - val_accuracy: 0.0112 - val_mse: 0.7345 - val_rmse: 0.8570 - 2s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.6244 - cat_acc: 0.4901 - accuracy: 0.0116 - mse: 0.7347 - rmse: 0.8571 - val_loss: 0.6258 - val_cat_acc: 0.4906 - val_accuracy: 0.0114 - val_mse: 0.7360 - val_rmse: 0.8579 - 1s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.6241 - cat_acc: 0.4902 - accuracy: 0.0128 - mse: 0.7355 - rmse: 0.8576 - val_loss: 0.6252 - val_cat_acc: 0.4904 - val_accuracy: 0.0142 - val_mse: 0.7353 - val_rmse: 0.8575 - 1s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.6237 - cat_acc: 0.4900 - accuracy: 0.0143 - mse: 0.7360 - rmse: 0.8579 - val_loss: 0.6255 - val_cat_acc: 0.4901 - val_accuracy: 0.0156 - val_mse: 0.7356 - val_rmse: 0.8577 - 1s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.6234 - cat_acc: 0.4901 - accuracy: 0.0158 - mse: 0.7364 - rmse: 0.8581 - val_loss: 0.6245 - val_cat_acc: 0.4912 - val_accuracy: 0.0180 - val_mse: 0.7360 - val_rmse: 0.8579 - 1s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.6231 - cat_acc: 0.4903 - accuracy: 0.0174 - mse: 0.7368 - rmse: 0.8584 - val_loss: 0.6244 - val_cat_acc: 0.4895 - val_accuracy: 0.0174 - val_mse: 0.7372 - val_rmse: 0.8586 - 1s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.6228 - cat_acc: 0.4902 - accuracy: 0.0187 - mse: 0.7373 - rmse: 0.8587 - val_loss: 0.6241 - val_cat_acc: 0.4911 - val_accuracy: 0.0199 - val_mse: 0.7371 - val_rmse: 0.8585 - 1s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.6225 - cat_acc: 0.4903 - accuracy: 0.0200 - mse: 0.7375 - rmse: 0.8588 - val_loss: 0.6237 - val_cat_acc: 0.4908 - val_accuracy: 0.0220 - val_mse: 0.7370 - val_rmse: 0.8585 - 1s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.6223 - cat_acc: 0.4903 - accuracy: 0.0215 - mse: 0.7379 - rmse: 0.8590 - val_loss: 0.6235 - val_cat_acc: 0.4902 - val_accuracy: 0.0216 - val_mse: 0.7380 - val_rmse: 0.8591 - 1s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.6220 - cat_acc: 0.4904 - accuracy: 0.0229 - mse: 0.7382 - rmse: 0.8592 - val_loss: 0.6239 - val_cat_acc: 0.4895 - val_accuracy: 0.0233 - val_mse: 0.7384 - val_rmse: 0.8593 - 1s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.6219 - cat_acc: 0.4902 - accuracy: 0.0240 - mse: 0.7385 - rmse: 0.8594 - val_loss: 0.6236 - val_cat_acc: 0.4910 - val_accuracy: 0.0240 - val_mse: 0.7397 - val_rmse: 0.8600 - 1s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.6218 - cat_acc: 0.4901 - accuracy: 0.0254 - mse: 0.7390 - rmse: 0.8597 - val_loss: 0.6227 - val_cat_acc: 0.4904 - val_accuracy: 0.0252 - val_mse: 0.7395 - val_rmse: 0.8600 - 1s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.6214 - cat_acc: 0.4903 - accuracy: 0.0267 - mse: 0.7392 - rmse: 0.8597 - val_loss: 0.6227 - val_cat_acc: 0.4904 - val_accuracy: 0.0270 - val_mse: 0.7392 - val_rmse: 0.8598 - 1s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.6213 - cat_acc: 0.4904 - accuracy: 0.0278 - mse: 0.7394 - rmse: 0.8599 - val_loss: 0.6222 - val_cat_acc: 0.4910 - val_accuracy: 0.0284 - val_mse: 0.7395 - val_rmse: 0.8600 - 1s/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.6211 - cat_acc: 0.4902 - accuracy: 0.0291 - mse: 0.7397 - rmse: 0.8600 - val_loss: 0.6224 - val_cat_acc: 0.4900 - val_accuracy: 0.0301 - val_mse: 0.7404 - val_rmse: 0.8604 - 1s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.6210 - cat_acc: 0.4904 - accuracy: 0.0303 - mse: 0.7402 - rmse: 0.8603 - val_loss: 0.6221 - val_cat_acc: 0.4906 - val_accuracy: 0.0302 - val_mse: 0.7397 - val_rmse: 0.8601 - 1s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.6208 - cat_acc: 0.4905 - accuracy: 0.0313 - mse: 0.7402 - rmse: 0.8603 - val_loss: 0.6224 - val_cat_acc: 0.4900 - val_accuracy: 0.0330 - val_mse: 0.7400 - val_rmse: 0.8602 - 1s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.6206 - cat_acc: 0.4904 - accuracy: 0.0328 - mse: 0.7403 - rmse: 0.8604 - val_loss: 0.6225 - val_cat_acc: 0.4915 - val_accuracy: 0.0352 - val_mse: 0.7402 - val_rmse: 0.8603 - 1s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.6205 - cat_acc: 0.4905 - accuracy: 0.0339 - mse: 0.7404 - rmse: 0.8605 - val_loss: 0.6218 - val_cat_acc: 0.4909 - val_accuracy: 0.0346 - val_mse: 0.7406 - val_rmse: 0.8606 - 1s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.6203 - cat_acc: 0.4905 - accuracy: 0.0352 - mse: 0.7408 - rmse: 0.8607 - val_loss: 0.6214 - val_cat_acc: 0.4914 - val_accuracy: 0.0350 - val_mse: 0.7409 - val_rmse: 0.8608 - 1s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.6202 - cat_acc: 0.4906 - accuracy: 0.0362 - mse: 0.7410 - rmse: 0.8608 - val_loss: 0.6222 - val_cat_acc: 0.4913 - val_accuracy: 0.0380 - val_mse: 0.7410 - val_rmse: 0.8608 - 1s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.6201 - cat_acc: 0.4905 - accuracy: 0.0370 - mse: 0.7414 - rmse: 0.8611 - val_loss: 0.6218 - val_cat_acc: 0.4916 - val_accuracy: 0.0389 - val_mse: 0.7406 - val_rmse: 0.8606 - 1s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.6199 - cat_acc: 0.4906 - accuracy: 0.0382 - mse: 0.7415 - rmse: 0.8611 - val_loss: 0.6211 - val_cat_acc: 0.4916 - val_accuracy: 0.0419 - val_mse: 0.7409 - val_rmse: 0.8608 - 1s/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.6199 - cat_acc: 0.4905 - accuracy: 0.0394 - mse: 0.7416 - rmse: 0.8611 - val_loss: 0.6215 - val_cat_acc: 0.4913 - val_accuracy: 0.0418 - val_mse: 0.7406 - val_rmse: 0.8606 - 1s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.6198 - cat_acc: 0.4907 - accuracy: 0.0405 - mse: 0.7418 - rmse: 0.8613 - val_loss: 0.6212 - val_cat_acc: 0.4919 - val_accuracy: 0.0435 - val_mse: 0.7416 - val_rmse: 0.8611 - 1s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.6196 - cat_acc: 0.4906 - accuracy: 0.0410 - mse: 0.7420 - rmse: 0.8614 - val_loss: 0.6209 - val_cat_acc: 0.4915 - val_accuracy: 0.0429 - val_mse: 0.7418 - val_rmse: 0.8613 - 1s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.6196 - cat_acc: 0.4905 - accuracy: 0.0419 - mse: 0.7421 - rmse: 0.8615 - val_loss: 0.6210 - val_cat_acc: 0.4909 - val_accuracy: 0.0441 - val_mse: 0.7430 - val_rmse: 0.8620 - 1s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 1s - loss: 0.6194 - cat_acc: 0.4905 - accuracy: 0.0428 - mse: 0.7424 - rmse: 0.8616 - val_loss: 0.6209 - val_cat_acc: 0.4902 - val_accuracy: 0.0432 - val_mse: 0.7429 - val_rmse: 0.8619 - 1s/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 1s - loss: 0.6194 - cat_acc: 0.4905 - accuracy: 0.0441 - mse: 0.7423 - rmse: 0.8616 - val_loss: 0.6218 - val_cat_acc: 0.4890 - val_accuracy: 0.0443 - val_mse: 0.7429 - val_rmse: 0.8619 - 1s/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 1s - loss: 0.6192 - cat_acc: 0.4905 - accuracy: 0.0449 - mse: 0.7424 - rmse: 0.8616 - val_loss: 0.6214 - val_cat_acc: 0.4908 - val_accuracy: 0.0459 - val_mse: 0.7426 - val_rmse: 0.8618 - 1s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 1s - loss: 0.6193 - cat_acc: 0.4908 - accuracy: 0.0463 - mse: 0.7425 - rmse: 0.8617 - val_loss: 0.6209 - val_cat_acc: 0.4893 - val_accuracy: 0.0468 - val_mse: 0.7433 - val_rmse: 0.8621 - 1s/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "800/800 - 1s - loss: 0.6192 - cat_acc: 0.4905 - accuracy: 0.0468 - mse: 0.7428 - rmse: 0.8618 - val_loss: 0.6204 - val_cat_acc: 0.4904 - val_accuracy: 0.0477 - val_mse: 0.7427 - val_rmse: 0.8618 - 1s/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "800/800 - 1s - loss: 0.6189 - cat_acc: 0.4905 - accuracy: 0.0479 - mse: 0.7428 - rmse: 0.8618 - val_loss: 0.6203 - val_cat_acc: 0.4906 - val_accuracy: 0.0499 - val_mse: 0.7433 - val_rmse: 0.8621 - 1s/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "800/800 - 1s - loss: 0.6190 - cat_acc: 0.4908 - accuracy: 0.0485 - mse: 0.7430 - rmse: 0.8620 - val_loss: 0.6197 - val_cat_acc: 0.4911 - val_accuracy: 0.0493 - val_mse: 0.7433 - val_rmse: 0.8621 - 1s/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "800/800 - 1s - loss: 0.6189 - cat_acc: 0.4905 - accuracy: 0.0490 - mse: 0.7434 - rmse: 0.8622 - val_loss: 0.6206 - val_cat_acc: 0.4909 - val_accuracy: 0.0481 - val_mse: 0.7431 - val_rmse: 0.8620 - 1s/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "800/800 - 1s - loss: 0.6187 - cat_acc: 0.4904 - accuracy: 0.0501 - mse: 0.7433 - rmse: 0.8621 - val_loss: 0.6198 - val_cat_acc: 0.4907 - val_accuracy: 0.0504 - val_mse: 0.7431 - val_rmse: 0.8621 - 1s/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "800/800 - 1s - loss: 0.6187 - cat_acc: 0.4907 - accuracy: 0.0513 - mse: 0.7433 - rmse: 0.8622 - val_loss: 0.6204 - val_cat_acc: 0.4909 - val_accuracy: 0.0499 - val_mse: 0.7440 - val_rmse: 0.8626 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "800/800 - 1s - loss: 0.6187 - cat_acc: 0.4904 - accuracy: 0.0516 - mse: 0.7435 - rmse: 0.8623 - val_loss: 0.6203 - val_cat_acc: 0.4898 - val_accuracy: 0.0519 - val_mse: 0.7439 - val_rmse: 0.8625 - 1s/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "800/800 - 1s - loss: 0.6186 - cat_acc: 0.4905 - accuracy: 0.0526 - mse: 0.7437 - rmse: 0.8624 - val_loss: 0.6198 - val_cat_acc: 0.4914 - val_accuracy: 0.0545 - val_mse: 0.7435 - val_rmse: 0.8622 - 1s/epoch - 1ms/step\n",
      "Epoch 73: early stopping\n",
      "3125/3125 [==============================] - 3s 916us/step\n",
      "INFO:tensorflow:Assets written to: ram://7436e0c8-b874-4de1-86b5-55ec623fb178/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7436e0c8-b874-4de1-86b5-55ec623fb178/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 neuron in [1, 10, 100]\n",
      "Training for 1 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.6883 - cat_acc: 0.9589 - accuracy: 0.0000e+00 - mse: 0.3414 - rmse: 0.5843 - val_loss: 0.4341 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.5271 - val_rmse: 0.7260 - 2s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.3975 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.6187 - rmse: 0.7866 - val_loss: 0.3807 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.6760 - val_rmse: 0.8222 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.3689 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7120 - rmse: 0.8438 - val_loss: 0.3657 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7329 - val_rmse: 0.8561 - 1s/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3621 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7387 - rmse: 0.8595 - val_loss: 0.3629 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7447 - val_rmse: 0.8630 - 1s/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3602 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7465 - rmse: 0.8640 - val_loss: 0.3615 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7499 - val_rmse: 0.8659 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.3591 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7503 - rmse: 0.8662 - val_loss: 0.3607 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7526 - val_rmse: 0.8675 - 1s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3584 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7524 - rmse: 0.8674 - val_loss: 0.3600 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7542 - val_rmse: 0.8684 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3578 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7537 - rmse: 0.8681 - val_loss: 0.3595 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7552 - val_rmse: 0.8690 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 2s - loss: 0.3574 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7545 - rmse: 0.8686 - val_loss: 0.3591 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7558 - val_rmse: 0.8694 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3570 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7551 - rmse: 0.8690 - val_loss: 0.3588 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7564 - val_rmse: 0.8697 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3567 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7556 - rmse: 0.8692 - val_loss: 0.3586 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7568 - val_rmse: 0.8699 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3565 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7559 - rmse: 0.8694 - val_loss: 0.3584 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7570 - val_rmse: 0.8701 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7562 - rmse: 0.8696 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7573 - val_rmse: 0.8702 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 3.1250e-06 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 1.2500e-05 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 2.5000e-05 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 6.2500e-05 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 9.6875e-05 - mse: 0.7566 - rmse: 0.8699 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 1.0000e-04 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 1.8750e-04 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 1.0000e-04 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 4.7500e-04 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 3.8750e-04 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 6.9375e-04 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0020 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0010 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0022 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0014 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 4.5000e-04 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0024 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0022 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0029 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0031 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0035 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0043 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0045 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0038 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0050 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0048 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0087 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0070 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0071 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0048 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0083 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0139 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0119 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0083 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0144 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0111 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0132 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0104 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0142 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0534 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0251 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0148 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0159 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0150 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0168 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0198 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0274 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0295 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0233 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0264 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0203 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0258 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0217 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0196 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0224 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0202 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0233 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0247 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0320 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0317 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0269 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0327 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0414 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0271 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 2s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0435 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0318 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0334 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0290 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0390 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0279 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0386 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0389 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0345 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0314 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0371 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3579 - val_cat_acc: 0.9917 - val_accuracy: 0.0855 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0598 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0488 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0410 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0362 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0391 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0451 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0432 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0440 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0486 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0420 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0436 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0463 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0561 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0501 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0581 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1314 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.1012 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0763 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0635 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0525 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 61: early stopping\n",
      "3125/3125 [==============================] - 3s 935us/step\n",
      "INFO:tensorflow:Assets written to: ram://b02086d2-ff50-40e6-8330-d60ff060be18/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://b02086d2-ff50-40e6-8330-d60ff060be18/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.6741 - cat_acc: 0.9512 - accuracy: 0.0000e+00 - mse: 0.3207 - rmse: 0.5663 - val_loss: 0.4405 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.4984 - val_rmse: 0.7060 - 2s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.4000 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.6044 - rmse: 0.7775 - val_loss: 0.3807 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.6730 - val_rmse: 0.8204 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.3699 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7071 - rmse: 0.8409 - val_loss: 0.3665 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7295 - val_rmse: 0.8541 - 1s/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3626 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7367 - rmse: 0.8583 - val_loss: 0.3631 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7434 - val_rmse: 0.8622 - 1s/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3604 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7456 - rmse: 0.8635 - val_loss: 0.3617 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7492 - val_rmse: 0.8655 - 1s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.3592 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7498 - rmse: 0.8659 - val_loss: 0.3607 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7522 - val_rmse: 0.8673 - 1s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3584 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7522 - rmse: 0.8673 - val_loss: 0.3600 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7541 - val_rmse: 0.8684 - 1s/epoch - 1ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3578 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7536 - rmse: 0.8681 - val_loss: 0.3595 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7551 - val_rmse: 0.8689 - 1s/epoch - 1ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.3574 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7544 - rmse: 0.8686 - val_loss: 0.3591 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7559 - val_rmse: 0.8694 - 1s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3570 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7551 - rmse: 0.8690 - val_loss: 0.3588 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7563 - val_rmse: 0.8697 - 1s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3567 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7555 - rmse: 0.8692 - val_loss: 0.3586 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7568 - val_rmse: 0.8699 - 1s/epoch - 1ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3565 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7559 - rmse: 0.8694 - val_loss: 0.3584 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7570 - val_rmse: 0.8701 - 1s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3564 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7561 - rmse: 0.8696 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7573 - val_rmse: 0.8703 - 1s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 3.7500e-05 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 9.3750e-06 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 1.0000e-04 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 1.0938e-04 - mse: 0.7566 - rmse: 0.8698 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 1.8750e-04 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 3.0625e-04 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 6.6250e-04 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 8.3750e-04 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 7.6250e-04 - val_mse: 0.7579 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0010 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0035 - val_mse: 0.7575 - val_rmse: 0.8703 - 1s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0022 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0052 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0039 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0028 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0050 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0048 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0059 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0105 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0093 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0121 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 2s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0114 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0122 - val_mse: 0.7580 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0111 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0169 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0159 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0154 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0143 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0150 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0169 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0148 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0192 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0150 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0218 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0266 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0214 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0135 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0200 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0261 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0292 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0351 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0280 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0351 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0276 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0175 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0271 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0638 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0408 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0274 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0343 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0400 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0525 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0345 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0324 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0836 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0564 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0440 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0359 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0312 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0279 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0247 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0397 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0911 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0560 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0506 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0524 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0578 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0439 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0360 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0536 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0518 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0492 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0406 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0481 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0501 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0556 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0494 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0491 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0764 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0590 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0509 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0531 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0679 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0806 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1180 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0857 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0719 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0680 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0616 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0429 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0545 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0518 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0394 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0558 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0400 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.1004 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1045 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0803 - mse: 0.7572 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0577 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0588 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0518 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0583 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.1217 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0963 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0708 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 66: early stopping\n",
      "3125/3125 [==============================] - 3s 941us/step\n",
      "INFO:tensorflow:Assets written to: ram://1f6e1897-a310-400e-9c55-84a9c80251de/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://1f6e1897-a310-400e-9c55-84a9c80251de/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100 neuron in [1, 10, 100]\n",
      "Training for 1 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.4532 - cat_acc: 0.9818 - accuracy: 0.0000e+00 - mse: 0.6226 - rmse: 0.7891 - val_loss: 0.3638 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7475 - val_rmse: 0.8646 - 2s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.3606 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7510 - rmse: 0.8666 - val_loss: 0.3618 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7543 - val_rmse: 0.8685 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 2s - loss: 0.3595 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7541 - rmse: 0.8684 - val_loss: 0.3611 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7557 - val_rmse: 0.8693 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3588 - cat_acc: 0.9928 - accuracy: 4.6875e-05 - mse: 0.7549 - rmse: 0.8688 - val_loss: 0.3604 - val_cat_acc: 0.9918 - val_accuracy: 8.7500e-05 - val_mse: 0.7562 - val_rmse: 0.8696 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3582 - cat_acc: 0.9928 - accuracy: 1.4375e-04 - mse: 0.7553 - rmse: 0.8691 - val_loss: 0.3599 - val_cat_acc: 0.9918 - val_accuracy: 2.0000e-04 - val_mse: 0.7565 - val_rmse: 0.8698 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 2s - loss: 0.3578 - cat_acc: 0.9928 - accuracy: 4.0625e-04 - mse: 0.7555 - rmse: 0.8692 - val_loss: 0.3596 - val_cat_acc: 0.9918 - val_accuracy: 6.2500e-04 - val_mse: 0.7569 - val_rmse: 0.8700 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3575 - cat_acc: 0.9928 - accuracy: 8.8750e-04 - mse: 0.7558 - rmse: 0.8694 - val_loss: 0.3593 - val_cat_acc: 0.9918 - val_accuracy: 0.0013 - val_mse: 0.7572 - val_rmse: 0.8702 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3571 - cat_acc: 0.9928 - accuracy: 0.0013 - mse: 0.7561 - rmse: 0.8695 - val_loss: 0.3589 - val_cat_acc: 0.9918 - val_accuracy: 0.0012 - val_mse: 0.7572 - val_rmse: 0.8702 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.3570 - cat_acc: 0.9928 - accuracy: 0.0024 - mse: 0.7562 - rmse: 0.8696 - val_loss: 0.3588 - val_cat_acc: 0.9918 - val_accuracy: 0.0021 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3567 - cat_acc: 0.9928 - accuracy: 0.0030 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3585 - val_cat_acc: 0.9918 - val_accuracy: 0.0018 - val_mse: 0.7575 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3566 - cat_acc: 0.9928 - accuracy: 0.0043 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3585 - val_cat_acc: 0.9918 - val_accuracy: 0.0071 - val_mse: 0.7573 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3565 - cat_acc: 0.9928 - accuracy: 0.0057 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3585 - val_cat_acc: 0.9918 - val_accuracy: 0.0093 - val_mse: 0.7575 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3564 - cat_acc: 0.9928 - accuracy: 0.0083 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0051 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0075 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0095 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0148 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0082 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0107 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0093 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0119 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0233 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0191 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0153 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0135 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0103 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0298 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0318 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0295 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0150 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0266 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0344 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0260 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0184 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0240 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0295 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0291 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0373 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0489 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0651 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0607 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.1413 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.1230 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0977 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0777 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0576 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0658 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0737 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0575 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0436 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0858 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.1641 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.1269 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.1021 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0883 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0798 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0594 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0341 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0392 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0406 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0383 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0374 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0386 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0537 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0413 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0343 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0597 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.1227 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0960 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0651 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0751 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0728 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0566 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3583 - val_cat_acc: 0.9918 - val_accuracy: 0.0469 - val_mse: 0.7571 - val_rmse: 0.8701 - 1s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0521 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0502 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0504 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0726 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0501 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0466 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0648 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.1578 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.1314 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0997 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0948 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.1010 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 49: early stopping\n",
      "3125/3125 [==============================] - 3s 981us/step\n",
      "INFO:tensorflow:Assets written to: ram://5a12caa4-d070-4aff-8741-8825460f4dbb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://5a12caa4-d070-4aff-8741-8825460f4dbb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.4570 - cat_acc: 0.9755 - accuracy: 0.0000e+00 - mse: 0.6179 - rmse: 0.7860 - val_loss: 0.3640 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7471 - val_rmse: 0.8644 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.3608 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7508 - rmse: 0.8665 - val_loss: 0.3620 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7543 - val_rmse: 0.8685 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.3596 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7540 - rmse: 0.8683 - val_loss: 0.3612 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7556 - val_rmse: 0.8693 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3589 - cat_acc: 0.9928 - accuracy: 9.3750e-06 - mse: 0.7548 - rmse: 0.8688 - val_loss: 0.3605 - val_cat_acc: 0.9918 - val_accuracy: 5.0000e-05 - val_mse: 0.7561 - val_rmse: 0.8695 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3583 - cat_acc: 0.9928 - accuracy: 5.6250e-05 - mse: 0.7552 - rmse: 0.8690 - val_loss: 0.3600 - val_cat_acc: 0.9918 - val_accuracy: 1.1250e-04 - val_mse: 0.7564 - val_rmse: 0.8697 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.3579 - cat_acc: 0.9928 - accuracy: 2.0313e-04 - mse: 0.7555 - rmse: 0.8692 - val_loss: 0.3597 - val_cat_acc: 0.9918 - val_accuracy: 7.3750e-04 - val_mse: 0.7562 - val_rmse: 0.8696 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3575 - cat_acc: 0.9928 - accuracy: 6.6250e-04 - mse: 0.7558 - rmse: 0.8694 - val_loss: 0.3593 - val_cat_acc: 0.9918 - val_accuracy: 0.0015 - val_mse: 0.7570 - val_rmse: 0.8701 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3572 - cat_acc: 0.9928 - accuracy: 0.0010 - mse: 0.7560 - rmse: 0.8695 - val_loss: 0.3593 - val_cat_acc: 0.9918 - val_accuracy: 0.0034 - val_mse: 0.7563 - val_rmse: 0.8697 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.3570 - cat_acc: 0.9928 - accuracy: 0.0017 - mse: 0.7562 - rmse: 0.8696 - val_loss: 0.3588 - val_cat_acc: 0.9918 - val_accuracy: 0.0014 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3568 - cat_acc: 0.9928 - accuracy: 0.0027 - mse: 0.7563 - rmse: 0.8697 - val_loss: 0.3586 - val_cat_acc: 0.9918 - val_accuracy: 0.0030 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3566 - cat_acc: 0.9928 - accuracy: 0.0028 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3584 - val_cat_acc: 0.9918 - val_accuracy: 0.0014 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3565 - cat_acc: 0.9928 - accuracy: 0.0043 - mse: 0.7566 - rmse: 0.8698 - val_loss: 0.3583 - val_cat_acc: 0.9918 - val_accuracy: 0.0023 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3564 - cat_acc: 0.9928 - accuracy: 0.0060 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0033 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0079 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0047 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0062 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0042 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0098 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0090 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0099 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0101 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0127 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0106 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0102 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0082 - val_mse: 0.7575 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0140 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0178 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0186 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0365 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0199 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0133 - val_mse: 0.7578 - val_rmse: 0.8705 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 2s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0300 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0512 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0430 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0319 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0269 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0231 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0314 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0365 - val_mse: 0.7575 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0213 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0362 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0387 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0310 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0475 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.1457 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.1311 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.1240 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0821 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0643 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0642 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0399 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0527 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0338 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0359 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0191 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0399 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0516 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0350 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0480 - val_mse: 0.7577 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0455 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0590 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0417 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0269 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0758 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.1122 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0956 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.1195 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0941 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0646 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0646 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0763 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0572 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0488 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0466 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0294 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.1173 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.1342 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.1025 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0772 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0647 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0678 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0983 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0819 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0699 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0498 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0405 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0524 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0859 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.1198 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0854 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0580 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0779 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0788 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0774 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0714 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0492 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0591 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0626 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0794 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0679 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0856 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0635 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0419 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0457 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0357 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 2s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0576 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0452 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 4s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0605 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.1597 - val_mse: 0.7578 - val_rmse: 0.8705 - 4s/epoch - 4ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 3s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.1541 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.1333 - val_mse: 0.7582 - val_rmse: 0.8707 - 3s/epoch - 4ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 3s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0946 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0568 - val_mse: 0.7581 - val_rmse: 0.8707 - 3s/epoch - 3ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 3s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0501 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.1065 - val_mse: 0.7581 - val_rmse: 0.8707 - 3s/epoch - 3ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 2s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0791 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0675 - val_mse: 0.7582 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 65: early stopping\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "INFO:tensorflow:Assets written to: ram://c2478859-7165-4ffd-93c0-3676888f26d0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://c2478859-7165-4ffd-93c0-3676888f26d0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 4 fold of 5 folds\n",
      "Training for 1 neuron in [1, 10, 100]\n",
      "Training for 1 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 1.1177 - cat_acc: 0.4825 - accuracy: 0.0000e+00 - mse: 0.2460 - rmse: 0.4960 - val_loss: 0.9458 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.3457 - val_rmse: 0.5880 - 2s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.9034 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.4453 - rmse: 0.6673 - val_loss: 0.8780 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.5239 - val_rmse: 0.7238 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.8650 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.5726 - rmse: 0.7567 - val_loss: 0.8566 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.6129 - val_rmse: 0.7829 - 1s/epoch - 1ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.8503 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.6392 - rmse: 0.7995 - val_loss: 0.8466 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.6618 - val_rmse: 0.8135 - 1s/epoch - 1ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.8412 - cat_acc: 0.4972 - accuracy: 0.0000e+00 - mse: 0.6680 - rmse: 0.8173 - val_loss: 0.8298 - val_cat_acc: 0.4965 - val_accuracy: 0.0000e+00 - val_mse: 0.6382 - val_rmse: 0.7989 - 1s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.8045 - cat_acc: 0.4961 - accuracy: 0.0000e+00 - mse: 0.6194 - rmse: 0.7870 - val_loss: 0.7837 - val_cat_acc: 0.4968 - val_accuracy: 0.0000e+00 - val_mse: 0.6162 - val_rmse: 0.7850 - 1s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.7694 - cat_acc: 0.4963 - accuracy: 0.0000e+00 - mse: 0.6224 - rmse: 0.7890 - val_loss: 0.7553 - val_cat_acc: 0.4963 - val_accuracy: 0.0000e+00 - val_mse: 0.6230 - val_rmse: 0.7893 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.7375 - cat_acc: 0.4939 - accuracy: 0.0000e+00 - mse: 0.6183 - rmse: 0.7863 - val_loss: 0.7201 - val_cat_acc: 0.4937 - val_accuracy: 0.0000e+00 - val_mse: 0.6197 - val_rmse: 0.7872 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.7064 - cat_acc: 0.4926 - accuracy: 0.0000e+00 - mse: 0.6257 - rmse: 0.7910 - val_loss: 0.6950 - val_cat_acc: 0.4929 - val_accuracy: 0.0000e+00 - val_mse: 0.6330 - val_rmse: 0.7956 - 1s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.6857 - cat_acc: 0.4926 - accuracy: 0.0000e+00 - mse: 0.6406 - rmse: 0.8003 - val_loss: 0.6783 - val_cat_acc: 0.4934 - val_accuracy: 0.0000e+00 - val_mse: 0.6485 - val_rmse: 0.8053 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.6712 - cat_acc: 0.4929 - accuracy: 0.0000e+00 - mse: 0.6547 - rmse: 0.8091 - val_loss: 0.6658 - val_cat_acc: 0.4943 - val_accuracy: 0.0000e+00 - val_mse: 0.6610 - val_rmse: 0.8130 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.6602 - cat_acc: 0.4931 - accuracy: 0.0000e+00 - mse: 0.6668 - rmse: 0.8166 - val_loss: 0.6561 - val_cat_acc: 0.4942 - val_accuracy: 0.0000e+00 - val_mse: 0.6716 - val_rmse: 0.8195 - 1s/epoch - 1ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.6516 - cat_acc: 0.4931 - accuracy: 0.0000e+00 - mse: 0.6771 - rmse: 0.8229 - val_loss: 0.6485 - val_cat_acc: 0.4938 - val_accuracy: 0.0000e+00 - val_mse: 0.6820 - val_rmse: 0.8258 - 1s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.6446 - cat_acc: 0.4934 - accuracy: 0.0000e+00 - mse: 0.6858 - rmse: 0.8281 - val_loss: 0.6423 - val_cat_acc: 0.4945 - val_accuracy: 0.0000e+00 - val_mse: 0.6903 - val_rmse: 0.8308 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.6391 - cat_acc: 0.4934 - accuracy: 0.0000e+00 - mse: 0.6935 - rmse: 0.8328 - val_loss: 0.6372 - val_cat_acc: 0.4940 - val_accuracy: 0.0000e+00 - val_mse: 0.6972 - val_rmse: 0.8350 - 1s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.6345 - cat_acc: 0.4936 - accuracy: 0.0000e+00 - mse: 0.6997 - rmse: 0.8365 - val_loss: 0.6334 - val_cat_acc: 0.4940 - val_accuracy: 0.0000e+00 - val_mse: 0.7033 - val_rmse: 0.8386 - 1s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.6306 - cat_acc: 0.4936 - accuracy: 0.0000e+00 - mse: 0.7052 - rmse: 0.8398 - val_loss: 0.6294 - val_cat_acc: 0.4942 - val_accuracy: 0.0000e+00 - val_mse: 0.7087 - val_rmse: 0.8419 - 1s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.6275 - cat_acc: 0.4938 - accuracy: 0.0000e+00 - mse: 0.7100 - rmse: 0.8426 - val_loss: 0.6266 - val_cat_acc: 0.4949 - val_accuracy: 0.0000e+00 - val_mse: 0.7110 - val_rmse: 0.8432 - 1s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.6249 - cat_acc: 0.4939 - accuracy: 1.5625e-05 - mse: 0.7138 - rmse: 0.8449 - val_loss: 0.6241 - val_cat_acc: 0.4945 - val_accuracy: 3.7500e-05 - val_mse: 0.7163 - val_rmse: 0.8464 - 1s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.6227 - cat_acc: 0.4940 - accuracy: 8.4375e-05 - mse: 0.7173 - rmse: 0.8469 - val_loss: 0.6229 - val_cat_acc: 0.4947 - val_accuracy: 1.6250e-04 - val_mse: 0.7183 - val_rmse: 0.8475 - 1s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.6208 - cat_acc: 0.4940 - accuracy: 1.4375e-04 - mse: 0.7201 - rmse: 0.8486 - val_loss: 0.6206 - val_cat_acc: 0.4945 - val_accuracy: 2.3750e-04 - val_mse: 0.7220 - val_rmse: 0.8497 - 1s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.6193 - cat_acc: 0.4941 - accuracy: 1.9062e-04 - mse: 0.7227 - rmse: 0.8501 - val_loss: 0.6192 - val_cat_acc: 0.4945 - val_accuracy: 3.0000e-04 - val_mse: 0.7245 - val_rmse: 0.8512 - 1s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.6178 - cat_acc: 0.4943 - accuracy: 2.3437e-04 - mse: 0.7250 - rmse: 0.8515 - val_loss: 0.6179 - val_cat_acc: 0.4949 - val_accuracy: 3.1250e-04 - val_mse: 0.7255 - val_rmse: 0.8518 - 1s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.6167 - cat_acc: 0.4942 - accuracy: 3.0625e-04 - mse: 0.7268 - rmse: 0.8525 - val_loss: 0.6168 - val_cat_acc: 0.4953 - val_accuracy: 3.1250e-04 - val_mse: 0.7278 - val_rmse: 0.8531 - 1s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.6157 - cat_acc: 0.4942 - accuracy: 3.8437e-04 - mse: 0.7286 - rmse: 0.8536 - val_loss: 0.6156 - val_cat_acc: 0.4944 - val_accuracy: 4.7500e-04 - val_mse: 0.7300 - val_rmse: 0.8544 - 1s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.6147 - cat_acc: 0.4942 - accuracy: 4.9062e-04 - mse: 0.7301 - rmse: 0.8545 - val_loss: 0.6160 - val_cat_acc: 0.4940 - val_accuracy: 5.7500e-04 - val_mse: 0.7308 - val_rmse: 0.8549 - 1s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.6139 - cat_acc: 0.4943 - accuracy: 7.3437e-04 - mse: 0.7314 - rmse: 0.8552 - val_loss: 0.6141 - val_cat_acc: 0.4951 - val_accuracy: 0.0010 - val_mse: 0.7318 - val_rmse: 0.8555 - 1s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.6132 - cat_acc: 0.4944 - accuracy: 0.0011 - mse: 0.7323 - rmse: 0.8558 - val_loss: 0.6133 - val_cat_acc: 0.4952 - val_accuracy: 0.0012 - val_mse: 0.7332 - val_rmse: 0.8563 - 1s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.6126 - cat_acc: 0.4944 - accuracy: 0.0016 - mse: 0.7335 - rmse: 0.8565 - val_loss: 0.6129 - val_cat_acc: 0.4943 - val_accuracy: 0.0014 - val_mse: 0.7353 - val_rmse: 0.8575 - 1s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.6121 - cat_acc: 0.4943 - accuracy: 0.0021 - mse: 0.7345 - rmse: 0.8570 - val_loss: 0.6123 - val_cat_acc: 0.4953 - val_accuracy: 0.0026 - val_mse: 0.7341 - val_rmse: 0.8568 - 1s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.6115 - cat_acc: 0.4945 - accuracy: 0.0027 - mse: 0.7351 - rmse: 0.8574 - val_loss: 0.6117 - val_cat_acc: 0.4949 - val_accuracy: 0.0031 - val_mse: 0.7362 - val_rmse: 0.8580 - 1s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.6111 - cat_acc: 0.4945 - accuracy: 0.0035 - mse: 0.7361 - rmse: 0.8580 - val_loss: 0.6113 - val_cat_acc: 0.4951 - val_accuracy: 0.0043 - val_mse: 0.7365 - val_rmse: 0.8582 - 1s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.6106 - cat_acc: 0.4945 - accuracy: 0.0044 - mse: 0.7367 - rmse: 0.8583 - val_loss: 0.6112 - val_cat_acc: 0.4951 - val_accuracy: 0.0053 - val_mse: 0.7374 - val_rmse: 0.8587 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.6104 - cat_acc: 0.4946 - accuracy: 0.0055 - mse: 0.7373 - rmse: 0.8587 - val_loss: 0.6107 - val_cat_acc: 0.4952 - val_accuracy: 0.0063 - val_mse: 0.7373 - val_rmse: 0.8586 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.6101 - cat_acc: 0.4945 - accuracy: 0.0068 - mse: 0.7378 - rmse: 0.8589 - val_loss: 0.6106 - val_cat_acc: 0.4951 - val_accuracy: 0.0071 - val_mse: 0.7389 - val_rmse: 0.8596 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.6097 - cat_acc: 0.4946 - accuracy: 0.0080 - mse: 0.7383 - rmse: 0.8592 - val_loss: 0.6099 - val_cat_acc: 0.4955 - val_accuracy: 0.0091 - val_mse: 0.7388 - val_rmse: 0.8596 - 1s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.6094 - cat_acc: 0.4946 - accuracy: 0.0093 - mse: 0.7389 - rmse: 0.8596 - val_loss: 0.6096 - val_cat_acc: 0.4949 - val_accuracy: 0.0103 - val_mse: 0.7393 - val_rmse: 0.8598 - 1s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 2s - loss: 0.6091 - cat_acc: 0.4946 - accuracy: 0.0106 - mse: 0.7393 - rmse: 0.8598 - val_loss: 0.6097 - val_cat_acc: 0.4949 - val_accuracy: 0.0118 - val_mse: 0.7394 - val_rmse: 0.8599 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 3s - loss: 0.6089 - cat_acc: 0.4946 - accuracy: 0.0119 - mse: 0.7397 - rmse: 0.8601 - val_loss: 0.6090 - val_cat_acc: 0.4952 - val_accuracy: 0.0132 - val_mse: 0.7404 - val_rmse: 0.8605 - 3s/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 2s - loss: 0.6086 - cat_acc: 0.4946 - accuracy: 0.0134 - mse: 0.7403 - rmse: 0.8604 - val_loss: 0.6089 - val_cat_acc: 0.4952 - val_accuracy: 0.0146 - val_mse: 0.7406 - val_rmse: 0.8606 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 2s - loss: 0.6085 - cat_acc: 0.4945 - accuracy: 0.0149 - mse: 0.7406 - rmse: 0.8606 - val_loss: 0.6094 - val_cat_acc: 0.4950 - val_accuracy: 0.0172 - val_mse: 0.7400 - val_rmse: 0.8602 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 2s - loss: 0.6083 - cat_acc: 0.4946 - accuracy: 0.0163 - mse: 0.7409 - rmse: 0.8608 - val_loss: 0.6086 - val_cat_acc: 0.4952 - val_accuracy: 0.0165 - val_mse: 0.7420 - val_rmse: 0.8614 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.6080 - cat_acc: 0.4945 - accuracy: 0.0175 - mse: 0.7413 - rmse: 0.8610 - val_loss: 0.6083 - val_cat_acc: 0.4947 - val_accuracy: 0.0169 - val_mse: 0.7427 - val_rmse: 0.8618 - 1s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 2s - loss: 0.6079 - cat_acc: 0.4947 - accuracy: 0.0192 - mse: 0.7415 - rmse: 0.8611 - val_loss: 0.6080 - val_cat_acc: 0.4951 - val_accuracy: 0.0198 - val_mse: 0.7423 - val_rmse: 0.8616 - 2s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.6078 - cat_acc: 0.4947 - accuracy: 0.0208 - mse: 0.7417 - rmse: 0.8612 - val_loss: 0.6093 - val_cat_acc: 0.4954 - val_accuracy: 0.0240 - val_mse: 0.7413 - val_rmse: 0.8610 - 1s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.6076 - cat_acc: 0.4948 - accuracy: 0.0224 - mse: 0.7421 - rmse: 0.8615 - val_loss: 0.6079 - val_cat_acc: 0.4953 - val_accuracy: 0.0239 - val_mse: 0.7420 - val_rmse: 0.8614 - 1s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.6074 - cat_acc: 0.4948 - accuracy: 0.0238 - mse: 0.7423 - rmse: 0.8615 - val_loss: 0.6078 - val_cat_acc: 0.4951 - val_accuracy: 0.0235 - val_mse: 0.7430 - val_rmse: 0.8620 - 1s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.6073 - cat_acc: 0.4948 - accuracy: 0.0251 - mse: 0.7427 - rmse: 0.8618 - val_loss: 0.6077 - val_cat_acc: 0.4951 - val_accuracy: 0.0251 - val_mse: 0.7433 - val_rmse: 0.8621 - 1s/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.6072 - cat_acc: 0.4947 - accuracy: 0.0267 - mse: 0.7428 - rmse: 0.8619 - val_loss: 0.6075 - val_cat_acc: 0.4955 - val_accuracy: 0.0291 - val_mse: 0.7427 - val_rmse: 0.8618 - 1s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.6070 - cat_acc: 0.4948 - accuracy: 0.0279 - mse: 0.7432 - rmse: 0.8621 - val_loss: 0.6074 - val_cat_acc: 0.4954 - val_accuracy: 0.0301 - val_mse: 0.7426 - val_rmse: 0.8617 - 1s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.6070 - cat_acc: 0.4947 - accuracy: 0.0299 - mse: 0.7431 - rmse: 0.8620 - val_loss: 0.6071 - val_cat_acc: 0.4953 - val_accuracy: 0.0297 - val_mse: 0.7439 - val_rmse: 0.8625 - 1s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.6068 - cat_acc: 0.4948 - accuracy: 0.0313 - mse: 0.7434 - rmse: 0.8622 - val_loss: 0.6086 - val_cat_acc: 0.4952 - val_accuracy: 0.0347 - val_mse: 0.7423 - val_rmse: 0.8616 - 1s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.6068 - cat_acc: 0.4948 - accuracy: 0.0326 - mse: 0.7437 - rmse: 0.8624 - val_loss: 0.6070 - val_cat_acc: 0.4954 - val_accuracy: 0.0343 - val_mse: 0.7435 - val_rmse: 0.8623 - 1s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.6066 - cat_acc: 0.4949 - accuracy: 0.0340 - mse: 0.7439 - rmse: 0.8625 - val_loss: 0.6068 - val_cat_acc: 0.4954 - val_accuracy: 0.0339 - val_mse: 0.7445 - val_rmse: 0.8629 - 1s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.6065 - cat_acc: 0.4948 - accuracy: 0.0353 - mse: 0.7440 - rmse: 0.8625 - val_loss: 0.6067 - val_cat_acc: 0.4949 - val_accuracy: 0.0321 - val_mse: 0.7454 - val_rmse: 0.8633 - 1s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.6064 - cat_acc: 0.4948 - accuracy: 0.0363 - mse: 0.7441 - rmse: 0.8626 - val_loss: 0.6068 - val_cat_acc: 0.4958 - val_accuracy: 0.0408 - val_mse: 0.7437 - val_rmse: 0.8624 - 1s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.6064 - cat_acc: 0.4948 - accuracy: 0.0375 - mse: 0.7445 - rmse: 0.8629 - val_loss: 0.6066 - val_cat_acc: 0.4955 - val_accuracy: 0.0403 - val_mse: 0.7440 - val_rmse: 0.8625 - 1s/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.6062 - cat_acc: 0.4949 - accuracy: 0.0392 - mse: 0.7444 - rmse: 0.8628 - val_loss: 0.6068 - val_cat_acc: 0.4953 - val_accuracy: 0.0408 - val_mse: 0.7446 - val_rmse: 0.8629 - 1s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.6063 - cat_acc: 0.4947 - accuracy: 0.0406 - mse: 0.7447 - rmse: 0.8630 - val_loss: 0.6064 - val_cat_acc: 0.4949 - val_accuracy: 0.0400 - val_mse: 0.7447 - val_rmse: 0.8630 - 1s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.6061 - cat_acc: 0.4948 - accuracy: 0.0419 - mse: 0.7447 - rmse: 0.8629 - val_loss: 0.6064 - val_cat_acc: 0.4953 - val_accuracy: 0.0416 - val_mse: 0.7450 - val_rmse: 0.8631 - 1s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.6060 - cat_acc: 0.4948 - accuracy: 0.0426 - mse: 0.7450 - rmse: 0.8631 - val_loss: 0.6074 - val_cat_acc: 0.4947 - val_accuracy: 0.0402 - val_mse: 0.7460 - val_rmse: 0.8637 - 1s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 1s - loss: 0.6059 - cat_acc: 0.4948 - accuracy: 0.0442 - mse: 0.7450 - rmse: 0.8631 - val_loss: 0.6065 - val_cat_acc: 0.4952 - val_accuracy: 0.0422 - val_mse: 0.7460 - val_rmse: 0.8637 - 1s/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 1s - loss: 0.6058 - cat_acc: 0.4950 - accuracy: 0.0451 - mse: 0.7451 - rmse: 0.8632 - val_loss: 0.6065 - val_cat_acc: 0.4951 - val_accuracy: 0.0443 - val_mse: 0.7458 - val_rmse: 0.8636 - 1s/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 1s - loss: 0.6058 - cat_acc: 0.4950 - accuracy: 0.0459 - mse: 0.7453 - rmse: 0.8633 - val_loss: 0.6060 - val_cat_acc: 0.4951 - val_accuracy: 0.0441 - val_mse: 0.7463 - val_rmse: 0.8639 - 1s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 1s - loss: 0.6057 - cat_acc: 0.4947 - accuracy: 0.0469 - mse: 0.7456 - rmse: 0.8635 - val_loss: 0.6060 - val_cat_acc: 0.4951 - val_accuracy: 0.0447 - val_mse: 0.7463 - val_rmse: 0.8639 - 1s/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "800/800 - 1s - loss: 0.6057 - cat_acc: 0.4949 - accuracy: 0.0478 - mse: 0.7456 - rmse: 0.8635 - val_loss: 0.6061 - val_cat_acc: 0.4954 - val_accuracy: 0.0483 - val_mse: 0.7460 - val_rmse: 0.8637 - 1s/epoch - 1ms/step\n",
      "Epoch 67/100\n",
      "800/800 - 1s - loss: 0.6057 - cat_acc: 0.4948 - accuracy: 0.0493 - mse: 0.7457 - rmse: 0.8635 - val_loss: 0.6061 - val_cat_acc: 0.4954 - val_accuracy: 0.0490 - val_mse: 0.7467 - val_rmse: 0.8641 - 1s/epoch - 1ms/step\n",
      "Epoch 68/100\n",
      "800/800 - 1s - loss: 0.6056 - cat_acc: 0.4948 - accuracy: 0.0506 - mse: 0.7458 - rmse: 0.8636 - val_loss: 0.6062 - val_cat_acc: 0.4947 - val_accuracy: 0.0490 - val_mse: 0.7465 - val_rmse: 0.8640 - 1s/epoch - 1ms/step\n",
      "Epoch 69/100\n",
      "800/800 - 1s - loss: 0.6055 - cat_acc: 0.4949 - accuracy: 0.0512 - mse: 0.7459 - rmse: 0.8637 - val_loss: 0.6059 - val_cat_acc: 0.4958 - val_accuracy: 0.0548 - val_mse: 0.7454 - val_rmse: 0.8633 - 1s/epoch - 1ms/step\n",
      "Epoch 70/100\n",
      "800/800 - 1s - loss: 0.6055 - cat_acc: 0.4948 - accuracy: 0.0523 - mse: 0.7460 - rmse: 0.8637 - val_loss: 0.6062 - val_cat_acc: 0.4949 - val_accuracy: 0.0494 - val_mse: 0.7466 - val_rmse: 0.8641 - 1s/epoch - 1ms/step\n",
      "Epoch 71/100\n",
      "800/800 - 1s - loss: 0.6054 - cat_acc: 0.4947 - accuracy: 0.0529 - mse: 0.7461 - rmse: 0.8638 - val_loss: 0.6064 - val_cat_acc: 0.4947 - val_accuracy: 0.0511 - val_mse: 0.7468 - val_rmse: 0.8642 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "800/800 - 1s - loss: 0.6053 - cat_acc: 0.4949 - accuracy: 0.0540 - mse: 0.7463 - rmse: 0.8639 - val_loss: 0.6058 - val_cat_acc: 0.4951 - val_accuracy: 0.0538 - val_mse: 0.7464 - val_rmse: 0.8640 - 1s/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "800/800 - 1s - loss: 0.6053 - cat_acc: 0.4948 - accuracy: 0.0551 - mse: 0.7464 - rmse: 0.8640 - val_loss: 0.6061 - val_cat_acc: 0.4956 - val_accuracy: 0.0601 - val_mse: 0.7454 - val_rmse: 0.8634 - 1s/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "800/800 - 1s - loss: 0.6053 - cat_acc: 0.4948 - accuracy: 0.0564 - mse: 0.7463 - rmse: 0.8639 - val_loss: 0.6058 - val_cat_acc: 0.4954 - val_accuracy: 0.0555 - val_mse: 0.7466 - val_rmse: 0.8641 - 1s/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "800/800 - 1s - loss: 0.6051 - cat_acc: 0.4950 - accuracy: 0.0571 - mse: 0.7464 - rmse: 0.8639 - val_loss: 0.6054 - val_cat_acc: 0.4955 - val_accuracy: 0.0547 - val_mse: 0.7475 - val_rmse: 0.8646 - 1s/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "800/800 - 3s - loss: 0.6050 - cat_acc: 0.4950 - accuracy: 0.0570 - mse: 0.7466 - rmse: 0.8641 - val_loss: 0.6055 - val_cat_acc: 0.4953 - val_accuracy: 0.0572 - val_mse: 0.7467 - val_rmse: 0.8641 - 3s/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "800/800 - 3s - loss: 0.6050 - cat_acc: 0.4950 - accuracy: 0.0583 - mse: 0.7465 - rmse: 0.8640 - val_loss: 0.6056 - val_cat_acc: 0.4951 - val_accuracy: 0.0582 - val_mse: 0.7471 - val_rmse: 0.8644 - 3s/epoch - 4ms/step\n",
      "Epoch 78/100\n",
      "800/800 - 1s - loss: 0.6051 - cat_acc: 0.4948 - accuracy: 0.0587 - mse: 0.7469 - rmse: 0.8642 - val_loss: 0.6052 - val_cat_acc: 0.4954 - val_accuracy: 0.0585 - val_mse: 0.7474 - val_rmse: 0.8645 - 1s/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "800/800 - 1s - loss: 0.6049 - cat_acc: 0.4949 - accuracy: 0.0598 - mse: 0.7469 - rmse: 0.8642 - val_loss: 0.6052 - val_cat_acc: 0.4954 - val_accuracy: 0.0594 - val_mse: 0.7474 - val_rmse: 0.8645 - 1s/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "800/800 - 1s - loss: 0.6049 - cat_acc: 0.4949 - accuracy: 0.0604 - mse: 0.7469 - rmse: 0.8642 - val_loss: 0.6054 - val_cat_acc: 0.4954 - val_accuracy: 0.0608 - val_mse: 0.7469 - val_rmse: 0.8642 - 1s/epoch - 1ms/step\n",
      "Epoch 81/100\n",
      "800/800 - 1s - loss: 0.6049 - cat_acc: 0.4951 - accuracy: 0.0613 - mse: 0.7470 - rmse: 0.8643 - val_loss: 0.6053 - val_cat_acc: 0.4949 - val_accuracy: 0.0560 - val_mse: 0.7482 - val_rmse: 0.8650 - 1s/epoch - 1ms/step\n",
      "Epoch 82/100\n",
      "800/800 - 1s - loss: 0.6049 - cat_acc: 0.4950 - accuracy: 0.0619 - mse: 0.7470 - rmse: 0.8643 - val_loss: 0.6053 - val_cat_acc: 0.4951 - val_accuracy: 0.0586 - val_mse: 0.7477 - val_rmse: 0.8647 - 1s/epoch - 1ms/step\n",
      "Epoch 83/100\n",
      "800/800 - 1s - loss: 0.6048 - cat_acc: 0.4950 - accuracy: 0.0622 - mse: 0.7471 - rmse: 0.8644 - val_loss: 0.6051 - val_cat_acc: 0.4954 - val_accuracy: 0.0637 - val_mse: 0.7476 - val_rmse: 0.8646 - 1s/epoch - 1ms/step\n",
      "Epoch 84/100\n",
      "800/800 - 1s - loss: 0.6049 - cat_acc: 0.4949 - accuracy: 0.0629 - mse: 0.7474 - rmse: 0.8645 - val_loss: 0.6054 - val_cat_acc: 0.4956 - val_accuracy: 0.0668 - val_mse: 0.7467 - val_rmse: 0.8641 - 1s/epoch - 1ms/step\n",
      "Epoch 85/100\n",
      "800/800 - 1s - loss: 0.6047 - cat_acc: 0.4948 - accuracy: 0.0637 - mse: 0.7474 - rmse: 0.8645 - val_loss: 0.6051 - val_cat_acc: 0.4953 - val_accuracy: 0.0623 - val_mse: 0.7475 - val_rmse: 0.8646 - 1s/epoch - 1ms/step\n",
      "Epoch 86/100\n",
      "800/800 - 1s - loss: 0.6048 - cat_acc: 0.4950 - accuracy: 0.0646 - mse: 0.7474 - rmse: 0.8645 - val_loss: 0.6053 - val_cat_acc: 0.4955 - val_accuracy: 0.0668 - val_mse: 0.7471 - val_rmse: 0.8643 - 1s/epoch - 1ms/step\n",
      "Epoch 87/100\n",
      "800/800 - 1s - loss: 0.6047 - cat_acc: 0.4950 - accuracy: 0.0652 - mse: 0.7474 - rmse: 0.8645 - val_loss: 0.6049 - val_cat_acc: 0.4951 - val_accuracy: 0.0621 - val_mse: 0.7481 - val_rmse: 0.8650 - 1s/epoch - 1ms/step\n",
      "Epoch 88/100\n",
      "800/800 - 1s - loss: 0.6046 - cat_acc: 0.4949 - accuracy: 0.0654 - mse: 0.7476 - rmse: 0.8647 - val_loss: 0.6049 - val_cat_acc: 0.4954 - val_accuracy: 0.0639 - val_mse: 0.7482 - val_rmse: 0.8650 - 1s/epoch - 1ms/step\n",
      "Epoch 89/100\n",
      "800/800 - 1s - loss: 0.6047 - cat_acc: 0.4950 - accuracy: 0.0666 - mse: 0.7475 - rmse: 0.8646 - val_loss: 0.6050 - val_cat_acc: 0.4956 - val_accuracy: 0.0667 - val_mse: 0.7481 - val_rmse: 0.8650 - 1s/epoch - 1ms/step\n",
      "Epoch 90/100\n",
      "800/800 - 1s - loss: 0.6045 - cat_acc: 0.4950 - accuracy: 0.0675 - mse: 0.7475 - rmse: 0.8646 - val_loss: 0.6048 - val_cat_acc: 0.4951 - val_accuracy: 0.0664 - val_mse: 0.7481 - val_rmse: 0.8649 - 1s/epoch - 1ms/step\n",
      "Epoch 91/100\n",
      "800/800 - 1s - loss: 0.6045 - cat_acc: 0.4950 - accuracy: 0.0680 - mse: 0.7477 - rmse: 0.8647 - val_loss: 0.6051 - val_cat_acc: 0.4960 - val_accuracy: 0.0689 - val_mse: 0.7480 - val_rmse: 0.8649 - 1s/epoch - 1ms/step\n",
      "Epoch 92/100\n",
      "800/800 - 1s - loss: 0.6045 - cat_acc: 0.4950 - accuracy: 0.0687 - mse: 0.7477 - rmse: 0.8647 - val_loss: 0.6050 - val_cat_acc: 0.4956 - val_accuracy: 0.0711 - val_mse: 0.7478 - val_rmse: 0.8648 - 1s/epoch - 1ms/step\n",
      "Epoch 93/100\n",
      "800/800 - 1s - loss: 0.6045 - cat_acc: 0.4950 - accuracy: 0.0692 - mse: 0.7477 - rmse: 0.8647 - val_loss: 0.6051 - val_cat_acc: 0.4954 - val_accuracy: 0.0682 - val_mse: 0.7490 - val_rmse: 0.8655 - 1s/epoch - 1ms/step\n",
      "Epoch 94/100\n",
      "800/800 - 1s - loss: 0.6044 - cat_acc: 0.4950 - accuracy: 0.0698 - mse: 0.7479 - rmse: 0.8648 - val_loss: 0.6047 - val_cat_acc: 0.4955 - val_accuracy: 0.0710 - val_mse: 0.7478 - val_rmse: 0.8648 - 1s/epoch - 1ms/step\n",
      "Epoch 95/100\n",
      "800/800 - 1s - loss: 0.6044 - cat_acc: 0.4950 - accuracy: 0.0707 - mse: 0.7479 - rmse: 0.8648 - val_loss: 0.6050 - val_cat_acc: 0.4959 - val_accuracy: 0.0715 - val_mse: 0.7476 - val_rmse: 0.8647 - 1s/epoch - 1ms/step\n",
      "Epoch 96/100\n",
      "800/800 - 1s - loss: 0.6043 - cat_acc: 0.4950 - accuracy: 0.0709 - mse: 0.7479 - rmse: 0.8648 - val_loss: 0.6049 - val_cat_acc: 0.4958 - val_accuracy: 0.0717 - val_mse: 0.7482 - val_rmse: 0.8650 - 1s/epoch - 1ms/step\n",
      "Epoch 97/100\n",
      "800/800 - 1s - loss: 0.6043 - cat_acc: 0.4950 - accuracy: 0.0716 - mse: 0.7479 - rmse: 0.8648 - val_loss: 0.6045 - val_cat_acc: 0.4954 - val_accuracy: 0.0713 - val_mse: 0.7485 - val_rmse: 0.8652 - 1s/epoch - 1ms/step\n",
      "Epoch 98/100\n",
      "800/800 - 1s - loss: 0.6045 - cat_acc: 0.4950 - accuracy: 0.0719 - mse: 0.7480 - rmse: 0.8649 - val_loss: 0.6052 - val_cat_acc: 0.4949 - val_accuracy: 0.0708 - val_mse: 0.7481 - val_rmse: 0.8649 - 1s/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "800/800 - 1s - loss: 0.6043 - cat_acc: 0.4949 - accuracy: 0.0723 - mse: 0.7480 - rmse: 0.8649 - val_loss: 0.6051 - val_cat_acc: 0.4957 - val_accuracy: 0.0779 - val_mse: 0.7475 - val_rmse: 0.8646 - 1s/epoch - 1ms/step\n",
      "Epoch 100/100\n",
      "800/800 - 1s - loss: 0.6043 - cat_acc: 0.4950 - accuracy: 0.0739 - mse: 0.7480 - rmse: 0.8649 - val_loss: 0.6046 - val_cat_acc: 0.4949 - val_accuracy: 0.0682 - val_mse: 0.7497 - val_rmse: 0.8658 - 1s/epoch - 1ms/step\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "INFO:tensorflow:Assets written to: ram://06b15311-211e-4ae6-9ace-986cd51b920a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://06b15311-211e-4ae6-9ace-986cd51b920a/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 1.1179 - cat_acc: 0.4899 - accuracy: 0.0000e+00 - mse: 0.2459 - rmse: 0.4959 - val_loss: 0.9463 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.3452 - val_rmse: 0.5875 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.9038 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.4442 - rmse: 0.6665 - val_loss: 0.8783 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.5230 - val_rmse: 0.7232 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.8652 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.5717 - rmse: 0.7561 - val_loss: 0.8568 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.6121 - val_rmse: 0.7824 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.8504 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.6387 - rmse: 0.7992 - val_loss: 0.8467 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.6612 - val_rmse: 0.8131 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.8417 - cat_acc: 0.4973 - accuracy: 0.0000e+00 - mse: 0.6697 - rmse: 0.8184 - val_loss: 0.8324 - val_cat_acc: 0.4970 - val_accuracy: 0.0000e+00 - val_mse: 0.6483 - val_rmse: 0.8051 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.8063 - cat_acc: 0.4961 - accuracy: 0.0000e+00 - mse: 0.6209 - rmse: 0.7880 - val_loss: 0.7850 - val_cat_acc: 0.4968 - val_accuracy: 0.0000e+00 - val_mse: 0.6177 - val_rmse: 0.7859 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.7702 - cat_acc: 0.4963 - accuracy: 0.0000e+00 - mse: 0.6218 - rmse: 0.7886 - val_loss: 0.7562 - val_cat_acc: 0.4961 - val_accuracy: 0.0000e+00 - val_mse: 0.6232 - val_rmse: 0.7894 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.7384 - cat_acc: 0.4938 - accuracy: 0.0000e+00 - mse: 0.6188 - rmse: 0.7866 - val_loss: 0.7211 - val_cat_acc: 0.4935 - val_accuracy: 0.0000e+00 - val_mse: 0.6188 - val_rmse: 0.7866 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.7071 - cat_acc: 0.4928 - accuracy: 0.0000e+00 - mse: 0.6255 - rmse: 0.7909 - val_loss: 0.6957 - val_cat_acc: 0.4931 - val_accuracy: 0.0000e+00 - val_mse: 0.6331 - val_rmse: 0.7957 - 1s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.6861 - cat_acc: 0.4928 - accuracy: 0.0000e+00 - mse: 0.6403 - rmse: 0.8002 - val_loss: 0.6785 - val_cat_acc: 0.4933 - val_accuracy: 0.0000e+00 - val_mse: 0.6477 - val_rmse: 0.8048 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.6716 - cat_acc: 0.4928 - accuracy: 0.0000e+00 - mse: 0.6543 - rmse: 0.8089 - val_loss: 0.6671 - val_cat_acc: 0.4941 - val_accuracy: 0.0000e+00 - val_mse: 0.6605 - val_rmse: 0.8127 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.6605 - cat_acc: 0.4931 - accuracy: 0.0000e+00 - mse: 0.6664 - rmse: 0.8163 - val_loss: 0.6566 - val_cat_acc: 0.4926 - val_accuracy: 0.0000e+00 - val_mse: 0.6728 - val_rmse: 0.8202 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 2s - loss: 0.6518 - cat_acc: 0.4932 - accuracy: 0.0000e+00 - mse: 0.6768 - rmse: 0.8227 - val_loss: 0.6487 - val_cat_acc: 0.4940 - val_accuracy: 0.0000e+00 - val_mse: 0.6815 - val_rmse: 0.8256 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 2s - loss: 0.6449 - cat_acc: 0.4935 - accuracy: 0.0000e+00 - mse: 0.6857 - rmse: 0.8281 - val_loss: 0.6426 - val_cat_acc: 0.4940 - val_accuracy: 0.0000e+00 - val_mse: 0.6901 - val_rmse: 0.8307 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.6392 - cat_acc: 0.4935 - accuracy: 0.0000e+00 - mse: 0.6931 - rmse: 0.8325 - val_loss: 0.6374 - val_cat_acc: 0.4938 - val_accuracy: 0.0000e+00 - val_mse: 0.6972 - val_rmse: 0.8350 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 2s - loss: 0.6346 - cat_acc: 0.4936 - accuracy: 0.0000e+00 - mse: 0.6996 - rmse: 0.8364 - val_loss: 0.6332 - val_cat_acc: 0.4945 - val_accuracy: 0.0000e+00 - val_mse: 0.7029 - val_rmse: 0.8384 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.6309 - cat_acc: 0.4937 - accuracy: 0.0000e+00 - mse: 0.7051 - rmse: 0.8397 - val_loss: 0.6301 - val_cat_acc: 0.4943 - val_accuracy: 0.0000e+00 - val_mse: 0.7074 - val_rmse: 0.8411 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 2s - loss: 0.6277 - cat_acc: 0.4937 - accuracy: 0.0000e+00 - mse: 0.7096 - rmse: 0.8424 - val_loss: 0.6266 - val_cat_acc: 0.4947 - val_accuracy: 0.0000e+00 - val_mse: 0.7118 - val_rmse: 0.8437 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 2s - loss: 0.6250 - cat_acc: 0.4939 - accuracy: 1.8750e-05 - mse: 0.7137 - rmse: 0.8448 - val_loss: 0.6246 - val_cat_acc: 0.4947 - val_accuracy: 2.5000e-05 - val_mse: 0.7156 - val_rmse: 0.8460 - 2s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.6227 - cat_acc: 0.4939 - accuracy: 8.7500e-05 - mse: 0.7172 - rmse: 0.8469 - val_loss: 0.6221 - val_cat_acc: 0.4948 - val_accuracy: 1.6250e-04 - val_mse: 0.7187 - val_rmse: 0.8477 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.6208 - cat_acc: 0.4940 - accuracy: 1.4375e-04 - mse: 0.7200 - rmse: 0.8486 - val_loss: 0.6218 - val_cat_acc: 0.4942 - val_accuracy: 2.3750e-04 - val_mse: 0.7222 - val_rmse: 0.8498 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.6193 - cat_acc: 0.4939 - accuracy: 2.0625e-04 - mse: 0.7226 - rmse: 0.8501 - val_loss: 0.6189 - val_cat_acc: 0.4949 - val_accuracy: 3.0000e-04 - val_mse: 0.7245 - val_rmse: 0.8512 - 1s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.6178 - cat_acc: 0.4944 - accuracy: 2.4062e-04 - mse: 0.7250 - rmse: 0.8514 - val_loss: 0.6179 - val_cat_acc: 0.4943 - val_accuracy: 3.1250e-04 - val_mse: 0.7268 - val_rmse: 0.8525 - 1s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 2s - loss: 0.6166 - cat_acc: 0.4942 - accuracy: 2.9063e-04 - mse: 0.7268 - rmse: 0.8525 - val_loss: 0.6165 - val_cat_acc: 0.4949 - val_accuracy: 3.6250e-04 - val_mse: 0.7283 - val_rmse: 0.8534 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 2s - loss: 0.6157 - cat_acc: 0.4943 - accuracy: 3.8437e-04 - mse: 0.7284 - rmse: 0.8535 - val_loss: 0.6165 - val_cat_acc: 0.4938 - val_accuracy: 3.5000e-04 - val_mse: 0.7307 - val_rmse: 0.8548 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.6148 - cat_acc: 0.4942 - accuracy: 5.3125e-04 - mse: 0.7299 - rmse: 0.8544 - val_loss: 0.6148 - val_cat_acc: 0.4951 - val_accuracy: 6.2500e-04 - val_mse: 0.7305 - val_rmse: 0.8547 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.6140 - cat_acc: 0.4943 - accuracy: 7.3750e-04 - mse: 0.7313 - rmse: 0.8551 - val_loss: 0.6138 - val_cat_acc: 0.4949 - val_accuracy: 8.5000e-04 - val_mse: 0.7321 - val_rmse: 0.8556 - 1s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.6133 - cat_acc: 0.4944 - accuracy: 0.0011 - mse: 0.7324 - rmse: 0.8558 - val_loss: 0.6133 - val_cat_acc: 0.4952 - val_accuracy: 0.0013 - val_mse: 0.7333 - val_rmse: 0.8563 - 1s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.6126 - cat_acc: 0.4944 - accuracy: 0.0015 - mse: 0.7335 - rmse: 0.8564 - val_loss: 0.6129 - val_cat_acc: 0.4947 - val_accuracy: 0.0022 - val_mse: 0.7333 - val_rmse: 0.8563 - 1s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.6121 - cat_acc: 0.4944 - accuracy: 0.0021 - mse: 0.7345 - rmse: 0.8570 - val_loss: 0.6128 - val_cat_acc: 0.4954 - val_accuracy: 0.0025 - val_mse: 0.7344 - val_rmse: 0.8570 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.6115 - cat_acc: 0.4946 - accuracy: 0.0028 - mse: 0.7352 - rmse: 0.8574 - val_loss: 0.6122 - val_cat_acc: 0.4943 - val_accuracy: 0.0036 - val_mse: 0.7352 - val_rmse: 0.8574 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.6111 - cat_acc: 0.4944 - accuracy: 0.0037 - mse: 0.7361 - rmse: 0.8580 - val_loss: 0.6113 - val_cat_acc: 0.4951 - val_accuracy: 0.0046 - val_mse: 0.7359 - val_rmse: 0.8578 - 1s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.6108 - cat_acc: 0.4945 - accuracy: 0.0048 - mse: 0.7366 - rmse: 0.8583 - val_loss: 0.6109 - val_cat_acc: 0.4952 - val_accuracy: 0.0052 - val_mse: 0.7374 - val_rmse: 0.8587 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.6104 - cat_acc: 0.4945 - accuracy: 0.0058 - mse: 0.7374 - rmse: 0.8587 - val_loss: 0.6109 - val_cat_acc: 0.4954 - val_accuracy: 0.0071 - val_mse: 0.7366 - val_rmse: 0.8583 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.6101 - cat_acc: 0.4946 - accuracy: 0.0069 - mse: 0.7380 - rmse: 0.8590 - val_loss: 0.6101 - val_cat_acc: 0.4951 - val_accuracy: 0.0076 - val_mse: 0.7384 - val_rmse: 0.8593 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.6097 - cat_acc: 0.4946 - accuracy: 0.0081 - mse: 0.7384 - rmse: 0.8593 - val_loss: 0.6102 - val_cat_acc: 0.4947 - val_accuracy: 0.0082 - val_mse: 0.7397 - val_rmse: 0.8601 - 1s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.6095 - cat_acc: 0.4945 - accuracy: 0.0094 - mse: 0.7389 - rmse: 0.8596 - val_loss: 0.6097 - val_cat_acc: 0.4951 - val_accuracy: 0.0098 - val_mse: 0.7402 - val_rmse: 0.8603 - 1s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.6092 - cat_acc: 0.4945 - accuracy: 0.0106 - mse: 0.7394 - rmse: 0.8599 - val_loss: 0.6094 - val_cat_acc: 0.4953 - val_accuracy: 0.0115 - val_mse: 0.7398 - val_rmse: 0.8601 - 1s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.6089 - cat_acc: 0.4946 - accuracy: 0.0120 - mse: 0.7398 - rmse: 0.8601 - val_loss: 0.6093 - val_cat_acc: 0.4949 - val_accuracy: 0.0127 - val_mse: 0.7406 - val_rmse: 0.8606 - 1s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.6087 - cat_acc: 0.4947 - accuracy: 0.0135 - mse: 0.7401 - rmse: 0.8603 - val_loss: 0.6091 - val_cat_acc: 0.4947 - val_accuracy: 0.0127 - val_mse: 0.7418 - val_rmse: 0.8613 - 1s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.6085 - cat_acc: 0.4946 - accuracy: 0.0147 - mse: 0.7406 - rmse: 0.8606 - val_loss: 0.6089 - val_cat_acc: 0.4954 - val_accuracy: 0.0170 - val_mse: 0.7404 - val_rmse: 0.8605 - 1s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.6083 - cat_acc: 0.4946 - accuracy: 0.0164 - mse: 0.7409 - rmse: 0.8607 - val_loss: 0.6086 - val_cat_acc: 0.4950 - val_accuracy: 0.0174 - val_mse: 0.7414 - val_rmse: 0.8610 - 1s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.6081 - cat_acc: 0.4947 - accuracy: 0.0179 - mse: 0.7412 - rmse: 0.8609 - val_loss: 0.6085 - val_cat_acc: 0.4949 - val_accuracy: 0.0189 - val_mse: 0.7416 - val_rmse: 0.8612 - 1s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.6079 - cat_acc: 0.4947 - accuracy: 0.0191 - mse: 0.7416 - rmse: 0.8612 - val_loss: 0.6080 - val_cat_acc: 0.4954 - val_accuracy: 0.0215 - val_mse: 0.7412 - val_rmse: 0.8610 - 1s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.6077 - cat_acc: 0.4947 - accuracy: 0.0208 - mse: 0.7419 - rmse: 0.8613 - val_loss: 0.6084 - val_cat_acc: 0.4954 - val_accuracy: 0.0230 - val_mse: 0.7414 - val_rmse: 0.8611 - 1s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.6076 - cat_acc: 0.4947 - accuracy: 0.0224 - mse: 0.7421 - rmse: 0.8614 - val_loss: 0.6080 - val_cat_acc: 0.4954 - val_accuracy: 0.0239 - val_mse: 0.7420 - val_rmse: 0.8614 - 1s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.6075 - cat_acc: 0.4947 - accuracy: 0.0242 - mse: 0.7423 - rmse: 0.8616 - val_loss: 0.6076 - val_cat_acc: 0.4953 - val_accuracy: 0.0247 - val_mse: 0.7428 - val_rmse: 0.8619 - 1s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.6074 - cat_acc: 0.4946 - accuracy: 0.0253 - mse: 0.7427 - rmse: 0.8618 - val_loss: 0.6077 - val_cat_acc: 0.4946 - val_accuracy: 0.0242 - val_mse: 0.7435 - val_rmse: 0.8623 - 1s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.6073 - cat_acc: 0.4946 - accuracy: 0.0271 - mse: 0.7427 - rmse: 0.8618 - val_loss: 0.6076 - val_cat_acc: 0.4953 - val_accuracy: 0.0278 - val_mse: 0.7433 - val_rmse: 0.8621 - 1s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.6071 - cat_acc: 0.4948 - accuracy: 0.0285 - mse: 0.7430 - rmse: 0.8620 - val_loss: 0.6072 - val_cat_acc: 0.4951 - val_accuracy: 0.0289 - val_mse: 0.7432 - val_rmse: 0.8621 - 1s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.6069 - cat_acc: 0.4945 - accuracy: 0.0298 - mse: 0.7432 - rmse: 0.8621 - val_loss: 0.6073 - val_cat_acc: 0.4951 - val_accuracy: 0.0297 - val_mse: 0.7437 - val_rmse: 0.8624 - 1s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.6069 - cat_acc: 0.4947 - accuracy: 0.0313 - mse: 0.7433 - rmse: 0.8622 - val_loss: 0.6073 - val_cat_acc: 0.4956 - val_accuracy: 0.0316 - val_mse: 0.7444 - val_rmse: 0.8628 - 1s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.6067 - cat_acc: 0.4949 - accuracy: 0.0322 - mse: 0.7437 - rmse: 0.8624 - val_loss: 0.6075 - val_cat_acc: 0.4961 - val_accuracy: 0.0378 - val_mse: 0.7425 - val_rmse: 0.8617 - 1s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 2s - loss: 0.6065 - cat_acc: 0.4949 - accuracy: 0.0336 - mse: 0.7439 - rmse: 0.8625 - val_loss: 0.6069 - val_cat_acc: 0.4955 - val_accuracy: 0.0351 - val_mse: 0.7441 - val_rmse: 0.8626 - 2s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 2s - loss: 0.6065 - cat_acc: 0.4948 - accuracy: 0.0352 - mse: 0.7440 - rmse: 0.8626 - val_loss: 0.6068 - val_cat_acc: 0.4956 - val_accuracy: 0.0366 - val_mse: 0.7442 - val_rmse: 0.8627 - 2s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.6063 - cat_acc: 0.4947 - accuracy: 0.0363 - mse: 0.7441 - rmse: 0.8626 - val_loss: 0.6074 - val_cat_acc: 0.4951 - val_accuracy: 0.0355 - val_mse: 0.7446 - val_rmse: 0.8629 - 1s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.6064 - cat_acc: 0.4947 - accuracy: 0.0377 - mse: 0.7444 - rmse: 0.8628 - val_loss: 0.6067 - val_cat_acc: 0.4954 - val_accuracy: 0.0397 - val_mse: 0.7443 - val_rmse: 0.8627 - 1s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 2s - loss: 0.6062 - cat_acc: 0.4948 - accuracy: 0.0388 - mse: 0.7445 - rmse: 0.8629 - val_loss: 0.6062 - val_cat_acc: 0.4954 - val_accuracy: 0.0388 - val_mse: 0.7451 - val_rmse: 0.8632 - 2s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 2s - loss: 0.6061 - cat_acc: 0.4948 - accuracy: 0.0398 - mse: 0.7447 - rmse: 0.8630 - val_loss: 0.6066 - val_cat_acc: 0.4951 - val_accuracy: 0.0389 - val_mse: 0.7452 - val_rmse: 0.8632 - 2s/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.6062 - cat_acc: 0.4947 - accuracy: 0.0411 - mse: 0.7449 - rmse: 0.8631 - val_loss: 0.6069 - val_cat_acc: 0.4956 - val_accuracy: 0.0448 - val_mse: 0.7439 - val_rmse: 0.8625 - 1s/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.6060 - cat_acc: 0.4949 - accuracy: 0.0423 - mse: 0.7449 - rmse: 0.8631 - val_loss: 0.6062 - val_cat_acc: 0.4952 - val_accuracy: 0.0405 - val_mse: 0.7460 - val_rmse: 0.8637 - 1s/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 2s - loss: 0.6059 - cat_acc: 0.4949 - accuracy: 0.0433 - mse: 0.7451 - rmse: 0.8632 - val_loss: 0.6062 - val_cat_acc: 0.4953 - val_accuracy: 0.0426 - val_mse: 0.7460 - val_rmse: 0.8637 - 2s/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 2s - loss: 0.6058 - cat_acc: 0.4948 - accuracy: 0.0444 - mse: 0.7453 - rmse: 0.8633 - val_loss: 0.6068 - val_cat_acc: 0.4951 - val_accuracy: 0.0456 - val_mse: 0.7453 - val_rmse: 0.8633 - 2s/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 1s - loss: 0.6057 - cat_acc: 0.4948 - accuracy: 0.0456 - mse: 0.7454 - rmse: 0.8633 - val_loss: 0.6059 - val_cat_acc: 0.4954 - val_accuracy: 0.0464 - val_mse: 0.7458 - val_rmse: 0.8636 - 1s/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 1s - loss: 0.6057 - cat_acc: 0.4948 - accuracy: 0.0469 - mse: 0.7455 - rmse: 0.8634 - val_loss: 0.6063 - val_cat_acc: 0.4952 - val_accuracy: 0.0466 - val_mse: 0.7459 - val_rmse: 0.8637 - 1s/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "800/800 - 1s - loss: 0.6056 - cat_acc: 0.4950 - accuracy: 0.0476 - mse: 0.7457 - rmse: 0.8635 - val_loss: 0.6058 - val_cat_acc: 0.4954 - val_accuracy: 0.0484 - val_mse: 0.7460 - val_rmse: 0.8637 - 1s/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "800/800 - 1s - loss: 0.6056 - cat_acc: 0.4949 - accuracy: 0.0490 - mse: 0.7457 - rmse: 0.8635 - val_loss: 0.6065 - val_cat_acc: 0.4945 - val_accuracy: 0.0445 - val_mse: 0.7470 - val_rmse: 0.8643 - 1s/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "800/800 - 1s - loss: 0.6056 - cat_acc: 0.4948 - accuracy: 0.0497 - mse: 0.7459 - rmse: 0.8637 - val_loss: 0.6057 - val_cat_acc: 0.4956 - val_accuracy: 0.0494 - val_mse: 0.7467 - val_rmse: 0.8641 - 1s/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "800/800 - 1s - loss: 0.6054 - cat_acc: 0.4950 - accuracy: 0.0511 - mse: 0.7457 - rmse: 0.8636 - val_loss: 0.6056 - val_cat_acc: 0.4954 - val_accuracy: 0.0514 - val_mse: 0.7465 - val_rmse: 0.8640 - 1s/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "800/800 - 1s - loss: 0.6054 - cat_acc: 0.4948 - accuracy: 0.0517 - mse: 0.7461 - rmse: 0.8638 - val_loss: 0.6055 - val_cat_acc: 0.4953 - val_accuracy: 0.0503 - val_mse: 0.7467 - val_rmse: 0.8641 - 1s/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "800/800 - 1s - loss: 0.6053 - cat_acc: 0.4950 - accuracy: 0.0529 - mse: 0.7461 - rmse: 0.8638 - val_loss: 0.6059 - val_cat_acc: 0.4953 - val_accuracy: 0.0544 - val_mse: 0.7462 - val_rmse: 0.8638 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "800/800 - 1s - loss: 0.6053 - cat_acc: 0.4948 - accuracy: 0.0541 - mse: 0.7461 - rmse: 0.8638 - val_loss: 0.6055 - val_cat_acc: 0.4954 - val_accuracy: 0.0533 - val_mse: 0.7473 - val_rmse: 0.8645 - 1s/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "800/800 - 1s - loss: 0.6052 - cat_acc: 0.4949 - accuracy: 0.0544 - mse: 0.7464 - rmse: 0.8639 - val_loss: 0.6058 - val_cat_acc: 0.4953 - val_accuracy: 0.0539 - val_mse: 0.7471 - val_rmse: 0.8644 - 1s/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "800/800 - 1s - loss: 0.6052 - cat_acc: 0.4949 - accuracy: 0.0556 - mse: 0.7464 - rmse: 0.8639 - val_loss: 0.6056 - val_cat_acc: 0.4958 - val_accuracy: 0.0582 - val_mse: 0.7466 - val_rmse: 0.8641 - 1s/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "800/800 - 1s - loss: 0.6051 - cat_acc: 0.4950 - accuracy: 0.0566 - mse: 0.7464 - rmse: 0.8639 - val_loss: 0.6060 - val_cat_acc: 0.4946 - val_accuracy: 0.0543 - val_mse: 0.7470 - val_rmse: 0.8643 - 1s/epoch - 2ms/step\n",
      "Epoch 75: early stopping\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "INFO:tensorflow:Assets written to: ram://87bc6d34-768b-40da-b1c3-f71b37daf504/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://87bc6d34-768b-40da-b1c3-f71b37daf504/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 neuron in [1, 10, 100]\n",
      "Training for 1 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 3s - loss: 0.6607 - cat_acc: 0.9388 - accuracy: 0.0000e+00 - mse: 0.3529 - rmse: 0.5941 - val_loss: 0.4165 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.5622 - val_rmse: 0.7498 - 3s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.3834 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.6557 - rmse: 0.8098 - val_loss: 0.3710 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7078 - val_rmse: 0.8413 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.3654 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7230 - rmse: 0.8503 - val_loss: 0.3647 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7353 - val_rmse: 0.8575 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3615 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7401 - rmse: 0.8603 - val_loss: 0.3625 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7456 - val_rmse: 0.8635 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3599 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7473 - rmse: 0.8645 - val_loss: 0.3614 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7504 - val_rmse: 0.8663 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.3590 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7508 - rmse: 0.8665 - val_loss: 0.3606 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7530 - val_rmse: 0.8677 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3583 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7527 - rmse: 0.8676 - val_loss: 0.3600 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7544 - val_rmse: 0.8686 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3578 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7538 - rmse: 0.8682 - val_loss: 0.3595 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7553 - val_rmse: 0.8691 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.3574 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7546 - rmse: 0.8687 - val_loss: 0.3592 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7559 - val_rmse: 0.8694 - 1s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3570 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7552 - rmse: 0.8690 - val_loss: 0.3588 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7565 - val_rmse: 0.8698 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3568 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7556 - rmse: 0.8693 - val_loss: 0.3587 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7567 - val_rmse: 0.8699 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3565 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7559 - rmse: 0.8694 - val_loss: 0.3584 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7571 - val_rmse: 0.8701 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7562 - rmse: 0.8696 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7573 - val_rmse: 0.8702 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 6.2500e-06 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7575 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 2.8125e-05 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 5.3750e-04 - val_mse: 0.7575 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 1.2187e-04 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 2.0000e-04 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 4.7813e-04 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 4.8750e-04 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 9.4062e-04 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0011 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0014 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0012 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0023 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0043 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0034 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0042 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0049 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0042 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0055 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0040 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0087 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0093 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 2s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0091 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0075 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 2s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0101 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0105 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 2s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0115 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0088 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 2s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0111 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0139 - val_mse: 0.7580 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 2s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0144 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0127 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 2s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0145 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0125 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 2s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0195 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0134 - val_mse: 0.7580 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0156 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0122 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 2s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0169 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0157 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0178 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0181 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0274 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0423 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0242 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0221 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0216 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0234 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0222 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0264 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0254 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0216 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0214 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0240 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0270 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0266 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0261 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0227 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0297 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0239 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0280 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0359 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0325 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0314 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0381 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0232 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0326 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0349 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0355 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0557 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0397 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0420 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0361 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0524 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0436 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0324 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0749 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0439 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 2s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0434 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0547 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0433 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0315 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0400 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0446 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0376 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0329 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0694 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0547 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0516 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0517 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0411 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0597 - val_mse: 0.7571 - val_rmse: 0.8701 - 1s/epoch - 2ms/step\n",
      "Epoch 59: early stopping\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "INFO:tensorflow:Assets written to: ram://16dbc13d-2cfb-49a9-956c-a0a847ca68b2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://16dbc13d-2cfb-49a9-956c-a0a847ca68b2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 3s - loss: 0.6431 - cat_acc: 0.9671 - accuracy: 0.0000e+00 - mse: 0.3575 - rmse: 0.5979 - val_loss: 0.4137 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.5621 - val_rmse: 0.7497 - 3s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.3864 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.6434 - rmse: 0.8022 - val_loss: 0.3743 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.6951 - val_rmse: 0.8337 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.3673 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7160 - rmse: 0.8462 - val_loss: 0.3655 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7333 - val_rmse: 0.8563 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3619 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7398 - rmse: 0.8601 - val_loss: 0.3625 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7463 - val_rmse: 0.8639 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3599 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7480 - rmse: 0.8649 - val_loss: 0.3612 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7513 - val_rmse: 0.8668 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 2s - loss: 0.3589 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7515 - rmse: 0.8669 - val_loss: 0.3605 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7537 - val_rmse: 0.8681 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 2s - loss: 0.3583 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7533 - rmse: 0.8679 - val_loss: 0.3599 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7549 - val_rmse: 0.8689 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 2s - loss: 0.3578 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7543 - rmse: 0.8685 - val_loss: 0.3595 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7557 - val_rmse: 0.8693 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 2s - loss: 0.3574 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7549 - rmse: 0.8689 - val_loss: 0.3591 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7563 - val_rmse: 0.8696 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 2s - loss: 0.3570 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7554 - rmse: 0.8691 - val_loss: 0.3589 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7566 - val_rmse: 0.8699 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 2s - loss: 0.3568 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7557 - rmse: 0.8693 - val_loss: 0.3587 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7568 - val_rmse: 0.8699 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3566 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7560 - rmse: 0.8695 - val_loss: 0.3584 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7571 - val_rmse: 0.8701 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3564 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7562 - rmse: 0.8696 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 3.1250e-06 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 5.0000e-05 - val_mse: 0.7575 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 1.1875e-04 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 8.2500e-04 - val_mse: 0.7575 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 3.5313e-04 - mse: 0.7566 - rmse: 0.8699 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 3.8750e-04 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 8.1250e-04 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0011 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0012 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0013 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0018 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0016 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0027 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0040 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0040 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0037 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0048 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0054 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0061 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0103 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0075 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0098 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0083 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0145 - val_mse: 0.7573 - val_rmse: 0.8702 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0114 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0114 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0115 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0088 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0123 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0114 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0156 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0202 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0194 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0161 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0156 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0147 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0156 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0242 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0234 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0186 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0188 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0238 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0210 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0255 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0209 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0384 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0239 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0207 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0325 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0467 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0302 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0233 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 2s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0278 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0219 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 3ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 2s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0266 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0314 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0334 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0480 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0356 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0253 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0307 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0303 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0443 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0882 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0597 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0430 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0386 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0302 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0459 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0430 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0467 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0361 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0520 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0656 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0483 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0360 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0371 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0468 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0423 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0400 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0471 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0410 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 2s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0467 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0562 - val_mse: 0.7580 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 2s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0480 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0404 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0519 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0441 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0472 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0464 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0492 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0520 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0541 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0582 - val_mse: 0.7575 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0676 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0668 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0531 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0497 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0467 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0391 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0820 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0726 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0606 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0505 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0740 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0585 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0558 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0481 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0535 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0684 - val_mse: 0.7579 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0844 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0799 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0647 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0585 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0614 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0689 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.1035 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0844 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "800/800 - 2s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0747 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0689 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "800/800 - 2s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0584 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3573 - val_cat_acc: 0.9918 - val_accuracy: 0.0530 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "800/800 - 2s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0787 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0924 - val_mse: 0.7582 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.1076 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0830 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0774 - mse: 0.7572 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0625 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0632 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3573 - val_cat_acc: 0.9918 - val_accuracy: 0.0550 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0575 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0878 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 79: early stopping\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "INFO:tensorflow:Assets written to: ram://fba8fe25-c811-4776-896a-bd403c29a7e0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://fba8fe25-c811-4776-896a-bd403c29a7e0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100 neuron in [1, 10, 100]\n",
      "Training for 1 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.4545 - cat_acc: 0.9799 - accuracy: 0.0000e+00 - mse: 0.6222 - rmse: 0.7888 - val_loss: 0.3638 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7472 - val_rmse: 0.8644 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 2s - loss: 0.3607 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7510 - rmse: 0.8666 - val_loss: 0.3618 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7543 - val_rmse: 0.8685 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 2s - loss: 0.3595 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7541 - rmse: 0.8684 - val_loss: 0.3611 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7557 - val_rmse: 0.8693 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 2s - loss: 0.3588 - cat_acc: 0.9928 - accuracy: 2.8125e-05 - mse: 0.7549 - rmse: 0.8689 - val_loss: 0.3604 - val_cat_acc: 0.9918 - val_accuracy: 5.0000e-05 - val_mse: 0.7562 - val_rmse: 0.8696 - 2s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3583 - cat_acc: 0.9928 - accuracy: 1.2500e-04 - mse: 0.7553 - rmse: 0.8691 - val_loss: 0.3599 - val_cat_acc: 0.9918 - val_accuracy: 1.5000e-04 - val_mse: 0.7565 - val_rmse: 0.8698 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 2s - loss: 0.3578 - cat_acc: 0.9928 - accuracy: 2.6250e-04 - mse: 0.7556 - rmse: 0.8692 - val_loss: 0.3596 - val_cat_acc: 0.9918 - val_accuracy: 5.7500e-04 - val_mse: 0.7566 - val_rmse: 0.8698 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 2s - loss: 0.3575 - cat_acc: 0.9928 - accuracy: 6.3125e-04 - mse: 0.7558 - rmse: 0.8694 - val_loss: 0.3592 - val_cat_acc: 0.9918 - val_accuracy: 8.6250e-04 - val_mse: 0.7571 - val_rmse: 0.8701 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 2s - loss: 0.3572 - cat_acc: 0.9928 - accuracy: 0.0011 - mse: 0.7560 - rmse: 0.8695 - val_loss: 0.3590 - val_cat_acc: 0.9918 - val_accuracy: 0.0033 - val_mse: 0.7568 - val_rmse: 0.8699 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 2s - loss: 0.3569 - cat_acc: 0.9928 - accuracy: 0.0020 - mse: 0.7562 - rmse: 0.8696 - val_loss: 0.3587 - val_cat_acc: 0.9918 - val_accuracy: 0.0028 - val_mse: 0.7574 - val_rmse: 0.8703 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 2s - loss: 0.3568 - cat_acc: 0.9928 - accuracy: 0.0036 - mse: 0.7563 - rmse: 0.8697 - val_loss: 0.3586 - val_cat_acc: 0.9918 - val_accuracy: 0.0065 - val_mse: 0.7577 - val_rmse: 0.8704 - 2s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 2s - loss: 0.3566 - cat_acc: 0.9928 - accuracy: 0.0044 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3584 - val_cat_acc: 0.9918 - val_accuracy: 0.0025 - val_mse: 0.7576 - val_rmse: 0.8704 - 2s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 2s - loss: 0.3565 - cat_acc: 0.9928 - accuracy: 0.0048 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3585 - val_cat_acc: 0.9918 - val_accuracy: 0.0033 - val_mse: 0.7577 - val_rmse: 0.8704 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3564 - cat_acc: 0.9928 - accuracy: 0.0089 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3583 - val_cat_acc: 0.9918 - val_accuracy: 0.0097 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 2s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0079 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0064 - val_mse: 0.7578 - val_rmse: 0.8705 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0080 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3583 - val_cat_acc: 0.9918 - val_accuracy: 0.0060 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 2s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0124 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0171 - val_mse: 0.7577 - val_rmse: 0.8705 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 2s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0149 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0242 - val_mse: 0.7579 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 2s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0265 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0247 - val_mse: 0.7579 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0168 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0139 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 2s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0195 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0526 - val_mse: 0.7578 - val_rmse: 0.8705 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 2s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0331 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0377 - val_mse: 0.7579 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 2s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0224 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0167 - val_mse: 0.7580 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 2s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0353 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0271 - val_mse: 0.7580 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 2s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0249 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0585 - val_mse: 0.7578 - val_rmse: 0.8705 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0285 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0239 - val_mse: 0.7580 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0282 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0162 - val_mse: 0.7580 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0274 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0223 - val_mse: 0.7580 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 2s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0722 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0759 - val_mse: 0.7580 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 2s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0532 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0568 - val_mse: 0.7580 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 2s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0411 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0404 - val_mse: 0.7580 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0404 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0780 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0669 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0515 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0402 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0341 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0455 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0302 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0538 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0514 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 - 2s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.1075 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.1187 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.1083 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.1275 - val_mse: 0.7579 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 2s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.1038 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0773 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 2s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0689 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0625 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 2s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0640 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0498 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 2s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.1195 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.1481 - val_mse: 0.7582 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 2s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.1235 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0879 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0941 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0944 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 2s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0707 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0596 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 2s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0485 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0350 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 2s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0463 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0719 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0585 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0689 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 2s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0602 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0769 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0858 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.1676 - val_mse: 0.7580 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 2s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.1496 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.1471 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 50: early stopping\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "INFO:tensorflow:Assets written to: ram://4e193a96-ec3a-4f9b-ad7b-9e66e21f298f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4e193a96-ec3a-4f9b-ad7b-9e66e21f298f/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.4579 - cat_acc: 0.9815 - accuracy: 0.0000e+00 - mse: 0.6187 - rmse: 0.7866 - val_loss: 0.3640 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7468 - val_rmse: 0.8642 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 2s - loss: 0.3607 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7509 - rmse: 0.8665 - val_loss: 0.3619 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7543 - val_rmse: 0.8685 - 2s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 2s - loss: 0.3596 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7541 - rmse: 0.8684 - val_loss: 0.3611 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7557 - val_rmse: 0.8693 - 2s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3589 - cat_acc: 0.9928 - accuracy: 9.3750e-06 - mse: 0.7548 - rmse: 0.8688 - val_loss: 0.3607 - val_cat_acc: 0.9918 - val_accuracy: 1.8750e-04 - val_mse: 0.7557 - val_rmse: 0.8693 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 2s - loss: 0.3583 - cat_acc: 0.9928 - accuracy: 1.0312e-04 - mse: 0.7552 - rmse: 0.8690 - val_loss: 0.3600 - val_cat_acc: 0.9918 - val_accuracy: 1.1250e-04 - val_mse: 0.7566 - val_rmse: 0.8698 - 2s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 2s - loss: 0.3579 - cat_acc: 0.9928 - accuracy: 2.0937e-04 - mse: 0.7555 - rmse: 0.8692 - val_loss: 0.3597 - val_cat_acc: 0.9918 - val_accuracy: 6.8750e-04 - val_mse: 0.7565 - val_rmse: 0.8698 - 2s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 2s - loss: 0.3575 - cat_acc: 0.9928 - accuracy: 4.4375e-04 - mse: 0.7558 - rmse: 0.8694 - val_loss: 0.3592 - val_cat_acc: 0.9918 - val_accuracy: 0.0010 - val_mse: 0.7570 - val_rmse: 0.8701 - 2s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 2s - loss: 0.3572 - cat_acc: 0.9928 - accuracy: 0.0010 - mse: 0.7560 - rmse: 0.8695 - val_loss: 0.3590 - val_cat_acc: 0.9918 - val_accuracy: 9.3750e-04 - val_mse: 0.7572 - val_rmse: 0.8702 - 2s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 2s - loss: 0.3569 - cat_acc: 0.9928 - accuracy: 0.0014 - mse: 0.7562 - rmse: 0.8696 - val_loss: 0.3588 - val_cat_acc: 0.9918 - val_accuracy: 0.0015 - val_mse: 0.7575 - val_rmse: 0.8703 - 2s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3568 - cat_acc: 0.9928 - accuracy: 0.0027 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3586 - val_cat_acc: 0.9918 - val_accuracy: 0.0021 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3566 - cat_acc: 0.9928 - accuracy: 0.0037 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3585 - val_cat_acc: 0.9918 - val_accuracy: 0.0055 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 2s - loss: 0.3565 - cat_acc: 0.9928 - accuracy: 0.0042 - mse: 0.7566 - rmse: 0.8698 - val_loss: 0.3588 - val_cat_acc: 0.9918 - val_accuracy: 0.0124 - val_mse: 0.7569 - val_rmse: 0.8700 - 2s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 2s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0051 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0040 - val_mse: 0.7578 - val_rmse: 0.8705 - 2s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 2s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0065 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0029 - val_mse: 0.7579 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 2s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0077 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0097 - val_mse: 0.7578 - val_rmse: 0.8705 - 2s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 2s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0098 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0058 - val_mse: 0.7580 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 2s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0120 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0097 - val_mse: 0.7579 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 2s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0166 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0115 - val_mse: 0.7580 - val_rmse: 0.8706 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 2s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0123 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0103 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 2s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0174 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0138 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 2s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0171 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0190 - val_mse: 0.7578 - val_rmse: 0.8705 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 2s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0243 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0211 - val_mse: 0.7580 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 2s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0353 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0418 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 2s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0317 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0327 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0273 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0115 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0220 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0147 - val_mse: 0.7580 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0263 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0349 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 2s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0634 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.1592 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 2s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.1202 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0954 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0756 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0463 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 2s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0367 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0406 - val_mse: 0.7580 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0407 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0721 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 2s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0428 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0358 - val_mse: 0.7570 - val_rmse: 0.8701 - 2s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 2s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0823 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.1489 - val_mse: 0.7582 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.1026 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0750 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 35: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "INFO:tensorflow:Assets written to: ram://720e802c-dda0-4503-b280-953fdfec7e89/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://720e802c-dda0-4503-b280-953fdfec7e89/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 5 fold of 5 folds\n",
      "Training for 1 neuron in [1, 10, 100]\n",
      "Training for 1 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 1.1191 - cat_acc: 0.5214 - accuracy: 0.0000e+00 - mse: 0.2445 - rmse: 0.4945 - val_loss: 0.9502 - val_cat_acc: 0.4969 - val_accuracy: 0.0000e+00 - val_mse: 0.3413 - val_rmse: 0.5842 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.9061 - cat_acc: 0.4972 - accuracy: 0.0000e+00 - mse: 0.4382 - rmse: 0.6620 - val_loss: 0.8807 - val_cat_acc: 0.4970 - val_accuracy: 0.0000e+00 - val_mse: 0.5173 - val_rmse: 0.7192 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.8663 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.5662 - rmse: 0.7525 - val_loss: 0.8584 - val_cat_acc: 0.4971 - val_accuracy: 0.0000e+00 - val_mse: 0.6079 - val_rmse: 0.7797 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.8509 - cat_acc: 0.4975 - accuracy: 0.0000e+00 - mse: 0.6347 - rmse: 0.7967 - val_loss: 0.8480 - val_cat_acc: 0.4972 - val_accuracy: 0.0000e+00 - val_mse: 0.6590 - val_rmse: 0.8118 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.8430 - cat_acc: 0.4975 - accuracy: 0.0000e+00 - mse: 0.6741 - rmse: 0.8210 - val_loss: 0.8421 - val_cat_acc: 0.4972 - val_accuracy: 0.0000e+00 - val_mse: 0.6881 - val_rmse: 0.8295 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.8369 - cat_acc: 0.4971 - accuracy: 0.0000e+00 - mse: 0.6893 - rmse: 0.8303 - val_loss: 0.8313 - val_cat_acc: 0.4960 - val_accuracy: 0.0000e+00 - val_mse: 0.6744 - val_rmse: 0.8212 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.8075 - cat_acc: 0.4936 - accuracy: 0.0000e+00 - mse: 0.6356 - rmse: 0.7972 - val_loss: 0.7892 - val_cat_acc: 0.4929 - val_accuracy: 0.0000e+00 - val_mse: 0.6249 - val_rmse: 0.7905 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.7699 - cat_acc: 0.4937 - accuracy: 0.0000e+00 - mse: 0.6257 - rmse: 0.7910 - val_loss: 0.7556 - val_cat_acc: 0.4925 - val_accuracy: 0.0000e+00 - val_mse: 0.6283 - val_rmse: 0.7927 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.7357 - cat_acc: 0.4914 - accuracy: 0.0000e+00 - mse: 0.6261 - rmse: 0.7913 - val_loss: 0.7224 - val_cat_acc: 0.4904 - val_accuracy: 0.0000e+00 - val_mse: 0.6293 - val_rmse: 0.7933 - 1s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.7095 - cat_acc: 0.4889 - accuracy: 0.0000e+00 - mse: 0.6355 - rmse: 0.7972 - val_loss: 0.7024 - val_cat_acc: 0.4888 - val_accuracy: 0.0000e+00 - val_mse: 0.6434 - val_rmse: 0.8021 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.6929 - cat_acc: 0.4882 - accuracy: 0.0000e+00 - mse: 0.6494 - rmse: 0.8059 - val_loss: 0.6884 - val_cat_acc: 0.4891 - val_accuracy: 0.0000e+00 - val_mse: 0.6557 - val_rmse: 0.8098 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.6809 - cat_acc: 0.4882 - accuracy: 0.0000e+00 - mse: 0.6616 - rmse: 0.8134 - val_loss: 0.6780 - val_cat_acc: 0.4886 - val_accuracy: 0.0000e+00 - val_mse: 0.6677 - val_rmse: 0.8171 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.6717 - cat_acc: 0.4882 - accuracy: 0.0000e+00 - mse: 0.6721 - rmse: 0.8198 - val_loss: 0.6700 - val_cat_acc: 0.4888 - val_accuracy: 0.0000e+00 - val_mse: 0.6771 - val_rmse: 0.8228 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.6643 - cat_acc: 0.4882 - accuracy: 0.0000e+00 - mse: 0.6809 - rmse: 0.8252 - val_loss: 0.6628 - val_cat_acc: 0.4891 - val_accuracy: 0.0000e+00 - val_mse: 0.6846 - val_rmse: 0.8274 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.6583 - cat_acc: 0.4883 - accuracy: 0.0000e+00 - mse: 0.6885 - rmse: 0.8298 - val_loss: 0.6576 - val_cat_acc: 0.4893 - val_accuracy: 0.0000e+00 - val_mse: 0.6917 - val_rmse: 0.8317 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.6532 - cat_acc: 0.4886 - accuracy: 0.0000e+00 - mse: 0.6949 - rmse: 0.8336 - val_loss: 0.6530 - val_cat_acc: 0.4881 - val_accuracy: 0.0000e+00 - val_mse: 0.6976 - val_rmse: 0.8352 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.6491 - cat_acc: 0.4886 - accuracy: 0.0000e+00 - mse: 0.7004 - rmse: 0.8369 - val_loss: 0.6494 - val_cat_acc: 0.4904 - val_accuracy: 0.0000e+00 - val_mse: 0.7023 - val_rmse: 0.8380 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.6455 - cat_acc: 0.4888 - accuracy: 0.0000e+00 - mse: 0.7052 - rmse: 0.8398 - val_loss: 0.6469 - val_cat_acc: 0.4879 - val_accuracy: 0.0000e+00 - val_mse: 0.7067 - val_rmse: 0.8406 - 1s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.6426 - cat_acc: 0.4889 - accuracy: 3.1250e-06 - mse: 0.7094 - rmse: 0.8423 - val_loss: 0.6428 - val_cat_acc: 0.4899 - val_accuracy: 0.0000e+00 - val_mse: 0.7109 - val_rmse: 0.8431 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.6401 - cat_acc: 0.4891 - accuracy: 5.0000e-05 - mse: 0.7129 - rmse: 0.8443 - val_loss: 0.6404 - val_cat_acc: 0.4900 - val_accuracy: 7.5000e-05 - val_mse: 0.7138 - val_rmse: 0.8448 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.6379 - cat_acc: 0.4890 - accuracy: 1.3750e-04 - mse: 0.7158 - rmse: 0.8460 - val_loss: 0.6383 - val_cat_acc: 0.4896 - val_accuracy: 1.1250e-04 - val_mse: 0.7175 - val_rmse: 0.8470 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.6359 - cat_acc: 0.4892 - accuracy: 2.5625e-04 - mse: 0.7183 - rmse: 0.8475 - val_loss: 0.6366 - val_cat_acc: 0.4897 - val_accuracy: 2.1250e-04 - val_mse: 0.7192 - val_rmse: 0.8481 - 1s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.6343 - cat_acc: 0.4893 - accuracy: 4.1250e-04 - mse: 0.7208 - rmse: 0.8490 - val_loss: 0.6355 - val_cat_acc: 0.4890 - val_accuracy: 4.2500e-04 - val_mse: 0.7223 - val_rmse: 0.8499 - 1s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.6330 - cat_acc: 0.4894 - accuracy: 7.2187e-04 - mse: 0.7227 - rmse: 0.8501 - val_loss: 0.6340 - val_cat_acc: 0.4906 - val_accuracy: 8.1250e-04 - val_mse: 0.7234 - val_rmse: 0.8505 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.6317 - cat_acc: 0.4896 - accuracy: 0.0011 - mse: 0.7243 - rmse: 0.8511 - val_loss: 0.6325 - val_cat_acc: 0.4903 - val_accuracy: 0.0011 - val_mse: 0.7251 - val_rmse: 0.8516 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.6306 - cat_acc: 0.4897 - accuracy: 0.0015 - mse: 0.7261 - rmse: 0.8521 - val_loss: 0.6315 - val_cat_acc: 0.4897 - val_accuracy: 0.0017 - val_mse: 0.7270 - val_rmse: 0.8526 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.6297 - cat_acc: 0.4897 - accuracy: 0.0021 - mse: 0.7271 - rmse: 0.8527 - val_loss: 0.6306 - val_cat_acc: 0.4893 - val_accuracy: 0.0022 - val_mse: 0.7287 - val_rmse: 0.8536 - 1s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.6289 - cat_acc: 0.4897 - accuracy: 0.0027 - mse: 0.7286 - rmse: 0.8536 - val_loss: 0.6301 - val_cat_acc: 0.4907 - val_accuracy: 0.0032 - val_mse: 0.7285 - val_rmse: 0.8535 - 1s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.6281 - cat_acc: 0.4896 - accuracy: 0.0035 - mse: 0.7296 - rmse: 0.8542 - val_loss: 0.6299 - val_cat_acc: 0.4893 - val_accuracy: 0.0038 - val_mse: 0.7299 - val_rmse: 0.8543 - 1s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.6275 - cat_acc: 0.4899 - accuracy: 0.0045 - mse: 0.7306 - rmse: 0.8547 - val_loss: 0.6283 - val_cat_acc: 0.4902 - val_accuracy: 0.0046 - val_mse: 0.7309 - val_rmse: 0.8549 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.6268 - cat_acc: 0.4899 - accuracy: 0.0054 - mse: 0.7314 - rmse: 0.8552 - val_loss: 0.6279 - val_cat_acc: 0.4910 - val_accuracy: 0.0060 - val_mse: 0.7314 - val_rmse: 0.8552 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.6263 - cat_acc: 0.4901 - accuracy: 0.0065 - mse: 0.7322 - rmse: 0.8557 - val_loss: 0.6281 - val_cat_acc: 0.4897 - val_accuracy: 0.0072 - val_mse: 0.7324 - val_rmse: 0.8558 - 1s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.6258 - cat_acc: 0.4900 - accuracy: 0.0076 - mse: 0.7332 - rmse: 0.8563 - val_loss: 0.6268 - val_cat_acc: 0.4904 - val_accuracy: 0.0086 - val_mse: 0.7328 - val_rmse: 0.8560 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.6253 - cat_acc: 0.4899 - accuracy: 0.0089 - mse: 0.7338 - rmse: 0.8566 - val_loss: 0.6272 - val_cat_acc: 0.4915 - val_accuracy: 0.0105 - val_mse: 0.7330 - val_rmse: 0.8562 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.6250 - cat_acc: 0.4900 - accuracy: 0.0101 - mse: 0.7344 - rmse: 0.8570 - val_loss: 0.6260 - val_cat_acc: 0.4898 - val_accuracy: 0.0107 - val_mse: 0.7344 - val_rmse: 0.8570 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.6245 - cat_acc: 0.4900 - accuracy: 0.0114 - mse: 0.7348 - rmse: 0.8572 - val_loss: 0.6278 - val_cat_acc: 0.4897 - val_accuracy: 0.0145 - val_mse: 0.7332 - val_rmse: 0.8563 - 1s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.6242 - cat_acc: 0.4902 - accuracy: 0.0128 - mse: 0.7354 - rmse: 0.8575 - val_loss: 0.6254 - val_cat_acc: 0.4905 - val_accuracy: 0.0136 - val_mse: 0.7358 - val_rmse: 0.8578 - 1s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.6237 - cat_acc: 0.4903 - accuracy: 0.0140 - mse: 0.7358 - rmse: 0.8578 - val_loss: 0.6251 - val_cat_acc: 0.4900 - val_accuracy: 0.0154 - val_mse: 0.7361 - val_rmse: 0.8579 - 1s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.6234 - cat_acc: 0.4903 - accuracy: 0.0155 - mse: 0.7364 - rmse: 0.8581 - val_loss: 0.6248 - val_cat_acc: 0.4910 - val_accuracy: 0.0175 - val_mse: 0.7358 - val_rmse: 0.8578 - 1s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.6231 - cat_acc: 0.4902 - accuracy: 0.0171 - mse: 0.7366 - rmse: 0.8582 - val_loss: 0.6244 - val_cat_acc: 0.4904 - val_accuracy: 0.0184 - val_mse: 0.7372 - val_rmse: 0.8586 - 1s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.6229 - cat_acc: 0.4901 - accuracy: 0.0183 - mse: 0.7371 - rmse: 0.8586 - val_loss: 0.6240 - val_cat_acc: 0.4910 - val_accuracy: 0.0195 - val_mse: 0.7372 - val_rmse: 0.8586 - 1s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.6225 - cat_acc: 0.4904 - accuracy: 0.0198 - mse: 0.7374 - rmse: 0.8587 - val_loss: 0.6236 - val_cat_acc: 0.4904 - val_accuracy: 0.0193 - val_mse: 0.7382 - val_rmse: 0.8592 - 1s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.6225 - cat_acc: 0.4901 - accuracy: 0.0213 - mse: 0.7379 - rmse: 0.8590 - val_loss: 0.6237 - val_cat_acc: 0.4913 - val_accuracy: 0.0236 - val_mse: 0.7372 - val_rmse: 0.8586 - 1s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.6221 - cat_acc: 0.4901 - accuracy: 0.0226 - mse: 0.7382 - rmse: 0.8592 - val_loss: 0.6234 - val_cat_acc: 0.4911 - val_accuracy: 0.0239 - val_mse: 0.7375 - val_rmse: 0.8588 - 1s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.6219 - cat_acc: 0.4903 - accuracy: 0.0243 - mse: 0.7385 - rmse: 0.8594 - val_loss: 0.6240 - val_cat_acc: 0.4891 - val_accuracy: 0.0248 - val_mse: 0.7390 - val_rmse: 0.8597 - 1s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.6218 - cat_acc: 0.4901 - accuracy: 0.0256 - mse: 0.7388 - rmse: 0.8595 - val_loss: 0.6231 - val_cat_acc: 0.4909 - val_accuracy: 0.0258 - val_mse: 0.7390 - val_rmse: 0.8596 - 1s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.6215 - cat_acc: 0.4904 - accuracy: 0.0270 - mse: 0.7390 - rmse: 0.8596 - val_loss: 0.6228 - val_cat_acc: 0.4907 - val_accuracy: 0.0289 - val_mse: 0.7391 - val_rmse: 0.8597 - 1s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.6213 - cat_acc: 0.4904 - accuracy: 0.0279 - mse: 0.7393 - rmse: 0.8598 - val_loss: 0.6228 - val_cat_acc: 0.4909 - val_accuracy: 0.0299 - val_mse: 0.7383 - val_rmse: 0.8593 - 1s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.6213 - cat_acc: 0.4906 - accuracy: 0.0295 - mse: 0.7396 - rmse: 0.8600 - val_loss: 0.6222 - val_cat_acc: 0.4908 - val_accuracy: 0.0294 - val_mse: 0.7405 - val_rmse: 0.8605 - 1s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.6210 - cat_acc: 0.4903 - accuracy: 0.0302 - mse: 0.7402 - rmse: 0.8603 - val_loss: 0.6223 - val_cat_acc: 0.4915 - val_accuracy: 0.0334 - val_mse: 0.7395 - val_rmse: 0.8599 - 1s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.6210 - cat_acc: 0.4902 - accuracy: 0.0317 - mse: 0.7401 - rmse: 0.8603 - val_loss: 0.6220 - val_cat_acc: 0.4902 - val_accuracy: 0.0324 - val_mse: 0.7403 - val_rmse: 0.8604 - 1s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.6206 - cat_acc: 0.4904 - accuracy: 0.0326 - mse: 0.7403 - rmse: 0.8604 - val_loss: 0.6224 - val_cat_acc: 0.4905 - val_accuracy: 0.0346 - val_mse: 0.7398 - val_rmse: 0.8601 - 1s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.6206 - cat_acc: 0.4906 - accuracy: 0.0340 - mse: 0.7406 - rmse: 0.8606 - val_loss: 0.6223 - val_cat_acc: 0.4902 - val_accuracy: 0.0329 - val_mse: 0.7409 - val_rmse: 0.8608 - 1s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.6204 - cat_acc: 0.4905 - accuracy: 0.0351 - mse: 0.7408 - rmse: 0.8607 - val_loss: 0.6217 - val_cat_acc: 0.4917 - val_accuracy: 0.0373 - val_mse: 0.7401 - val_rmse: 0.8603 - 1s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.6202 - cat_acc: 0.4904 - accuracy: 0.0360 - mse: 0.7410 - rmse: 0.8608 - val_loss: 0.6219 - val_cat_acc: 0.4909 - val_accuracy: 0.0386 - val_mse: 0.7418 - val_rmse: 0.8613 - 1s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.6202 - cat_acc: 0.4906 - accuracy: 0.0369 - mse: 0.7414 - rmse: 0.8610 - val_loss: 0.6216 - val_cat_acc: 0.4915 - val_accuracy: 0.0388 - val_mse: 0.7405 - val_rmse: 0.8605 - 1s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.6200 - cat_acc: 0.4908 - accuracy: 0.0379 - mse: 0.7413 - rmse: 0.8610 - val_loss: 0.6212 - val_cat_acc: 0.4911 - val_accuracy: 0.0409 - val_mse: 0.7415 - val_rmse: 0.8611 - 1s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.6199 - cat_acc: 0.4905 - accuracy: 0.0390 - mse: 0.7416 - rmse: 0.8612 - val_loss: 0.6209 - val_cat_acc: 0.4904 - val_accuracy: 0.0387 - val_mse: 0.7418 - val_rmse: 0.8613 - 1s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.6197 - cat_acc: 0.4905 - accuracy: 0.0402 - mse: 0.7416 - rmse: 0.8612 - val_loss: 0.6210 - val_cat_acc: 0.4902 - val_accuracy: 0.0388 - val_mse: 0.7423 - val_rmse: 0.8616 - 1s/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.6196 - cat_acc: 0.4907 - accuracy: 0.0409 - mse: 0.7416 - rmse: 0.8612 - val_loss: 0.6212 - val_cat_acc: 0.4902 - val_accuracy: 0.0421 - val_mse: 0.7431 - val_rmse: 0.8621 - 1s/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.6196 - cat_acc: 0.4905 - accuracy: 0.0418 - mse: 0.7421 - rmse: 0.8615 - val_loss: 0.6212 - val_cat_acc: 0.4906 - val_accuracy: 0.0435 - val_mse: 0.7416 - val_rmse: 0.8612 - 1s/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 1s - loss: 0.6195 - cat_acc: 0.4905 - accuracy: 0.0429 - mse: 0.7420 - rmse: 0.8614 - val_loss: 0.6204 - val_cat_acc: 0.4913 - val_accuracy: 0.0439 - val_mse: 0.7422 - val_rmse: 0.8615 - 1s/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 1s - loss: 0.6193 - cat_acc: 0.4905 - accuracy: 0.0437 - mse: 0.7423 - rmse: 0.8616 - val_loss: 0.6213 - val_cat_acc: 0.4904 - val_accuracy: 0.0456 - val_mse: 0.7422 - val_rmse: 0.8615 - 1s/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 1s - loss: 0.6192 - cat_acc: 0.4904 - accuracy: 0.0447 - mse: 0.7423 - rmse: 0.8616 - val_loss: 0.6207 - val_cat_acc: 0.4914 - val_accuracy: 0.0481 - val_mse: 0.7425 - val_rmse: 0.8617 - 1s/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 1s - loss: 0.6192 - cat_acc: 0.4906 - accuracy: 0.0454 - mse: 0.7427 - rmse: 0.8618 - val_loss: 0.6204 - val_cat_acc: 0.4915 - val_accuracy: 0.0488 - val_mse: 0.7425 - val_rmse: 0.8617 - 1s/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "800/800 - 1s - loss: 0.6192 - cat_acc: 0.4906 - accuracy: 0.0466 - mse: 0.7427 - rmse: 0.8618 - val_loss: 0.6204 - val_cat_acc: 0.4909 - val_accuracy: 0.0472 - val_mse: 0.7430 - val_rmse: 0.8620 - 1s/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "800/800 - 1s - loss: 0.6190 - cat_acc: 0.4906 - accuracy: 0.0472 - mse: 0.7428 - rmse: 0.8618 - val_loss: 0.6204 - val_cat_acc: 0.4909 - val_accuracy: 0.0487 - val_mse: 0.7428 - val_rmse: 0.8619 - 1s/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "800/800 - 2s - loss: 0.6190 - cat_acc: 0.4906 - accuracy: 0.0480 - mse: 0.7431 - rmse: 0.8620 - val_loss: 0.6200 - val_cat_acc: 0.4905 - val_accuracy: 0.0489 - val_mse: 0.7437 - val_rmse: 0.8624 - 2s/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "800/800 - 1s - loss: 0.6189 - cat_acc: 0.4908 - accuracy: 0.0486 - mse: 0.7432 - rmse: 0.8621 - val_loss: 0.6200 - val_cat_acc: 0.4907 - val_accuracy: 0.0512 - val_mse: 0.7431 - val_rmse: 0.8620 - 1s/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "800/800 - 1s - loss: 0.6188 - cat_acc: 0.4904 - accuracy: 0.0495 - mse: 0.7432 - rmse: 0.8621 - val_loss: 0.6199 - val_cat_acc: 0.4909 - val_accuracy: 0.0515 - val_mse: 0.7429 - val_rmse: 0.8619 - 1s/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "800/800 - 1s - loss: 0.6188 - cat_acc: 0.4907 - accuracy: 0.0504 - mse: 0.7435 - rmse: 0.8623 - val_loss: 0.6197 - val_cat_acc: 0.4909 - val_accuracy: 0.0511 - val_mse: 0.7433 - val_rmse: 0.8622 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "800/800 - 1s - loss: 0.6186 - cat_acc: 0.4908 - accuracy: 0.0513 - mse: 0.7435 - rmse: 0.8622 - val_loss: 0.6200 - val_cat_acc: 0.4909 - val_accuracy: 0.0516 - val_mse: 0.7434 - val_rmse: 0.8622 - 1s/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "800/800 - 1s - loss: 0.6186 - cat_acc: 0.4906 - accuracy: 0.0520 - mse: 0.7436 - rmse: 0.8623 - val_loss: 0.6202 - val_cat_acc: 0.4900 - val_accuracy: 0.0499 - val_mse: 0.7439 - val_rmse: 0.8625 - 1s/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "800/800 - 1s - loss: 0.6185 - cat_acc: 0.4906 - accuracy: 0.0522 - mse: 0.7439 - rmse: 0.8625 - val_loss: 0.6201 - val_cat_acc: 0.4913 - val_accuracy: 0.0531 - val_mse: 0.7439 - val_rmse: 0.8625 - 1s/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "800/800 - 1s - loss: 0.6184 - cat_acc: 0.4907 - accuracy: 0.0527 - mse: 0.7439 - rmse: 0.8625 - val_loss: 0.6195 - val_cat_acc: 0.4916 - val_accuracy: 0.0545 - val_mse: 0.7439 - val_rmse: 0.8625 - 1s/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "800/800 - 1s - loss: 0.6184 - cat_acc: 0.4908 - accuracy: 0.0534 - mse: 0.7440 - rmse: 0.8625 - val_loss: 0.6195 - val_cat_acc: 0.4916 - val_accuracy: 0.0574 - val_mse: 0.7435 - val_rmse: 0.8623 - 1s/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "800/800 - 1s - loss: 0.6182 - cat_acc: 0.4908 - accuracy: 0.0543 - mse: 0.7438 - rmse: 0.8625 - val_loss: 0.6194 - val_cat_acc: 0.4916 - val_accuracy: 0.0569 - val_mse: 0.7440 - val_rmse: 0.8626 - 1s/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "800/800 - 1s - loss: 0.6182 - cat_acc: 0.4907 - accuracy: 0.0552 - mse: 0.7441 - rmse: 0.8626 - val_loss: 0.6197 - val_cat_acc: 0.4904 - val_accuracy: 0.0551 - val_mse: 0.7456 - val_rmse: 0.8635 - 1s/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "800/800 - 1s - loss: 0.6182 - cat_acc: 0.4907 - accuracy: 0.0556 - mse: 0.7443 - rmse: 0.8627 - val_loss: 0.6193 - val_cat_acc: 0.4906 - val_accuracy: 0.0536 - val_mse: 0.7446 - val_rmse: 0.8629 - 1s/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "800/800 - 1s - loss: 0.6182 - cat_acc: 0.4906 - accuracy: 0.0560 - mse: 0.7443 - rmse: 0.8628 - val_loss: 0.6195 - val_cat_acc: 0.4915 - val_accuracy: 0.0600 - val_mse: 0.7443 - val_rmse: 0.8627 - 1s/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "800/800 - 1s - loss: 0.6181 - cat_acc: 0.4909 - accuracy: 0.0572 - mse: 0.7444 - rmse: 0.8628 - val_loss: 0.6200 - val_cat_acc: 0.4915 - val_accuracy: 0.0575 - val_mse: 0.7445 - val_rmse: 0.8628 - 1s/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "800/800 - 1s - loss: 0.6181 - cat_acc: 0.4907 - accuracy: 0.0577 - mse: 0.7443 - rmse: 0.8627 - val_loss: 0.6196 - val_cat_acc: 0.4904 - val_accuracy: 0.0582 - val_mse: 0.7455 - val_rmse: 0.8634 - 1s/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "800/800 - 1s - loss: 0.6179 - cat_acc: 0.4908 - accuracy: 0.0587 - mse: 0.7445 - rmse: 0.8628 - val_loss: 0.6191 - val_cat_acc: 0.4908 - val_accuracy: 0.0562 - val_mse: 0.7448 - val_rmse: 0.8630 - 1s/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "800/800 - 1s - loss: 0.6179 - cat_acc: 0.4907 - accuracy: 0.0588 - mse: 0.7446 - rmse: 0.8629 - val_loss: 0.6194 - val_cat_acc: 0.4908 - val_accuracy: 0.0622 - val_mse: 0.7443 - val_rmse: 0.8627 - 1s/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "800/800 - 1s - loss: 0.6179 - cat_acc: 0.4907 - accuracy: 0.0599 - mse: 0.7445 - rmse: 0.8629 - val_loss: 0.6204 - val_cat_acc: 0.4897 - val_accuracy: 0.0624 - val_mse: 0.7446 - val_rmse: 0.8629 - 1s/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "800/800 - 1s - loss: 0.6178 - cat_acc: 0.4909 - accuracy: 0.0599 - mse: 0.7449 - rmse: 0.8631 - val_loss: 0.6191 - val_cat_acc: 0.4911 - val_accuracy: 0.0617 - val_mse: 0.7443 - val_rmse: 0.8627 - 1s/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "800/800 - 1s - loss: 0.6178 - cat_acc: 0.4908 - accuracy: 0.0608 - mse: 0.7449 - rmse: 0.8631 - val_loss: 0.6189 - val_cat_acc: 0.4907 - val_accuracy: 0.0580 - val_mse: 0.7457 - val_rmse: 0.8635 - 1s/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "800/800 - 2s - loss: 0.6177 - cat_acc: 0.4906 - accuracy: 0.0612 - mse: 0.7450 - rmse: 0.8631 - val_loss: 0.6195 - val_cat_acc: 0.4920 - val_accuracy: 0.0617 - val_mse: 0.7452 - val_rmse: 0.8632 - 2s/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "800/800 - 2s - loss: 0.6177 - cat_acc: 0.4908 - accuracy: 0.0617 - mse: 0.7449 - rmse: 0.8631 - val_loss: 0.6185 - val_cat_acc: 0.4913 - val_accuracy: 0.0639 - val_mse: 0.7453 - val_rmse: 0.8633 - 2s/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "800/800 - 1s - loss: 0.6176 - cat_acc: 0.4906 - accuracy: 0.0624 - mse: 0.7452 - rmse: 0.8633 - val_loss: 0.6192 - val_cat_acc: 0.4913 - val_accuracy: 0.0636 - val_mse: 0.7448 - val_rmse: 0.8630 - 1s/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "800/800 - 1s - loss: 0.6176 - cat_acc: 0.4908 - accuracy: 0.0627 - mse: 0.7453 - rmse: 0.8633 - val_loss: 0.6185 - val_cat_acc: 0.4913 - val_accuracy: 0.0641 - val_mse: 0.7455 - val_rmse: 0.8634 - 1s/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "800/800 - 1s - loss: 0.6175 - cat_acc: 0.4907 - accuracy: 0.0636 - mse: 0.7451 - rmse: 0.8632 - val_loss: 0.6194 - val_cat_acc: 0.4904 - val_accuracy: 0.0617 - val_mse: 0.7453 - val_rmse: 0.8633 - 1s/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "800/800 - 1s - loss: 0.6175 - cat_acc: 0.4907 - accuracy: 0.0636 - mse: 0.7453 - rmse: 0.8633 - val_loss: 0.6186 - val_cat_acc: 0.4915 - val_accuracy: 0.0643 - val_mse: 0.7453 - val_rmse: 0.8633 - 1s/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "800/800 - 1s - loss: 0.6175 - cat_acc: 0.4908 - accuracy: 0.0642 - mse: 0.7454 - rmse: 0.8633 - val_loss: 0.6190 - val_cat_acc: 0.4913 - val_accuracy: 0.0655 - val_mse: 0.7463 - val_rmse: 0.8639 - 1s/epoch - 2ms/step\n",
      "Epoch 94: early stopping\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "INFO:tensorflow:Assets written to: ram://7c449165-929a-4298-92d7-fbd1ee105295/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7c449165-929a-4298-92d7-fbd1ee105295/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 1.1175 - cat_acc: 0.4925 - accuracy: 0.0000e+00 - mse: 0.2461 - rmse: 0.4961 - val_loss: 0.9458 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.3456 - val_rmse: 0.5879 - 2s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.9035 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.4449 - rmse: 0.6670 - val_loss: 0.8781 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.5236 - val_rmse: 0.7236 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.8651 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.5724 - rmse: 0.7566 - val_loss: 0.8568 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.6126 - val_rmse: 0.7827 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.8504 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.6392 - rmse: 0.7995 - val_loss: 0.8468 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.6621 - val_rmse: 0.8137 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.8427 - cat_acc: 0.4974 - accuracy: 0.0000e+00 - mse: 0.6757 - rmse: 0.8220 - val_loss: 0.8396 - val_cat_acc: 0.4975 - val_accuracy: 0.0000e+00 - val_mse: 0.6807 - val_rmse: 0.8251 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.8134 - cat_acc: 0.4963 - accuracy: 0.0000e+00 - mse: 0.6325 - rmse: 0.7953 - val_loss: 0.7893 - val_cat_acc: 0.4958 - val_accuracy: 0.0000e+00 - val_mse: 0.6160 - val_rmse: 0.7848 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.7735 - cat_acc: 0.4963 - accuracy: 0.0000e+00 - mse: 0.6242 - rmse: 0.7901 - val_loss: 0.7599 - val_cat_acc: 0.4969 - val_accuracy: 0.0000e+00 - val_mse: 0.6290 - val_rmse: 0.7931 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.7429 - cat_acc: 0.4945 - accuracy: 0.0000e+00 - mse: 0.6218 - rmse: 0.7885 - val_loss: 0.7248 - val_cat_acc: 0.4937 - val_accuracy: 0.0000e+00 - val_mse: 0.6195 - val_rmse: 0.7871 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.7095 - cat_acc: 0.4926 - accuracy: 0.0000e+00 - mse: 0.6250 - rmse: 0.7906 - val_loss: 0.6972 - val_cat_acc: 0.4924 - val_accuracy: 0.0000e+00 - val_mse: 0.6322 - val_rmse: 0.7951 - 1s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.6873 - cat_acc: 0.4928 - accuracy: 0.0000e+00 - mse: 0.6394 - rmse: 0.7996 - val_loss: 0.6795 - val_cat_acc: 0.4938 - val_accuracy: 0.0000e+00 - val_mse: 0.6468 - val_rmse: 0.8043 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.6722 - cat_acc: 0.4928 - accuracy: 0.0000e+00 - mse: 0.6536 - rmse: 0.8084 - val_loss: 0.6666 - val_cat_acc: 0.4940 - val_accuracy: 0.0000e+00 - val_mse: 0.6602 - val_rmse: 0.8125 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.6610 - cat_acc: 0.4929 - accuracy: 0.0000e+00 - mse: 0.6658 - rmse: 0.8160 - val_loss: 0.6569 - val_cat_acc: 0.4940 - val_accuracy: 0.0000e+00 - val_mse: 0.6718 - val_rmse: 0.8196 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.6523 - cat_acc: 0.4931 - accuracy: 0.0000e+00 - mse: 0.6763 - rmse: 0.8223 - val_loss: 0.6490 - val_cat_acc: 0.4942 - val_accuracy: 0.0000e+00 - val_mse: 0.6813 - val_rmse: 0.8254 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.6452 - cat_acc: 0.4934 - accuracy: 0.0000e+00 - mse: 0.6851 - rmse: 0.8277 - val_loss: 0.6426 - val_cat_acc: 0.4940 - val_accuracy: 0.0000e+00 - val_mse: 0.6893 - val_rmse: 0.8302 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.6394 - cat_acc: 0.4936 - accuracy: 0.0000e+00 - mse: 0.6929 - rmse: 0.8324 - val_loss: 0.6376 - val_cat_acc: 0.4945 - val_accuracy: 0.0000e+00 - val_mse: 0.6970 - val_rmse: 0.8348 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.6349 - cat_acc: 0.4937 - accuracy: 0.0000e+00 - mse: 0.6992 - rmse: 0.8362 - val_loss: 0.6334 - val_cat_acc: 0.4945 - val_accuracy: 0.0000e+00 - val_mse: 0.7022 - val_rmse: 0.8380 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.6310 - cat_acc: 0.4938 - accuracy: 0.0000e+00 - mse: 0.7048 - rmse: 0.8395 - val_loss: 0.6296 - val_cat_acc: 0.4943 - val_accuracy: 0.0000e+00 - val_mse: 0.7078 - val_rmse: 0.8413 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.6278 - cat_acc: 0.4938 - accuracy: 0.0000e+00 - mse: 0.7096 - rmse: 0.8424 - val_loss: 0.6269 - val_cat_acc: 0.4945 - val_accuracy: 0.0000e+00 - val_mse: 0.7116 - val_rmse: 0.8436 - 1s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.6251 - cat_acc: 0.4940 - accuracy: 6.2500e-06 - mse: 0.7135 - rmse: 0.8447 - val_loss: 0.6245 - val_cat_acc: 0.4952 - val_accuracy: 3.7500e-05 - val_mse: 0.7146 - val_rmse: 0.8454 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.6229 - cat_acc: 0.4940 - accuracy: 8.4375e-05 - mse: 0.7168 - rmse: 0.8466 - val_loss: 0.6222 - val_cat_acc: 0.4943 - val_accuracy: 1.0000e-04 - val_mse: 0.7195 - val_rmse: 0.8482 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.6210 - cat_acc: 0.4939 - accuracy: 1.5000e-04 - mse: 0.7200 - rmse: 0.8485 - val_loss: 0.6209 - val_cat_acc: 0.4945 - val_accuracy: 2.5000e-04 - val_mse: 0.7207 - val_rmse: 0.8490 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.6194 - cat_acc: 0.4940 - accuracy: 1.8438e-04 - mse: 0.7225 - rmse: 0.8500 - val_loss: 0.6189 - val_cat_acc: 0.4945 - val_accuracy: 2.8750e-04 - val_mse: 0.7241 - val_rmse: 0.8509 - 1s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.6180 - cat_acc: 0.4942 - accuracy: 2.3750e-04 - mse: 0.7248 - rmse: 0.8513 - val_loss: 0.6183 - val_cat_acc: 0.4951 - val_accuracy: 3.1250e-04 - val_mse: 0.7260 - val_rmse: 0.8521 - 1s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.6167 - cat_acc: 0.4941 - accuracy: 2.8125e-04 - mse: 0.7267 - rmse: 0.8525 - val_loss: 0.6167 - val_cat_acc: 0.4951 - val_accuracy: 3.6250e-04 - val_mse: 0.7274 - val_rmse: 0.8529 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.6157 - cat_acc: 0.4942 - accuracy: 3.5625e-04 - mse: 0.7284 - rmse: 0.8535 - val_loss: 0.6156 - val_cat_acc: 0.4949 - val_accuracy: 4.0000e-04 - val_mse: 0.7297 - val_rmse: 0.8542 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.6148 - cat_acc: 0.4944 - accuracy: 5.0000e-04 - mse: 0.7298 - rmse: 0.8543 - val_loss: 0.6149 - val_cat_acc: 0.4949 - val_accuracy: 5.8750e-04 - val_mse: 0.7306 - val_rmse: 0.8548 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.6140 - cat_acc: 0.4942 - accuracy: 7.0313e-04 - mse: 0.7313 - rmse: 0.8551 - val_loss: 0.6141 - val_cat_acc: 0.4945 - val_accuracy: 8.0000e-04 - val_mse: 0.7328 - val_rmse: 0.8561 - 1s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.6133 - cat_acc: 0.4943 - accuracy: 0.0010 - mse: 0.7323 - rmse: 0.8558 - val_loss: 0.6134 - val_cat_acc: 0.4944 - val_accuracy: 0.0011 - val_mse: 0.7344 - val_rmse: 0.8570 - 1s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.6126 - cat_acc: 0.4943 - accuracy: 0.0014 - mse: 0.7334 - rmse: 0.8564 - val_loss: 0.6129 - val_cat_acc: 0.4951 - val_accuracy: 0.0014 - val_mse: 0.7353 - val_rmse: 0.8575 - 1s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.6120 - cat_acc: 0.4945 - accuracy: 0.0020 - mse: 0.7345 - rmse: 0.8570 - val_loss: 0.6128 - val_cat_acc: 0.4949 - val_accuracy: 0.0025 - val_mse: 0.7350 - val_rmse: 0.8573 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.6116 - cat_acc: 0.4946 - accuracy: 0.0026 - mse: 0.7350 - rmse: 0.8573 - val_loss: 0.6117 - val_cat_acc: 0.4949 - val_accuracy: 0.0027 - val_mse: 0.7369 - val_rmse: 0.8584 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.6112 - cat_acc: 0.4944 - accuracy: 0.0034 - mse: 0.7360 - rmse: 0.8579 - val_loss: 0.6113 - val_cat_acc: 0.4950 - val_accuracy: 0.0040 - val_mse: 0.7367 - val_rmse: 0.8583 - 1s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.6108 - cat_acc: 0.4945 - accuracy: 0.0044 - mse: 0.7365 - rmse: 0.8582 - val_loss: 0.6108 - val_cat_acc: 0.4951 - val_accuracy: 0.0049 - val_mse: 0.7374 - val_rmse: 0.8587 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.6105 - cat_acc: 0.4945 - accuracy: 0.0054 - mse: 0.7373 - rmse: 0.8587 - val_loss: 0.6104 - val_cat_acc: 0.4951 - val_accuracy: 0.0058 - val_mse: 0.7383 - val_rmse: 0.8592 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.6100 - cat_acc: 0.4946 - accuracy: 0.0065 - mse: 0.7380 - rmse: 0.8590 - val_loss: 0.6104 - val_cat_acc: 0.4949 - val_accuracy: 0.0068 - val_mse: 0.7390 - val_rmse: 0.8597 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.6098 - cat_acc: 0.4944 - accuracy: 0.0079 - mse: 0.7383 - rmse: 0.8592 - val_loss: 0.6101 - val_cat_acc: 0.4954 - val_accuracy: 0.0081 - val_mse: 0.7393 - val_rmse: 0.8598 - 1s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.6094 - cat_acc: 0.4946 - accuracy: 0.0089 - mse: 0.7389 - rmse: 0.8596 - val_loss: 0.6096 - val_cat_acc: 0.4950 - val_accuracy: 0.0101 - val_mse: 0.7390 - val_rmse: 0.8596 - 1s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.6091 - cat_acc: 0.4947 - accuracy: 0.0104 - mse: 0.7392 - rmse: 0.8598 - val_loss: 0.6095 - val_cat_acc: 0.4949 - val_accuracy: 0.0109 - val_mse: 0.7401 - val_rmse: 0.8603 - 1s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.6089 - cat_acc: 0.4947 - accuracy: 0.0116 - mse: 0.7398 - rmse: 0.8601 - val_loss: 0.6093 - val_cat_acc: 0.4956 - val_accuracy: 0.0137 - val_mse: 0.7397 - val_rmse: 0.8601 - 1s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.6087 - cat_acc: 0.4946 - accuracy: 0.0132 - mse: 0.7400 - rmse: 0.8603 - val_loss: 0.6089 - val_cat_acc: 0.4950 - val_accuracy: 0.0148 - val_mse: 0.7404 - val_rmse: 0.8605 - 1s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.6085 - cat_acc: 0.4946 - accuracy: 0.0146 - mse: 0.7406 - rmse: 0.8606 - val_loss: 0.6089 - val_cat_acc: 0.4951 - val_accuracy: 0.0154 - val_mse: 0.7412 - val_rmse: 0.8609 - 1s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.6084 - cat_acc: 0.4946 - accuracy: 0.0161 - mse: 0.7409 - rmse: 0.8607 - val_loss: 0.6085 - val_cat_acc: 0.4952 - val_accuracy: 0.0170 - val_mse: 0.7415 - val_rmse: 0.8611 - 1s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.6081 - cat_acc: 0.4945 - accuracy: 0.0176 - mse: 0.7412 - rmse: 0.8609 - val_loss: 0.6086 - val_cat_acc: 0.4958 - val_accuracy: 0.0195 - val_mse: 0.7413 - val_rmse: 0.8610 - 1s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.6078 - cat_acc: 0.4947 - accuracy: 0.0190 - mse: 0.7415 - rmse: 0.8611 - val_loss: 0.6082 - val_cat_acc: 0.4951 - val_accuracy: 0.0191 - val_mse: 0.7425 - val_rmse: 0.8617 - 1s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.6078 - cat_acc: 0.4946 - accuracy: 0.0204 - mse: 0.7417 - rmse: 0.8612 - val_loss: 0.6080 - val_cat_acc: 0.4947 - val_accuracy: 0.0198 - val_mse: 0.7432 - val_rmse: 0.8621 - 1s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.6076 - cat_acc: 0.4946 - accuracy: 0.0220 - mse: 0.7420 - rmse: 0.8614 - val_loss: 0.6077 - val_cat_acc: 0.4951 - val_accuracy: 0.0229 - val_mse: 0.7420 - val_rmse: 0.8614 - 1s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.6074 - cat_acc: 0.4949 - accuracy: 0.0232 - mse: 0.7422 - rmse: 0.8615 - val_loss: 0.6077 - val_cat_acc: 0.4948 - val_accuracy: 0.0224 - val_mse: 0.7435 - val_rmse: 0.8623 - 1s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.6073 - cat_acc: 0.4947 - accuracy: 0.0248 - mse: 0.7426 - rmse: 0.8617 - val_loss: 0.6077 - val_cat_acc: 0.4948 - val_accuracy: 0.0234 - val_mse: 0.7435 - val_rmse: 0.8623 - 1s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.6073 - cat_acc: 0.4946 - accuracy: 0.0264 - mse: 0.7427 - rmse: 0.8618 - val_loss: 0.6074 - val_cat_acc: 0.4954 - val_accuracy: 0.0265 - val_mse: 0.7434 - val_rmse: 0.8622 - 1s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.6071 - cat_acc: 0.4947 - accuracy: 0.0276 - mse: 0.7429 - rmse: 0.8619 - val_loss: 0.6074 - val_cat_acc: 0.4958 - val_accuracy: 0.0302 - val_mse: 0.7425 - val_rmse: 0.8617 - 1s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.6068 - cat_acc: 0.4948 - accuracy: 0.0290 - mse: 0.7431 - rmse: 0.8620 - val_loss: 0.6072 - val_cat_acc: 0.4954 - val_accuracy: 0.0293 - val_mse: 0.7435 - val_rmse: 0.8623 - 1s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.6068 - cat_acc: 0.4948 - accuracy: 0.0306 - mse: 0.7433 - rmse: 0.8622 - val_loss: 0.6075 - val_cat_acc: 0.4954 - val_accuracy: 0.0319 - val_mse: 0.7436 - val_rmse: 0.8623 - 1s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.6068 - cat_acc: 0.4947 - accuracy: 0.0317 - mse: 0.7437 - rmse: 0.8624 - val_loss: 0.6072 - val_cat_acc: 0.4951 - val_accuracy: 0.0306 - val_mse: 0.7450 - val_rmse: 0.8631 - 1s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.6067 - cat_acc: 0.4948 - accuracy: 0.0334 - mse: 0.7438 - rmse: 0.8624 - val_loss: 0.6076 - val_cat_acc: 0.4952 - val_accuracy: 0.0351 - val_mse: 0.7439 - val_rmse: 0.8625 - 1s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.6065 - cat_acc: 0.4949 - accuracy: 0.0347 - mse: 0.7438 - rmse: 0.8624 - val_loss: 0.6078 - val_cat_acc: 0.4949 - val_accuracy: 0.0366 - val_mse: 0.7437 - val_rmse: 0.8624 - 1s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.6064 - cat_acc: 0.4948 - accuracy: 0.0358 - mse: 0.7442 - rmse: 0.8627 - val_loss: 0.6065 - val_cat_acc: 0.4952 - val_accuracy: 0.0350 - val_mse: 0.7451 - val_rmse: 0.8632 - 1s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.6064 - cat_acc: 0.4947 - accuracy: 0.0377 - mse: 0.7442 - rmse: 0.8627 - val_loss: 0.6071 - val_cat_acc: 0.4958 - val_accuracy: 0.0413 - val_mse: 0.7440 - val_rmse: 0.8625 - 1s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.6063 - cat_acc: 0.4949 - accuracy: 0.0384 - mse: 0.7446 - rmse: 0.8629 - val_loss: 0.6068 - val_cat_acc: 0.4953 - val_accuracy: 0.0380 - val_mse: 0.7447 - val_rmse: 0.8629 - 1s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.6063 - cat_acc: 0.4948 - accuracy: 0.0397 - mse: 0.7446 - rmse: 0.8629 - val_loss: 0.6068 - val_cat_acc: 0.4949 - val_accuracy: 0.0402 - val_mse: 0.7445 - val_rmse: 0.8629 - 1s/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.6060 - cat_acc: 0.4947 - accuracy: 0.0405 - mse: 0.7449 - rmse: 0.8631 - val_loss: 0.6065 - val_cat_acc: 0.4958 - val_accuracy: 0.0441 - val_mse: 0.7453 - val_rmse: 0.8633 - 1s/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.6060 - cat_acc: 0.4947 - accuracy: 0.0425 - mse: 0.7450 - rmse: 0.8631 - val_loss: 0.6064 - val_cat_acc: 0.4953 - val_accuracy: 0.0441 - val_mse: 0.7445 - val_rmse: 0.8628 - 1s/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 1s - loss: 0.6060 - cat_acc: 0.4949 - accuracy: 0.0435 - mse: 0.7450 - rmse: 0.8631 - val_loss: 0.6065 - val_cat_acc: 0.4956 - val_accuracy: 0.0439 - val_mse: 0.7452 - val_rmse: 0.8633 - 1s/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 1s - loss: 0.6059 - cat_acc: 0.4948 - accuracy: 0.0448 - mse: 0.7451 - rmse: 0.8632 - val_loss: 0.6061 - val_cat_acc: 0.4949 - val_accuracy: 0.0417 - val_mse: 0.7459 - val_rmse: 0.8636 - 1s/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 1s - loss: 0.6058 - cat_acc: 0.4947 - accuracy: 0.0458 - mse: 0.7453 - rmse: 0.8633 - val_loss: 0.6059 - val_cat_acc: 0.4956 - val_accuracy: 0.0449 - val_mse: 0.7461 - val_rmse: 0.8638 - 1s/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 1s - loss: 0.6056 - cat_acc: 0.4949 - accuracy: 0.0463 - mse: 0.7455 - rmse: 0.8634 - val_loss: 0.6068 - val_cat_acc: 0.4949 - val_accuracy: 0.0459 - val_mse: 0.7458 - val_rmse: 0.8636 - 1s/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "800/800 - 1s - loss: 0.6057 - cat_acc: 0.4949 - accuracy: 0.0482 - mse: 0.7453 - rmse: 0.8633 - val_loss: 0.6058 - val_cat_acc: 0.4951 - val_accuracy: 0.0455 - val_mse: 0.7465 - val_rmse: 0.8640 - 1s/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "800/800 - 1s - loss: 0.6057 - cat_acc: 0.4947 - accuracy: 0.0486 - mse: 0.7458 - rmse: 0.8636 - val_loss: 0.6060 - val_cat_acc: 0.4954 - val_accuracy: 0.0485 - val_mse: 0.7465 - val_rmse: 0.8640 - 1s/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "800/800 - 1s - loss: 0.6055 - cat_acc: 0.4949 - accuracy: 0.0503 - mse: 0.7456 - rmse: 0.8635 - val_loss: 0.6065 - val_cat_acc: 0.4942 - val_accuracy: 0.0454 - val_mse: 0.7466 - val_rmse: 0.8641 - 1s/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "800/800 - 1s - loss: 0.6055 - cat_acc: 0.4947 - accuracy: 0.0509 - mse: 0.7459 - rmse: 0.8636 - val_loss: 0.6056 - val_cat_acc: 0.4956 - val_accuracy: 0.0501 - val_mse: 0.7462 - val_rmse: 0.8638 - 1s/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "800/800 - 1s - loss: 0.6054 - cat_acc: 0.4949 - accuracy: 0.0517 - mse: 0.7459 - rmse: 0.8637 - val_loss: 0.6059 - val_cat_acc: 0.4958 - val_accuracy: 0.0508 - val_mse: 0.7464 - val_rmse: 0.8639 - 1s/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "800/800 - 1s - loss: 0.6053 - cat_acc: 0.4949 - accuracy: 0.0529 - mse: 0.7460 - rmse: 0.8637 - val_loss: 0.6057 - val_cat_acc: 0.4951 - val_accuracy: 0.0514 - val_mse: 0.7463 - val_rmse: 0.8639 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "800/800 - 1s - loss: 0.6053 - cat_acc: 0.4949 - accuracy: 0.0539 - mse: 0.7462 - rmse: 0.8638 - val_loss: 0.6058 - val_cat_acc: 0.4954 - val_accuracy: 0.0530 - val_mse: 0.7465 - val_rmse: 0.8640 - 1s/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "800/800 - 1s - loss: 0.6053 - cat_acc: 0.4949 - accuracy: 0.0544 - mse: 0.7462 - rmse: 0.8638 - val_loss: 0.6054 - val_cat_acc: 0.4954 - val_accuracy: 0.0547 - val_mse: 0.7465 - val_rmse: 0.8640 - 1s/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "800/800 - 1s - loss: 0.6052 - cat_acc: 0.4950 - accuracy: 0.0556 - mse: 0.7462 - rmse: 0.8639 - val_loss: 0.6054 - val_cat_acc: 0.4956 - val_accuracy: 0.0558 - val_mse: 0.7469 - val_rmse: 0.8642 - 1s/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "800/800 - 1s - loss: 0.6051 - cat_acc: 0.4949 - accuracy: 0.0562 - mse: 0.7465 - rmse: 0.8640 - val_loss: 0.6065 - val_cat_acc: 0.4954 - val_accuracy: 0.0560 - val_mse: 0.7471 - val_rmse: 0.8644 - 1s/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "800/800 - 1s - loss: 0.6051 - cat_acc: 0.4950 - accuracy: 0.0568 - mse: 0.7466 - rmse: 0.8641 - val_loss: 0.6057 - val_cat_acc: 0.4952 - val_accuracy: 0.0571 - val_mse: 0.7470 - val_rmse: 0.8643 - 1s/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "800/800 - 1s - loss: 0.6051 - cat_acc: 0.4949 - accuracy: 0.0581 - mse: 0.7465 - rmse: 0.8640 - val_loss: 0.6054 - val_cat_acc: 0.4954 - val_accuracy: 0.0581 - val_mse: 0.7476 - val_rmse: 0.8646 - 1s/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "800/800 - 1s - loss: 0.6050 - cat_acc: 0.4948 - accuracy: 0.0592 - mse: 0.7466 - rmse: 0.8641 - val_loss: 0.6057 - val_cat_acc: 0.4951 - val_accuracy: 0.0565 - val_mse: 0.7477 - val_rmse: 0.8647 - 1s/epoch - 2ms/step\n",
      "Epoch 78: early stopping\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "INFO:tensorflow:Assets written to: ram://1edc1037-c22c-4785-b3f4-32b3ef38659b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://1edc1037-c22c-4785-b3f4-32b3ef38659b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 neuron in [1, 10, 100]\n",
      "Training for 1 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.6746 - cat_acc: 0.9521 - accuracy: 0.0000e+00 - mse: 0.3194 - rmse: 0.5651 - val_loss: 0.4417 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.4958 - val_rmse: 0.7041 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.4006 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.6036 - rmse: 0.7769 - val_loss: 0.3805 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.6769 - val_rmse: 0.8227 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.3698 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7096 - rmse: 0.8424 - val_loss: 0.3666 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7300 - val_rmse: 0.8544 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3627 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7370 - rmse: 0.8585 - val_loss: 0.3632 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7437 - val_rmse: 0.8624 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3604 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7459 - rmse: 0.8636 - val_loss: 0.3617 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7494 - val_rmse: 0.8657 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.3592 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7500 - rmse: 0.8660 - val_loss: 0.3608 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7522 - val_rmse: 0.8673 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3585 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7522 - rmse: 0.8673 - val_loss: 0.3601 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7540 - val_rmse: 0.8683 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3579 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7535 - rmse: 0.8681 - val_loss: 0.3596 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7550 - val_rmse: 0.8689 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.3574 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7544 - rmse: 0.8685 - val_loss: 0.3592 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7557 - val_rmse: 0.8693 - 1s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3571 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7550 - rmse: 0.8689 - val_loss: 0.3589 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7563 - val_rmse: 0.8697 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3568 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7555 - rmse: 0.8692 - val_loss: 0.3586 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7567 - val_rmse: 0.8699 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3565 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7558 - rmse: 0.8694 - val_loss: 0.3584 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7570 - val_rmse: 0.8701 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3564 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7561 - rmse: 0.8696 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7573 - val_rmse: 0.8702 - 1s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 3.1250e-06 - mse: 0.7563 - rmse: 0.8697 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 2.5000e-05 - val_mse: 0.7575 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 2.8125e-05 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 6.2500e-05 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 1.6250e-04 - mse: 0.7566 - rmse: 0.8698 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 1.1250e-04 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 4.4687e-04 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 3.0000e-04 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 7.9062e-04 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0012 - val_mse: 0.7579 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0015 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0011 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0025 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0029 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0036 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0053 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0048 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0053 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0060 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0047 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0083 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0075 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0086 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0084 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0102 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0074 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0120 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0122 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0147 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0131 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0157 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0175 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0168 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0147 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0199 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0217 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0203 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0266 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0216 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0256 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0344 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0361 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0246 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0170 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0260 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0508 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0270 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0270 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0246 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0215 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0241 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0317 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0404 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0336 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0246 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0181 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0458 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0287 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0322 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0511 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0328 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0222 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0301 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0232 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0344 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0534 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0404 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0375 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0324 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0325 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0323 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0293 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0315 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0288 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0368 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0536 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0473 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0394 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0405 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0392 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0421 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0319 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0703 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0848 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 56/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0525 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0521 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 57/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0509 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0601 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 58/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0481 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0578 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 59/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0379 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0288 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 60/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0350 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0409 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 61/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0437 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0375 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 62/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0518 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0441 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 63/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0364 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0566 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 64/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0768 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0596 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 65/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0786 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0825 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 66/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0587 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0390 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 66: early stopping\n",
      "3125/3125 [==============================] - 3s 929us/step\n",
      "INFO:tensorflow:Assets written to: ram://5badd70f-052c-4e37-a024-3ab533ba5088/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://5badd70f-052c-4e37-a024-3ab533ba5088/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.6805 - cat_acc: 0.9587 - accuracy: 0.0000e+00 - mse: 0.3110 - rmse: 0.5577 - val_loss: 0.4629 - val_cat_acc: 0.9917 - val_accuracy: 0.0000e+00 - val_mse: 0.4520 - val_rmse: 0.6723 - 2s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.4068 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.5912 - rmse: 0.7689 - val_loss: 0.3749 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.6998 - val_rmse: 0.8366 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.3665 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7233 - rmse: 0.8505 - val_loss: 0.3649 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7376 - val_rmse: 0.8588 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3616 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7420 - rmse: 0.8614 - val_loss: 0.3625 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7470 - val_rmse: 0.8643 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3600 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7483 - rmse: 0.8651 - val_loss: 0.3614 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7512 - val_rmse: 0.8667 - 1s/epoch - 1ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.3590 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7513 - rmse: 0.8668 - val_loss: 0.3606 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7533 - val_rmse: 0.8679 - 1s/epoch - 1ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3584 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7530 - rmse: 0.8678 - val_loss: 0.3600 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7546 - val_rmse: 0.8687 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3578 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7540 - rmse: 0.8683 - val_loss: 0.3595 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7554 - val_rmse: 0.8691 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.3574 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7547 - rmse: 0.8687 - val_loss: 0.3592 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7560 - val_rmse: 0.8695 - 1s/epoch - 1ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3570 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7552 - rmse: 0.8690 - val_loss: 0.3589 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7565 - val_rmse: 0.8698 - 1s/epoch - 1ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3568 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7556 - rmse: 0.8693 - val_loss: 0.3586 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7568 - val_rmse: 0.8700 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3565 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7560 - rmse: 0.8695 - val_loss: 0.3584 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7571 - val_rmse: 0.8701 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3564 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7562 - rmse: 0.8696 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 1ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7575 - val_rmse: 0.8703 - 1s/epoch - 1ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 1ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 1ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 6.2500e-06 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 2.1875e-05 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 6.2500e-05 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 1.5313e-04 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 3.3750e-04 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 4.6875e-04 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 7.0000e-04 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 7.6250e-04 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 5.3750e-04 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0012 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 9.6250e-04 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 1ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0036 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0031 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0036 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0027 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3556 - cat_acc: 0.9928 - accuracy: 0.0063 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0035 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0047 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0088 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0101 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0103 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0084 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0176 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0129 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0118 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0121 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0065 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0169 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0115 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0162 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0120 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0152 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0322 - val_mse: 0.7574 - val_rmse: 0.8703 - 1s/epoch - 1ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0307 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0281 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0208 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0196 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0231 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.0625 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 38/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0412 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0290 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 39/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0302 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0472 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0324 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0170 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 41/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0286 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0160 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 42/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0372 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0286 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 43/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0300 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3575 - val_cat_acc: 0.9918 - val_accuracy: 0.1107 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 44/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0819 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0498 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0349 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0375 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0318 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0270 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 47/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0421 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0366 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 48/100\n",
      "800/800 - 1s - loss: 0.3555 - cat_acc: 0.9928 - accuracy: 0.0425 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0545 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 49/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0317 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3586 - val_cat_acc: 0.9915 - val_accuracy: 0.0577 - val_mse: 0.7571 - val_rmse: 0.8701 - 1s/epoch - 1ms/step\n",
      "Epoch 50/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0594 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0333 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 51/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0510 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0423 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 52/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0425 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0492 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0397 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0633 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0718 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0677 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 1ms/step\n",
      "Epoch 55/100\n",
      "800/800 - 1s - loss: 0.3554 - cat_acc: 0.9928 - accuracy: 0.0566 - mse: 0.7571 - rmse: 0.8701 - val_loss: 0.3574 - val_cat_acc: 0.9918 - val_accuracy: 0.0612 - val_mse: 0.7582 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 55: early stopping\n",
      "3125/3125 [==============================] - 3s 932us/step\n",
      "INFO:tensorflow:Assets written to: ram://45e09f7b-d1e5-46d6-b12c-ab6b674b57a2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://45e09f7b-d1e5-46d6-b12c-ab6b674b57a2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100 neuron in [1, 10, 100]\n",
      "Training for 1 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.4579 - cat_acc: 0.9775 - accuracy: 0.0000e+00 - mse: 0.6183 - rmse: 0.7863 - val_loss: 0.3640 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7471 - val_rmse: 0.8643 - 2s/epoch - 2ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.3608 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7508 - rmse: 0.8665 - val_loss: 0.3620 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7542 - val_rmse: 0.8685 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.3596 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7540 - rmse: 0.8683 - val_loss: 0.3611 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7555 - val_rmse: 0.8692 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3589 - cat_acc: 0.9928 - accuracy: 6.2500e-06 - mse: 0.7548 - rmse: 0.8688 - val_loss: 0.3605 - val_cat_acc: 0.9918 - val_accuracy: 1.2500e-05 - val_mse: 0.7563 - val_rmse: 0.8696 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3583 - cat_acc: 0.9928 - accuracy: 5.9375e-05 - mse: 0.7552 - rmse: 0.8690 - val_loss: 0.3600 - val_cat_acc: 0.9918 - val_accuracy: 1.6250e-04 - val_mse: 0.7564 - val_rmse: 0.8697 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.3579 - cat_acc: 0.9928 - accuracy: 2.0000e-04 - mse: 0.7555 - rmse: 0.8692 - val_loss: 0.3596 - val_cat_acc: 0.9918 - val_accuracy: 2.1250e-04 - val_mse: 0.7567 - val_rmse: 0.8699 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3575 - cat_acc: 0.9928 - accuracy: 4.4375e-04 - mse: 0.7558 - rmse: 0.8694 - val_loss: 0.3593 - val_cat_acc: 0.9918 - val_accuracy: 9.1250e-04 - val_mse: 0.7568 - val_rmse: 0.8700 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3572 - cat_acc: 0.9928 - accuracy: 9.2500e-04 - mse: 0.7560 - rmse: 0.8695 - val_loss: 0.3591 - val_cat_acc: 0.9918 - val_accuracy: 0.0037 - val_mse: 0.7569 - val_rmse: 0.8700 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.3570 - cat_acc: 0.9928 - accuracy: 0.0015 - mse: 0.7563 - rmse: 0.8696 - val_loss: 0.3587 - val_cat_acc: 0.9918 - val_accuracy: 0.0011 - val_mse: 0.7575 - val_rmse: 0.8703 - 1s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3568 - cat_acc: 0.9928 - accuracy: 0.0028 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3585 - val_cat_acc: 0.9918 - val_accuracy: 0.0012 - val_mse: 0.7576 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3567 - cat_acc: 0.9928 - accuracy: 0.0049 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3585 - val_cat_acc: 0.9918 - val_accuracy: 0.0037 - val_mse: 0.7577 - val_rmse: 0.8704 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3564 - cat_acc: 0.9928 - accuracy: 0.0032 - mse: 0.7566 - rmse: 0.8698 - val_loss: 0.3587 - val_cat_acc: 0.9918 - val_accuracy: 0.0039 - val_mse: 0.7571 - val_rmse: 0.8701 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3564 - cat_acc: 0.9928 - accuracy: 0.0049 - mse: 0.7566 - rmse: 0.8699 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0073 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3563 - cat_acc: 0.9928 - accuracy: 0.0080 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0077 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0112 - mse: 0.7567 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0135 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0120 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3583 - val_cat_acc: 0.9918 - val_accuracy: 0.0203 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0171 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0227 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0163 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0100 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0121 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0397 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0218 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0102 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0229 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0277 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0196 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0228 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0248 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0536 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0282 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0194 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0623 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0948 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0730 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0498 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0536 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0439 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0340 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0244 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0511 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0358 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0291 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3576 - val_cat_acc: 0.9918 - val_accuracy: 0.0189 - val_mse: 0.7580 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0275 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0309 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0238 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0445 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0607 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0766 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "800/800 - 1s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0500 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0507 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "800/800 - 1s - loss: 0.3557 - cat_acc: 0.9928 - accuracy: 0.0347 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3577 - val_cat_acc: 0.9918 - val_accuracy: 0.0365 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 35: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 3s 940us/step\n",
      "INFO:tensorflow:Assets written to: ram://0b51e2ac-a0bf-4506-9daa-4bcb2b9dc15b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://0b51e2ac-a0bf-4506-9daa-4bcb2b9dc15b/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 init in 2 inits\n",
      "Modelo nÃ£o existe\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "800/800 - 2s - loss: 0.4532 - cat_acc: 0.9782 - accuracy: 0.0000e+00 - mse: 0.6229 - rmse: 0.7892 - val_loss: 0.3638 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7476 - val_rmse: 0.8646 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "800/800 - 1s - loss: 0.3606 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7511 - rmse: 0.8667 - val_loss: 0.3618 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7545 - val_rmse: 0.8686 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "800/800 - 1s - loss: 0.3595 - cat_acc: 0.9928 - accuracy: 0.0000e+00 - mse: 0.7542 - rmse: 0.8684 - val_loss: 0.3611 - val_cat_acc: 0.9918 - val_accuracy: 0.0000e+00 - val_mse: 0.7558 - val_rmse: 0.8694 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "800/800 - 1s - loss: 0.3588 - cat_acc: 0.9928 - accuracy: 9.3750e-06 - mse: 0.7550 - rmse: 0.8689 - val_loss: 0.3604 - val_cat_acc: 0.9918 - val_accuracy: 5.0000e-05 - val_mse: 0.7563 - val_rmse: 0.8696 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "800/800 - 1s - loss: 0.3582 - cat_acc: 0.9928 - accuracy: 9.0625e-05 - mse: 0.7553 - rmse: 0.8691 - val_loss: 0.3599 - val_cat_acc: 0.9918 - val_accuracy: 1.2500e-04 - val_mse: 0.7566 - val_rmse: 0.8698 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "800/800 - 1s - loss: 0.3578 - cat_acc: 0.9928 - accuracy: 2.3750e-04 - mse: 0.7556 - rmse: 0.8693 - val_loss: 0.3595 - val_cat_acc: 0.9918 - val_accuracy: 3.1250e-04 - val_mse: 0.7568 - val_rmse: 0.8699 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "800/800 - 1s - loss: 0.3574 - cat_acc: 0.9928 - accuracy: 6.4063e-04 - mse: 0.7558 - rmse: 0.8694 - val_loss: 0.3592 - val_cat_acc: 0.9918 - val_accuracy: 9.3750e-04 - val_mse: 0.7570 - val_rmse: 0.8700 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "800/800 - 1s - loss: 0.3571 - cat_acc: 0.9928 - accuracy: 0.0013 - mse: 0.7560 - rmse: 0.8695 - val_loss: 0.3590 - val_cat_acc: 0.9918 - val_accuracy: 0.0029 - val_mse: 0.7572 - val_rmse: 0.8702 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "800/800 - 1s - loss: 0.3569 - cat_acc: 0.9928 - accuracy: 0.0018 - mse: 0.7563 - rmse: 0.8696 - val_loss: 0.3587 - val_cat_acc: 0.9918 - val_accuracy: 0.0021 - val_mse: 0.7573 - val_rmse: 0.8702 - 1s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "800/800 - 1s - loss: 0.3567 - cat_acc: 0.9928 - accuracy: 0.0029 - mse: 0.7564 - rmse: 0.8697 - val_loss: 0.3586 - val_cat_acc: 0.9918 - val_accuracy: 0.0039 - val_mse: 0.7577 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "800/800 - 1s - loss: 0.3566 - cat_acc: 0.9928 - accuracy: 0.0043 - mse: 0.7565 - rmse: 0.8698 - val_loss: 0.3584 - val_cat_acc: 0.9918 - val_accuracy: 0.0023 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "800/800 - 1s - loss: 0.3564 - cat_acc: 0.9928 - accuracy: 0.0051 - mse: 0.7566 - rmse: 0.8698 - val_loss: 0.3584 - val_cat_acc: 0.9918 - val_accuracy: 0.0081 - val_mse: 0.7573 - val_rmse: 0.8702 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "800/800 - 1s - loss: 0.3564 - cat_acc: 0.9928 - accuracy: 0.0065 - mse: 0.7566 - rmse: 0.8699 - val_loss: 0.3582 - val_cat_acc: 0.9918 - val_accuracy: 0.0086 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0060 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3586 - val_cat_acc: 0.9918 - val_accuracy: 0.0115 - val_mse: 0.7568 - val_rmse: 0.8699 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "800/800 - 1s - loss: 0.3562 - cat_acc: 0.9928 - accuracy: 0.0080 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0048 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0080 - mse: 0.7568 - rmse: 0.8699 - val_loss: 0.3581 - val_cat_acc: 0.9918 - val_accuracy: 0.0164 - val_mse: 0.7578 - val_rmse: 0.8705 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "800/800 - 1s - loss: 0.3561 - cat_acc: 0.9928 - accuracy: 0.0109 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0093 - val_mse: 0.7580 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "800/800 - 2s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0175 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0196 - val_mse: 0.7576 - val_rmse: 0.8704 - 2s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0125 - mse: 0.7568 - rmse: 0.8700 - val_loss: 0.3580 - val_cat_acc: 0.9918 - val_accuracy: 0.0230 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0163 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0326 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "800/800 - 2s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0259 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0128 - val_mse: 0.7580 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "800/800 - 2s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0203 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0273 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "800/800 - 2s - loss: 0.3558 - cat_acc: 0.9928 - accuracy: 0.0249 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0159 - val_mse: 0.7581 - val_rmse: 0.8707 - 2s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0249 - mse: 0.7570 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0367 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "800/800 - 1s - loss: 0.3560 - cat_acc: 0.9928 - accuracy: 0.0551 - mse: 0.7569 - rmse: 0.8700 - val_loss: 0.3579 - val_cat_acc: 0.9918 - val_accuracy: 0.0871 - val_mse: 0.7581 - val_rmse: 0.8707 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "800/800 - 1s - loss: 0.3559 - cat_acc: 0.9928 - accuracy: 0.0640 - mse: 0.7570 - rmse: 0.8701 - val_loss: 0.3578 - val_cat_acc: 0.9918 - val_accuracy: 0.0441 - val_mse: 0.7579 - val_rmse: 0.8706 - 1s/epoch - 2ms/step\n",
      "Epoch 26: early stopping\n",
      "3125/3125 [==============================] - 3s 911us/step\n",
      "INFO:tensorflow:Assets written to: ram://39266654-cb8c-47e7-b2db-b3823c0ae250/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://39266654-cb8c-47e7-b2db-b3823c0ae250/assets\n"
     ]
    }
   ],
   "source": [
    "# for kFolds CV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from src.functions.AuxiliarFunctions import *\n",
    "\n",
    "\n",
    "print(get_train_description(df_config, train_id))\n",
    "\n",
    "\n",
    "if True: # remova quando tiver seguranÃ§a no treinamento\n",
    "    print('Training Starting')\n",
    "    # data\n",
    "    model_type = 'MLPNeuralNetwork'\n",
    "    data = df_train.drop(columns=['target']).copy(deep=True)\n",
    "    print('Data shape: (%i, %i)'%(data.shape[0], data.shape[1]))\n",
    "    \n",
    "    trgt = df_train['target'].copy(deep=True).values\n",
    "    print('Trgt shape: %i'%(trgt.shape[0]))\n",
    "    \n",
    "    hidden_neurons = list(get_list_of_hidden_neurons(df_config['model_neurons'][train_id]))\n",
    "    \n",
    "    with open(df_config['model_status'][train_id],'rb') as file_handler:\n",
    "        [model_status] = pickle.load(file_handler)\n",
    "    \n",
    "    \n",
    "    n_folds = df_config['cv_folds'][train_id]\n",
    "    for ifold in range(n_folds):\n",
    "        print('Training %i fold of %i folds'%(ifold+1, n_folds))\n",
    "        # pipeline\n",
    "        pipeline_name = '%s_CV_fold_%i_of_%i_cv_pipe.pkl'%(df_config['hash_id'][train_id],\n",
    "                                                           ifold, n_folds)\n",
    "        \n",
    "        pipeline_path = df_config['pipeline_path'][train_id]\n",
    "        \n",
    "        with open(os.path.join(pipeline_path,pipeline_name),'rb') as file_handler:\n",
    "            pipe = joblib.load(file_handler)\n",
    "        trn_data = pipe.transform(data)\n",
    "        trn_trgt = tf.keras.utils.to_categorical(trgt, num_classes=len(np.unique(trgt)))\n",
    "        \n",
    "        for idx, ineuron in enumerate(hidden_neurons):\n",
    "            print('Training for %i neuron in'%(ineuron),hidden_neurons)\n",
    "            \n",
    "            for iinit in range(df_config['model_inits'][train_id]):\n",
    "                print('Training for %i init in %i inits'%(iinit+1, df_config['model_inits'][train_id]))\n",
    "                model_name = '%s_%s_%i_fold_%i_neuron_%i_init_model.pkl'%(df_config['hash_id'][train_id],\n",
    "                                                                          model_type,ifold, ineuron, iinit)\n",
    "                model_path = df_config['model_path'][train_id]\n",
    "                #print(os.path.join(model_path, model_name))\n",
    "                if os.path.exists(os.path.join(model_path, model_name)):\n",
    "                    print('Modelo existente em %s'%(os.path.join(model_path, model_name)))\n",
    "                    model = MLPModel(n_hidden_neurons=ineuron,verbose=2)\n",
    "                    model.load(os.path.join(model_path, model_name))\n",
    "                    \n",
    "                else:\n",
    "                    print('Modelo nÃ£o existe\\n\\n')\n",
    "                    model = MLPModel(n_hidden_neurons=ineuron,verbose=2)\n",
    "                    model.fit(trn_data, trn_trgt, trn_id=trn_idx, val_id=val_idx, \n",
    "                              epochs=df_config['model_epochs'][train_id], \n",
    "                              random_state=iinit, \n",
    "                              learning_rate=df_config['model_learning_rate'][train_id],\n",
    "                              patience=df_config['model_patience'][train_id],\n",
    "                              batch_size=int(df_config['model_batch_size'][train_id]),\n",
    "                             )\n",
    "                    predictions = model.predict(trn_data)\n",
    "                    df_predict = pd.DataFrame(data=np.concatenate((trgt[:,np.newaxis], \n",
    "                                                                   np.argmax(predictions,axis=1)[:,np.newaxis]),\n",
    "                                                                  axis=1), \n",
    "                                              columns=['target', 'predictions'])\n",
    "                    prediction_name = '%s_%s_%i_fold_%i_neuron_%i_init_prediction_file.csv'%(df_config['hash_id'][train_id],\n",
    "                                                                                             model_type,ifold, ineuron, iinit)\n",
    "                    df_predict.to_csv(os.path.join(model_path, prediction_name),index=False)\n",
    "                    model.save(os.path.join(model_path, model_name))\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f762e2e0",
   "metadata": {},
   "source": [
    "## AnÃ¡lise de topologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d466502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "=======================================\n",
      "Toy Data Classification Training Process\n",
      "=======================================\n",
      "Processing ../data/-8564343657574404315_train_data.csv\n",
      "Hidden Neurons: 1, 10, 100\n",
      "CV Folds: 5\n",
      "Inits: 2\n",
      "\n",
      "Analysing 1 fold of 5 folds\n",
      "Analysing for 1 neuron in [1, 10, 100]\n",
      "Analysing for 1 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_0_fold_1_neuron_0_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.495\n",
      "Analysing for 2 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_0_fold_1_neuron_1_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.486\n",
      "Analysing for 10 neuron in [1, 10, 100]\n",
      "Analysing for 1 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_0_fold_10_neuron_0_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing for 2 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_0_fold_10_neuron_1_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing for 100 neuron in [1, 10, 100]\n",
      "Analysing for 1 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_0_fold_100_neuron_0_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing for 2 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_0_fold_100_neuron_1_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing 2 fold of 5 folds\n",
      "Analysing for 1 neuron in [1, 10, 100]\n",
      "Analysing for 1 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_1_fold_1_neuron_0_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.492\n",
      "Analysing for 2 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_1_fold_1_neuron_1_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.491\n",
      "Analysing for 10 neuron in [1, 10, 100]\n",
      "Analysing for 1 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_1_fold_10_neuron_0_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing for 2 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_1_fold_10_neuron_1_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing for 100 neuron in [1, 10, 100]\n",
      "Analysing for 1 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_1_fold_100_neuron_0_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing for 2 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_1_fold_100_neuron_1_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing 3 fold of 5 folds\n",
      "Analysing for 1 neuron in [1, 10, 100]\n",
      "Analysing for 1 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_2_fold_1_neuron_0_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.491\n",
      "Analysing for 2 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_2_fold_1_neuron_1_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.491\n",
      "Analysing for 10 neuron in [1, 10, 100]\n",
      "Analysing for 1 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_2_fold_10_neuron_0_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing for 2 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_2_fold_10_neuron_1_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing for 100 neuron in [1, 10, 100]\n",
      "Analysing for 1 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_2_fold_100_neuron_0_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing for 2 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_2_fold_100_neuron_1_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing 4 fold of 5 folds\n",
      "Analysing for 1 neuron in [1, 10, 100]\n",
      "Analysing for 1 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_3_fold_1_neuron_0_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.495\n",
      "Analysing for 2 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_3_fold_1_neuron_1_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.494\n",
      "Analysing for 10 neuron in [1, 10, 100]\n",
      "Analysing for 1 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_3_fold_10_neuron_0_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing for 2 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_3_fold_10_neuron_1_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing for 100 neuron in [1, 10, 100]\n",
      "Analysing for 1 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_3_fold_100_neuron_0_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing for 2 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_3_fold_100_neuron_1_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing 5 fold of 5 folds\n",
      "Analysing for 1 neuron in [1, 10, 100]\n",
      "Analysing for 1 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_4_fold_1_neuron_0_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.491\n",
      "Analysing for 2 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_4_fold_1_neuron_1_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.495\n",
      "Analysing for 10 neuron in [1, 10, 100]\n",
      "Analysing for 1 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_4_fold_10_neuron_0_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing for 2 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_4_fold_10_neuron_1_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing for 100 neuron in [1, 10, 100]\n",
      "Analysing for 1 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_4_fold_100_neuron_0_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n",
      "Analysing for 2 init in 2 inits\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_4_fold_100_neuron_1_init_prediction_file.csv\n",
      "Figure of Merit: Acc, value 0.993\n"
     ]
    }
   ],
   "source": [
    "# for kFolds CV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from src.functions.AuxiliarFunctions import *\n",
    "\n",
    "\n",
    "print(get_train_description(df_config, train_id))\n",
    "\n",
    "\n",
    "if True: # remova quando tiver seguranÃ§a no treinamento\n",
    "    model_type = 'MLPNeuralNetwork'\n",
    "    \n",
    "    hidden_neurons = list(get_list_of_hidden_neurons(df_config['model_neurons'][train_id]))\n",
    "    \n",
    "    n_folds = df_config['cv_folds'][train_id]\n",
    "    \n",
    "    figure_of_merit_matrix = np.zeros((len(hidden_neurons),n_folds))\n",
    "    best_init_matrix = np.zeros((len(hidden_neurons),n_folds))\n",
    "    \n",
    "    for ifold in range(n_folds):\n",
    "        print('Analysing %i fold of %i folds'%(ifold+1, n_folds))\n",
    "        \n",
    "        for idx, ineuron in enumerate(hidden_neurons):\n",
    "            print('Analysing for %i neuron in'%(ineuron),hidden_neurons)\n",
    "            \n",
    "            best_figure_of_merit = -9999\n",
    "            \n",
    "            for iinit in range(df_config['model_inits'][train_id]):\n",
    "                print('Analysing for %i init in %i inits'%(iinit+1, df_config['model_inits'][train_id]))\n",
    "                # repare que mudou!\n",
    "                model_name = '%s_%s_%i_fold_%i_neuron_%i_init_prediction_file.csv'%(df_config['hash_id'][train_id],\n",
    "                                                                                    model_type,ifold, ineuron, iinit)\n",
    "                model_path = df_config['model_path'][train_id]\n",
    "                #print(os.path.join(model_path, model_name))\n",
    "                if os.path.exists(os.path.join(model_path, model_name)):\n",
    "                    print('Modelo existente em %s'%(os.path.join(model_path, model_name)))\n",
    "                    # adicionar a funÃ§Ã£o de analise acc ou outra\n",
    "                    df_predictions = pd.read_csv(os.path.join(model_path, model_name))\n",
    "                    figure_of_merit = accuracy_score(df_predictions['target'].values, df_predictions['predictions'].values)\n",
    "                    print('Figure of Merit: Acc, value %1.3f'%(figure_of_merit))\n",
    "                    if best_figure_of_merit < figure_of_merit:\n",
    "                        figure_of_merit_matrix[idx, ifold] = figure_of_merit\n",
    "                        best_figure_of_merit = figure_of_merit\n",
    "                        best_init_matrix[idx,ifold] = iinit\n",
    "                    \n",
    "                else:\n",
    "                    print('Modelo nÃ£o existe\\n\\n')\n",
    "                    # fora!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc1c4e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure_of_merit_label = 'Accuracy'\n",
    "\n",
    "hidden_neurons = list(get_list_of_hidden_neurons(df_config['model_neurons'][train_id]))\n",
    "mean_figure_of_merit = np.mean(figure_of_merit_matrix[:,:],axis=1)\n",
    "std_figure_of_merit = np.std(figure_of_merit_matrix[:,:],axis=1) \n",
    "\n",
    "linestyle = {\"linestyle\":\"-\", \"linewidth\":1, \"markersize\":2.5, \"markeredgewidth\":1, \"elinewidth\":1, \"capsize\":5}\n",
    "\n",
    "plt.errorbar(hidden_neurons, mean_figure_of_merit, yerr=std_figure_of_merit,\n",
    "             color=\"k\", fmt='o',**linestyle, label='Figure of Merit')\n",
    "plt.title('%s vs Neurons analysis'%(figure_of_merit_label))\n",
    "plt.ylabel('%s (percentage)'%(figure_of_merit_label))\n",
    "plt.xlabel('Number of Neurons')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa110522",
   "metadata": {},
   "source": [
    "## AnÃ¡lise de RelevÃ¢ncia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "71d8a30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "=======================================\n",
      "Toy Data Classification Training Process\n",
      "=======================================\n",
      "Processing ../data/-8564343657574404315_train_data.csv\n",
      "Hidden Neurons: 1, 10, 100\n",
      "CV Folds: 5\n",
      "Inits: 2\n",
      "\n",
      "Analysis Starting\n",
      "Data shape: (100000, 20)\n",
      "Trgt shape: 100000\n",
      "Analysing 1 fold of 5 folds\n",
      "Analysing for 100 neurons\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_0_fold_100_neuron_0_init_model.pkl\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 0 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 1 input in 20\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "Analysing for 2 input in 20\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "Analysing for 3 input in 20\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "Analysing for 4 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 5 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 6 input in 20\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "Analysing for 7 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 8 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 9 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 10 input in 20\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "Analysing for 11 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 12 input in 20\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "Analysing for 13 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 14 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 15 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 16 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 17 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 18 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 19 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing 2 fold of 5 folds\n",
      "Analysing for 100 neurons\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_1_fold_100_neuron_0_init_model.pkl\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "Analysing for 0 input in 20\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "Analysing for 1 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 2 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 3 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 4 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 5 input in 20\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Analysing for 6 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 7 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 8 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 9 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 10 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 11 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 12 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 13 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 14 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 15 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 16 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 17 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 18 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 19 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing 3 fold of 5 folds\n",
      "Analysing for 100 neurons\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_2_fold_100_neuron_0_init_model.pkl\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 0 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 1 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 2 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 3 input in 20\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "Analysing for 4 input in 20\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "Analysing for 5 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 6 input in 20\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "Analysing for 7 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 8 input in 20\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "Analysing for 9 input in 20\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "Analysing for 10 input in 20\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "Analysing for 11 input in 20\n",
      "3125/3125 [==============================] - 5s 1ms/step\n",
      "Analysing for 12 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 13 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 14 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 15 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 16 input in 20\n",
      "3125/3125 [==============================] - 7s 2ms/step\n",
      "Analysing for 17 input in 20\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "Analysing for 18 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 19 input in 20\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Analysing 4 fold of 5 folds\n",
      "Analysing for 100 neurons\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_3_fold_100_neuron_0_init_model.pkl\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 0 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 1 input in 20\n",
      "3125/3125 [==============================] - 3s 1ms/step\n",
      "Analysing for 2 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 3 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 4 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 5 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 6 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 7 input in 20\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Analysing for 8 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 9 input in 20\n",
      "3125/3125 [==============================] - 5s 1ms/step\n",
      "Analysing for 10 input in 20\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Analysing for 11 input in 20\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "Analysing for 12 input in 20\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "Analysing for 13 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 14 input in 20\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Analysing for 15 input in 20\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Analysing for 16 input in 20\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "Analysing for 17 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 18 input in 20\n",
      "3125/3125 [==============================] - 5s 1ms/step\n",
      "Analysing for 19 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing 5 fold of 5 folds\n",
      "Analysing for 100 neurons\n",
      "Modelo existente em ../data/models/-8564343657574404315_MLPNeuralNetwork_4_fold_100_neuron_0_init_model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Analysing for 0 input in 20\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Analysing for 1 input in 20\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Analysing for 2 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 3 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 4 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 5 input in 20\n",
      "3125/3125 [==============================] - 5s 2ms/step\n",
      "Analysing for 6 input in 20\n",
      "3125/3125 [==============================] - 5s 1ms/step\n",
      "Analysing for 7 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 8 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 9 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 10 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 11 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 12 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 13 input in 20\n",
      "3125/3125 [==============================] - 6s 2ms/step\n",
      "Analysing for 14 input in 20\n",
      "3125/3125 [==============================] - 5s 1ms/step\n",
      "Analysing for 15 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 16 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 17 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 18 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n",
      "Analysing for 19 input in 20\n",
      "3125/3125 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# for kFolds CV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from src.functions.AuxiliarFunctions import *\n",
    "\n",
    "\n",
    "print(get_train_description(df_config, train_id))\n",
    "\n",
    "\n",
    "if True: # remova quando tiver seguranÃ§a no treinamento\n",
    "    print('Analysis Starting')\n",
    "    # data\n",
    "    model_type = 'MLPNeuralNetwork'\n",
    "    data = df_train.drop(columns=['target']).copy(deep=True)\n",
    "    print('Data shape: (%i, %i)'%(data.shape[0], data.shape[1]))\n",
    "    \n",
    "    trgt = df_train['target'].copy(deep=True).values\n",
    "    print('Trgt shape: %i'%(trgt.shape[0]))\n",
    "    \n",
    "    hidden_neurons = list(get_list_of_hidden_neurons(df_config['model_neurons'][train_id]))\n",
    "    \n",
    "    with open(df_config['model_status'][train_id],'rb') as file_handler:\n",
    "        [model_status] = pickle.load(file_handler)\n",
    "    \n",
    "    \n",
    "    n_folds = df_config['cv_folds'][train_id]\n",
    "    model_hidden_neurons = 100 \n",
    "    \n",
    "    figure_of_merit_relevance_refence = np.zeros((n_folds,1))\n",
    "    figure_of_merit_relevance_matrix = np.zeros((n_folds,data.shape[1]))\n",
    "    \n",
    "    for ifold in range(n_folds):\n",
    "        print('Analysing %i fold of %i folds'%(ifold+1, n_folds))\n",
    "        # pipeline\n",
    "        pipeline_name = '%s_CV_fold_%i_of_%i_cv_pipe.pkl'%(df_config['hash_id'][train_id],\n",
    "                                                           ifold, n_folds)\n",
    "        \n",
    "        pipeline_path = df_config['pipeline_path'][train_id]\n",
    "        \n",
    "        with open(os.path.join(pipeline_path,pipeline_name),'rb') as file_handler:\n",
    "            pipe = joblib.load(file_handler)\n",
    "        trn_data = pipe.transform(data)\n",
    "        trn_trgt = tf.keras.utils.to_categorical(trgt, num_classes=len(np.unique(trgt)))\n",
    "        \n",
    "        \n",
    "        print('Analysing for %i neurons'%(model_hidden_neurons))\n",
    "            \n",
    "        model_name = '%s_%s_%i_fold_%i_neuron_%i_init_model.pkl'%(df_config['hash_id'][train_id],\n",
    "                                                                  model_type, ifold, model_hidden_neurons, \n",
    "                                                                  best_init_matrix[hidden_neurons.index(model_hidden_neurons),\n",
    "                                                                                   ifold])\n",
    "        model_path = df_config['model_path'][train_id]\n",
    "            \n",
    "        if not os.path.exists(os.path.join(model_path, model_name)):    \n",
    "            print('Modelo nÃ£o existe\\n')\n",
    "            continue\n",
    "                \n",
    "        else:\n",
    "            print('Modelo existente em %s'%(os.path.join(model_path, model_name)))\n",
    "            model = MLPModel(n_hidden_neurons=ineuron,verbose=2)\n",
    "            model.load(os.path.join(model_path, model_name))\n",
    "            predictions = model.predict(trn_data)\n",
    "            figure_of_merit = accuracy_score(trgt[:,np.newaxis],np.argmax(predictions,axis=1)[:,np.newaxis])\n",
    "            figure_of_merit_relevance_refence[ifold] = figure_of_merit\n",
    "            \n",
    "            for iinput in range(data.shape[1]):\n",
    "                print('Analysing for %i input in'%(iinput),data.shape[1])\n",
    "                buffer_data = np.copy(trn_data)\n",
    "                buffer_data[:,iinput] = np.mean(buffer_data[:,iinput])\n",
    "                predictions = model.predict(buffer_data)\n",
    "                figure_of_merit = accuracy_score(trgt[:,np.newaxis],np.argmax(predictions,axis=1)[:,np.newaxis])\n",
    "                figure_of_merit_relevance_matrix[ifold, iinput] = figure_of_merit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bf27f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99174 , 0.992572, 0.99259 , 0.992586, 0.99259 , 0.989704,\n",
       "       0.99259 , 0.99259 , 0.992572, 0.983722, 0.99259 , 0.99257 ,\n",
       "       0.958502, 0.992588, 0.99259 , 0.843318, 0.96633 , 0.99259 ,\n",
       "       0.99259 , 0.99259 ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(figure_of_merit_relevance_matrix,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54050a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.45304184e-04, 1.46969385e-05, 1.11022302e-16, 4.89897949e-06,\n",
       "       1.11022302e-16, 4.27100738e-03, 1.11022302e-16, 1.11022302e-16,\n",
       "       1.16619038e-05, 6.86884386e-03, 1.11022302e-16, 1.41421356e-05,\n",
       "       9.68624881e-03, 4.00000000e-06, 1.11022302e-16, 2.15553097e-02,\n",
       "       1.19823854e-02, 1.11022302e-16, 1.11022302e-16, 1.11022302e-16])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(figure_of_merit_relevance_matrix,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8bcaab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e5d14079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAGlCAYAAAAMMnkpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEFUlEQVR4nO3de3hU1b3/8c+EywSQjCI6k0AQLGrQQMJNGPSIlDkETg5l0FrMsU2k0P6woIR4I54CUi+RnqbeiOSgIFhLuXggWqDJiamAPAxigFRyWlAgmKiZAazMmKkGSub3h4c5HUlg0JnMhffredbzsNdea+3v3n1svs/aa9Y2+Hw+nwAAAHBeCZEOAAAAIFaQOAEAAASJxAkAACBIJE4AAABBInECAAAIEokTAABAkEicAAAAgkTiBAAAEKSOkQ4gnrS0tOiTTz5R9+7dZTAYIh0OAAAIgs/n0+eff66UlBQlJJx7TonEKYQ++eQTpaamRjoMAADwDTQ0NKh3797nbEPiFELdu3eX9NWDT0pKinA0AAAgGB6PR6mpqf6/4+dC4hRCZ17PJSUlkTgBABBjgllmw+JwAACAIJE4AQAABInECQAAIEgkTgAAAEEicQIAAAgSiRMAAECQSJwAAACCROIEAAAQJBInAACAIJE4AQAABInECQAAIEgkTgAAAEEicQIAAAhSx0gHEI/SF1Qowdg10mEAAGLQkaeyIx0CzoEZJwAAgCCROAEAAAQpJhOnbdu2aeLEiUpJSZHBYFBZWdlZbf7yl7/oe9/7nkwmk7p166bhw4ervr7+nOOuW7dOaWlpSkxM1MCBA7V58+Yw3QEAAIhFMZk4eb1eZWRkqKSkpNXzhw4d0s0336y0tDRt2bJF7733nubNm6fExMQ2x9yxY4dycnI0bdo07d27V3a7XXa7XbW1teG6DQAAEGMMPp/PF+kgvg2DwaANGzbIbrf76+6880516tRJv/nNb4IeZ8qUKfJ6vdq4caO/buTIkcrMzFRpaWlQY3g8HplMJqXmr2VxOADgG2FxePs78/fb7XYrKSnpnG1jcsbpXFpaWrRp0yZde+21ysrK0pVXXqkRI0a0+jrvHzkcDtlstoC6rKwsORyONvs0NzfL4/EEFAAAEL/iLnE6evSompqa9NRTT2n8+PH67//+b02ePFm33Xabtm7d2mY/p9Mps9kcUGc2m+V0OtvsU1RUJJPJ5C+pqakhuw8AABB94i5xamlpkSRNmjRJc+bMUWZmpubOnat//dd/DfqVW7AKCwvldrv9paGhIaTjAwCA6BJ3G2D27NlTHTt21PXXXx9QP2DAAG3fvr3NfhaLRS6XK6DO5XLJYrG02cdoNMpoNH67gAEAQMyIuxmnzp07a/jw4Tpw4EBA/fvvv6+rrrqqzX5Wq1VVVVUBdZWVlbJarWGJEwAAxJ6YnHFqamrSwYMH/cd1dXWqqalRjx491KdPHz344IOaMmWKbrnlFo0ZM0bl5eX6/e9/ry1btvj75ObmqlevXioqKpIkzZ49W6NHj1ZxcbGys7O1evVqVVdXa+nSpe19ewAAIErF5IxTdXW1Bg8erMGDB0uSCgoKNHjwYM2fP1+SNHnyZJWWluqXv/ylBg4cqJdeekn/9V//pZtvvtk/Rn19vRobG/3Ho0aN0qpVq7R06VJlZGTotddeU1lZmdLT09v35gAAQNSK+X2cosmF7AMBAACiw0W9jxMAAEC4kDgBAAAEicQJAAAgSDH5q7pol76ggm/VAQDwD+LlG3zMOAEAAAQpJhOnbdu2aeLEiUpJSZHBYDjrA76PPvqo0tLS1K1bN1122WWy2Wx65513zjtuSUmJ+vbtq8TERI0YMUK7du0K0x0AAIBYFJOJk9frVUZGhkpKSlo9f+2112rx4sXat2+ftm/frr59+2rcuHE6duxYm2OuWbNGBQUFWrBggfbs2aOMjAxlZWXp6NGj4boNAAAQY2J+HyeDwaANGzbIbre32ebM/gxvvvmmxo4d22qbESNGaPjw4Vq8eLGkrz4WnJqaqnvvvVdz584NKpYz10nNX8saJwAA/kE0r3FiH6d/cPLkSS1dulQmk0kZGRltttm9e7dsNpu/LiEhQTabTQ6Ho82xm5ub5fF4AgoAAIhfcZs4bdy4UZdccokSExP19NNPq7KyUj179my17fHjx3X69GmZzeaAerPZLKfT2eY1ioqKZDKZ/CU1NTWk9wAAAKJL3CZOY8aMUU1NjXbs2KHx48frBz/4QcjXKxUWFsrtdvtLQ0NDSMcHAADRJW4Tp27duql///4aOXKkli1bpo4dO2rZsmWttu3Zs6c6dOggl8sVUO9yuWSxWNq8htFoVFJSUkABAADxK24Tp69raWlRc3Nzq+c6d+6soUOHqqqqKqB9VVWVrFZre4UIAACiXEzuHN7U1KSDBw/6j+vq6lRTU6MePXro8ssv1xNPPKHvfe97Sk5O1vHjx1VSUqKPP/5Yd9xxh7/P2LFjNXnyZM2aNUuSVFBQoLy8PA0bNkw33nijnnnmGXm9Xk2dOrXd7w8AAESnmEycqqurNWbMGP9xQUGBJCkvL0+lpaXav3+/Vq5cqePHj+vyyy/X8OHD9fbbb+uGG27w9zl06JCOHz/uP54yZYqOHTum+fPny+l0KjMzU+Xl5WctGAcAABevmN/HKZqwjxMAAK2Ll32cYnLGKdrVLsxioTgAAHHoolkcDgAA8G2ROAEAAASJV3VhkL6ggjVOAACcQzSveToXZpwAAACCFJOJ07Zt2zRx4kSlpKTIYDCorKws4LzBYGi1/Md//Mc5xy0pKVHfvn2VmJioESNGaNeuXWG8CwAAEGtiMnHyer3KyMhQSUlJq+cbGxsDyvLly2UwGHT77be3OeaaNWtUUFCgBQsWaM+ePcrIyFBWVlbIv28HAABiV8zv42QwGLRhwwbZ7fY229jtdn3++ecBn1T5uhEjRmj48OFavHixpK8+uZKamqp7771Xc+fODSoW9nECACA40bTG6UL2cYrJGacL4XK5tGnTJk2bNq3NNidPntTu3btls9n8dQkJCbLZbHI4HG32a25ulsfjCSgAACB+xX3itHLlSnXv3l233XZbm22OHz+u06dPn/V5FbPZLKfT2Wa/oqIimUwmf0lNTQ1Z3AAAIPrEfeK0fPly3XXXXUpMTAz52IWFhXK73f7S0NAQ8msAAIDoEdf7OL399ts6cOCA1qxZc852PXv2VIcOHeRyuQLqXS6XLBZLm/2MRqOMRmNIYgUAANEvrmecli1bpqFDhyojI+Oc7Tp37qyhQ4cGLB5vaWlRVVWVrFZruMMEAAAxIiYTp6amJtXU1KimpkaSVFdXp5qaGtXX1/vbeDwerVu3TtOnT291jLFjx/p/QSdJBQUFevHFF7Vy5Ur95S9/0T333COv16upU6eG9V4AAEDsiMlXddXV1RozZoz/uKCgQJKUl5enFStWSJJWr14tn8+nnJycVsc4dOiQjh8/7j+eMmWKjh07pvnz58vpdCozM1Pl5eVnLRgHAAAXr5jfxymasI8TAADBidV9nGJyxina1S7MOu+DBwAAsScm1zgBAABEAokTAABAkHhVFwbpCypY4wQAwLcQTWug/hEzTgAAAEGKycRp27ZtmjhxolJSUmQwGFRWVhZw3ufzaf78+UpOTlaXLl1ks9n0wQcfnHfckpIS9e3bV4mJiRoxYoR27doVpjsAAACxKCYTJ6/Xq4yMDJWUlLR6/pe//KWee+45lZaW6p133lG3bt2UlZWlL7/8ss0x16xZo4KCAi1YsEB79uxRRkaGsrKydPTo0XDdBgAAiDExv4+TwWDQhg0bZLfbJX0125SSkqL7779fDzzwgCTJ7XbLbDZrxYoVuvPOO1sdZ8SIERo+fLh/N/GWlhalpqbq3nvv1dy5c4OKhX2cAAAIjfZc43Qh+zjF5IzTudTV1cnpdMpms/nrTCaTRowYIYfD0WqfkydPavfu3QF9EhISZLPZ2uwjSc3NzfJ4PAEFAADEr7hLnJxOpySd9akUs9nsP/d1x48f1+nTpy+ojyQVFRXJZDL5S2pq6reMHgAARLO4S5zaU2Fhodxut780NDREOiQAABBGcZc4WSwWSZLL5Qqod7lc/nNf17NnT3Xo0OGC+kiS0WhUUlJSQAEAAPEr7hKnfv36yWKxqKqqyl/n8Xj0zjvvyGq1ttqnc+fOGjp0aECflpYWVVVVtdkHAABcfGJy5/CmpiYdPHjQf1xXV6eamhr16NFDffr0UX5+vh5//HFdc8016tevn+bNm6eUlBT/L+8kaezYsZo8ebJmzZolSSooKFBeXp6GDRumG2+8Uc8884y8Xq+mTp3a3rcHAACiVEwmTtXV1RozZoz/uKCgQJKUl5enFStW6KGHHpLX69VPf/pTnThxQjfffLPKy8uVmJjo73Po0CEdP37cfzxlyhQdO3ZM8+fPl9PpVGZmpsrLy89aMA4AAC5eMb+PUzRhHycAAEIjWvdxiskZp2hXuzCLheIAAMShuFscDgAAEC4kTgAAAEHiVV0YpC+oYI0TAAAh0p7rnc6HGScAAIAgxXXi9PHHH+uHP/yhLr/8cnXp0kUDBw5UdXX1Ofts2bJFQ4YMkdFoVP/+/bVixYr2CRYAAES9uE2cPvvsM910003q1KmT/vCHP+jPf/6ziouLddlll7XZp66uTtnZ2RozZoxqamqUn5+v6dOnq6Kioh0jBwAA0Spu1zgtWrRIqampevnll/11/fr1O2ef0tJS9evXT8XFxZKkAQMGaPv27Xr66aeVlZUV1ngBAED0i9sZpzfeeEPDhg3THXfcoSuvvFKDBw/Wiy++eM4+DodDNpstoC4rK0sOhyOcoQIAgBgRt4nT4cOHtWTJEl1zzTWqqKjQPffco/vuu08rV65ss4/T6TzrEytms1kej0dffPHFWe2bm5vl8XgCCgAAiF9x+6qupaVFw4YN05NPPilJGjx4sGpra1VaWqq8vLyQXKOoqEgLFy4MyVgAACD6xe2MU3Jysq6//vqAugEDBqi+vr7NPhaLRS6XK6DO5XIpKSlJXbp0Oat9YWGh3G63vzQ0NIQmeAAAEJXidsbppptu0oEDBwLq3n//fV111VVt9rFardq8eXNAXWVlpaxWa6vtjUajjEbjtw8WAADEhLidcZozZ4527typJ598UgcPHtSqVau0dOlSzZw509+msLBQubm5/uMZM2bo8OHDeuihh7R//3698MILWrt2rebMmROJWwAAAFEmbhOn4cOHa8OGDfrd736n9PR0PfbYY3rmmWd01113+ds0NjYGvLrr16+fNm3apMrKSmVkZKi4uFgvvfQSWxEAAABJksHn8/kiHUS88Hg8MplMSs1fy7fqAAAIkXB/q+7M32+3262kpKRzto3bNU6RVLsw67wPHgAAxJ64fVUHAAAQaiROAAAAQeJVXRikL6hgjRMAACEU7nVOwWLGCQAAIEgkTgAAAEGK28Rp27ZtmjhxolJSUmQwGFRWVnbePlu2bNGQIUNkNBrVv39/rVixIuxxAgCA2BG3iZPX61VGRoZKSkqCal9XV6fs7GyNGTNGNTU1ys/P1/Tp01VRURHmSAEAQKyI28XhEyZM0IQJE4JuX1paqn79+qm4uFjSVx8E3r59u55++ml2DgcAAJLieMbpQjkcDtlstoC6rKwsORyONvs0NzfL4/EEFAAAEL9InP6X0+mU2WwOqDObzfJ4PPriiy9a7VNUVCSTyeQvqamp7REqAACIEBKnb6GwsFBut9tfGhoaIh0SAAAIo7hd43ShLBaLXC5XQJ3L5VJSUpK6dOnSah+j0Sij0dge4QEAgCjAjNP/slqtqqqqCqirrKyU1WqNUEQAACDaxG3i1NTUpJqaGtXU1Ej6aruBmpoa1dfXS/rqNVtubq6//YwZM3T48GE99NBD2r9/v1544QWtXbtWc+bMiUT4AAAgCsVt4lRdXa3Bgwdr8ODBkqSCggINHjxY8+fPlyQ1Njb6kyhJ6tevnzZt2qTKykplZGSouLhYL730ElsRAAAAP4PP5/NFOoh44fF4ZDKZ5Ha7lZSUFOlwAABAEC7k73fczjgBAACEGokTAABAkNiOIAzSF1Qowdg10mEAABBXjjyVHekQmHECAAAIFokTAABAkGIycdq2bZsmTpyolJQUGQwGlZWV+c+dOnVKDz/8sAYOHKhu3bopJSVFubm5+uSTT847bklJifr27avExESNGDFCu3btCuNdAACAWBOTiZPX61VGRoZKSkrOOve3v/1Ne/bs0bx587Rnzx6tX79eBw4c0Pe+971zjrlmzRoVFBRowYIF2rNnjzIyMpSVlaWjR4+G6zYAAECMifl9nAwGgzZs2CC73d5mm3fffVc33nijPvzwQ/Xp06fVNiNGjNDw4cO1ePFiSVJLS4tSU1N17733au7cuUHFcmYfiNT8tSwOBwAgxMK1OJx9nL7G7XbLYDDo0ksvbfX8yZMntXv3btlsNn9dQkKCbDabHA5Hm+M2NzfL4/EEFAAAEL/iPnH68ssv9fDDDysnJ6fNLPL48eM6ffq0zGZzQL3ZbJbT6Wxz7KKiIplMJn9JTU0NaewAACC6xHXidOrUKf3gBz+Qz+fTkiVLQj5+YWGh3G63vzQ0NIT8GgAAIHrE7QaYZ5KmDz/8UH/84x/P+c6yZ8+e6tChg1wuV0C9y+WSxWJps5/RaJTRaAxZzAAAILrF5YzTmaTpgw8+0JtvvqnLL7/8nO07d+6soUOHqqqqyl/X0tKiqqoqWa3WcIcLAABiREzOODU1NengwYP+47q6OtXU1KhHjx5KTk7W97//fe3Zs0cbN27U6dOn/euUevTooc6dO0uSxo4dq8mTJ2vWrFmSpIKCAuXl5WnYsGG68cYb9cwzz8jr9Wrq1Kntf4MAACAqxWTiVF1drTFjxviPCwoKJEl5eXl69NFH9cYbb0iSMjMzA/q99dZbuvXWWyVJhw4d0vHjx/3npkyZomPHjmn+/PlyOp3KzMxUeXn5WQvGAQDAxSvm93GKJheyDwQAAIgO7OMEAAAQBiROAAAAQSJxAgAACFJMLg6PdukLKvhWHQAAIRaub9VdCGacAAAAghS3iVNRUZGGDx+u7t2768orr5TdbteBAwfO22/dunVKS0tTYmKiBg4cqM2bN7dDtAAAIBbEbeK0detWzZw5Uzt37lRlZaVOnTqlcePGyev1ttlnx44dysnJ0bRp07R3717Z7XbZ7XbV1ta2Y+QAACBaXTT7OB07dkxXXnmltm7dqltuuaXVNlOmTJHX69XGjRv9dSNHjlRmZqZKS0vPe40z+0Ck5q9ljRMAACEWrjVO7OPUCrfbLemrz660xeFwyGazBdRlZWXJ4XC02r65uVkejyegAACA+HVRJE4tLS3Kz8/XTTfdpPT09DbbOZ3Osz6xYjab/d+6+7qioiKZTCZ/SU1NDWncAAAgulwUidPMmTNVW1ur1atXh3TcwsJCud1uf2loaAjp+AAAILrE/T5Os2bN0saNG7Vt2zb17t37nG0tFotcLldAncvlksViabW90WiU0WgMWawAACC6xe2Mk8/n06xZs7Rhwwb98Y9/VL9+/c7bx2q1qqqqKqCusrJSVqs1XGECAIAYErczTjNnztSqVav0+uuvq3v37v51SiaTSV26dJEk5ebmqlevXioqKpIkzZ49W6NHj1ZxcbGys7O1evVqVVdXa+nSpRG7DwAAED3idsZpyZIlcrvduvXWW5WcnOwva9as8bepr69XY2Oj/3jUqFFatWqVli5dqoyMDL322msqKys754JyAABw8bho9nFqDxeyDwQAAIgO7OMEAAAQBiROAAAAQSJxAgAACFLc/qouktIXVPCtOgAAQixc36q7EMw4AQAABCluE6fPP/9c+fn5uuqqq9SlSxeNGjVK77777jn7bNmyRUOGDJHRaFT//v21YsWK9gkWAADEhLhNnKZPn67Kykr95je/0b59+zRu3DjZbDZ9/PHHrbavq6tTdna2xowZo5qaGuXn52v69OmqqKho58gBAEC0ist9nL744gt1795dr7/+urKz/+996NChQzVhwgQ9/vjjZ/V5+OGHtWnTJtXW1vrr7rzzTp04cULl5eVBXffMPhCp+WtZ4wQAQIiFa43TRb+P09///nedPn1aiYmJAfVdunTR9u3bW+3jcDhks9kC6rKysuRwONq8TnNzszweT0ABAADxKy4Tp+7du8tqteqxxx7TJ598otOnT+vVV1+Vw+EI+MTKP3I6nTKbzQF1ZrNZHo9HX3zxRat9ioqKZDKZ/CU1NTXk9wIAAKJHXCZOkvSb3/xGPp9PvXr1ktFo1HPPPaecnBwlJITulgsLC+V2u/2loaEhZGMDAIDoE7f7OH3nO9/R1q1b5fV65fF4lJycrClTpujqq69utb3FYpHL5Qqoc7lcSkpKUpcuXVrtYzQaZTQaQx47AACITnE743RGt27dlJycrM8++0wVFRWaNGlSq+2sVquqqqoC6iorK2W1WtsjTAAAEAPiNnGqqKhQeXm56urqVFlZqTFjxigtLU1Tp06V9NVrttzcXH/7GTNm6PDhw3rooYe0f/9+vfDCC1q7dq3mzJkTqVsAAABRJm4TJ7fbrZkzZyotLU25ubm6+eabVVFRoU6dOkmSGhsbVV9f72/fr18/bdq0SZWVlcrIyFBxcbFeeuklZWVlReoWAABAlInLfZwihX2cAAAIn2jYxyluF4dHUu3CrPM+eAAAEHvi9lUdAABAqJE4AQAABIlXdWGQvqCCNU4AAIRYuNY4XQhmnAAAAIJ0USROTz31lAwGg/Lz88/Zbt26dUpLS1NiYqIGDhyozZs3t0+AAAAgJsR94vTuu+/qP//zPzVo0KBzttuxY4dycnI0bdo07d27V3a7XXa7XbW1te0UKQAAiHZxnTg1NTXprrvu0osvvqjLLrvsnG2fffZZjR8/Xg8++KAGDBigxx57TEOGDNHixYvbKVoAABDt4jpxmjlzprKzs2Wz2c7b1uFwnNUuKytLDoejzT7Nzc3yeDwBBQAAxK+4/VXd6tWrtWfPHr377rtBtXc6nTKbzQF1ZrNZTqezzT5FRUVauHDht4oTAADEjriccWpoaNDs2bP129/+VomJiWG7TmFhodxut780NDSE7VoAACDy4nLGaffu3Tp69KiGDBnirzt9+rS2bdumxYsXq7m5WR06dAjoY7FY5HK5AupcLpcsFkub1zEajTIajaENHgAARK24nHEaO3as9u3bp5qaGn8ZNmyY7rrrLtXU1JyVNEmS1WpVVVVVQF1lZaWsVmt7hQ0AAKJcXM44de/eXenp6QF13bp10+WXX+6vz83NVa9evVRUVCRJmj17tkaPHq3i4mJlZ2dr9erVqq6u1tKlS9s9fgAAEJ3icsYpGPX19WpsbPQfjxo1SqtWrdLSpUuVkZGh1157TWVlZWclYAAA4OJl8Pl8vkgHES88Ho9MJpNS89fyrToAAEIsXN+qO/P32+12Kykp6Zxt4/JVXaTVLsw674MHAACx56J9VQcAAHChSJwAAACCxKu6MEhfUMEaJwAAQixca5wuBDNOAAAAQYrJxGnbtm2aOHGiUlJSZDAYVFZW1mbbGTNmyGAw6JlnnjnvuCUlJerbt68SExM1YsQI7dq1K3RBAwCAmBeTiZPX61VGRoZKSkrO2W7Dhg3auXOnUlJSzjvmmjVrVFBQoAULFmjPnj3KyMhQVlaWjh49GqqwAQBAjIvJxGnChAl6/PHHNXny5DbbfPzxx7r33nv129/+Vp06dTrvmL/+9a/1k5/8RFOnTtX111+v0tJSde3aVcuXLw9l6AAAIIbFZOJ0Pi0tLfrRj36kBx98UDfccMN52588eVK7d++WzWbz1yUkJMhms8nhcLTZr7m5WR6PJ6AAAID4FZeJ06JFi9SxY0fdd999QbU/fvy4Tp8+LbPZHFBvNpvldDrb7FdUVCSTyeQvqamp3ypuAAAQ3eIucdq9e7eeffZZrVixQgaDIazXKiwslNvt9peGhoawXg8AAERW3CVOb7/9to4ePao+ffqoY8eO6tixoz788EPdf//96tu3b6t9evbsqQ4dOsjlcgXUu1wuWSyWNq9lNBqVlJQUUAAAQPyKu8TpRz/6kd577z3V1NT4S0pKih588EFVVFS02qdz584aOnSoqqqq/HUtLS2qqqqS1Wptr9ABAECUi8mdw5uamnTw4EH/cV1dnWpqatSjRw/16dNHl19+eUD7Tp06yWKx6LrrrvPXjR07VpMnT9asWbMkSQUFBcrLy9OwYcN044036plnnpHX69XUqVPb56YAAEDUi8nEqbq6WmPGjPEfFxQUSJLy8vK0YsWKoMY4dOiQjh8/7j+eMmWKjh07pvnz58vpdCozM1Pl5eVnLRgHAAAXL4PP5/NFOoh44fF4vvp1Xf5avlUHAECIhetbdWf+frvd7vOuV47JGadoV7swi4XiAADEobhbHA4AABAuJE4AAABB4lVdGKQvqGCNEwAAIRauNU4XghknAACAIMVt4rRkyRINGjTIv6O31WrVH/7wh3P2WbdundLS0pSYmKiBAwdq8+bN7RQtAACIBXGbOPXu3VtPPfWUdu/ererqan33u9/VpEmT9D//8z+ttt+xY4dycnI0bdo07d27V3a7XXa7XbW1te0cOQAAiFYX1T5OPXr00H/8x39o2rRpZ52bMmWKvF6vNm7c6K8bOXKkMjMzVVpaGtT47OMEAED4RMM+TnE74/SPTp8+rdWrV8vr9bb57TmHwyGbzRZQl5WVJYfD0R4hAgCAGBDXv6rbt2+frFarvvzyS11yySXasGGDrr/++lbbOp3Osz6vYjab5XQ62xy/ublZzc3N/mOPxxOawAEAQFSK6xmn6667TjU1NXrnnXd0zz33KC8vT3/+859DNn5RUZFMJpO/pKamhmxsAAAQfeI6cercubP69++voUOHqqioSBkZGXr22WdbbWuxWORyuQLqXC6XLBZLm+MXFhbK7Xb7S0NDQ0jjBwAA0SWuE6eva2lpCXi19o+sVquqqqoC6iorK9tcEyVJRqPRv93BmQIAAOJX3K5xKiws1IQJE9SnTx99/vnnWrVqlbZs2aKKigpJUm5urnr16qWioiJJ0uzZszV69GgVFxcrOztbq1evVnV1tZYuXRrJ2wAAAFEkbhOno0ePKjc3V42NjTKZTBo0aJAqKir0z//8z5Kk+vp6JST834TbqFGjtGrVKv385z/XI488omuuuUZlZWVKT0+P1C0AAIAoc1Ht4xRu7OMEAED4RMM+TnE74xRJtQuzWO8EAEAcuqgWhwMAAHwbJE4AAABB4lVdGKQvqGCNEwAAIRauNU4XghknAACAIJE4AQAABCluE6dHH31UBoMhoKSlpZ2zz7p165SWlqbExEQNHDhQmzdvbqdoAQBALIjbxEmSbrjhBjU2NvrL9u3b22y7Y8cO5eTkaNq0adq7d6/sdrvsdrtqa2vbMWIAABDN4jpx6tixoywWi7/07NmzzbbPPvusxo8frwcffFADBgzQY489piFDhmjx4sXtGDEAAIhmcZ04ffDBB0pJSdHVV1+tu+66S/X19W22dTgcstlsAXVZWVlyOBxt9mlubpbH4wkoAAAgfsVt4jRixAitWLFC5eXlWrJkierq6vRP//RP+vzzz1tt73Q6ZTabA+rMZrOcTmeb1ygqKpLJZPKX1NTUkN4DAACILnGbOE2YMEF33HGHBg0apKysLG3evFknTpzQ2rVrQ3aNwsJCud1uf2loaAjZ2AAAIPpcNBtgXnrppbr22mt18ODBVs9bLBa5XK6AOpfLJYvF0uaYRqNRRqMxpHECAIDoFbczTl/X1NSkQ4cOKTk5udXzVqtVVVVVAXWVlZWyWq3tER4AAIgBcZs4PfDAA9q6dauOHDmiHTt2aPLkyerQoYNycnIkSbm5uSosLPS3nz17tsrLy1VcXKz9+/fr0UcfVXV1tWbNmhWpWwAAAFEmbl/VffTRR8rJydGnn36qK664QjfffLN27typK664QpJUX1+vhIT/yxtHjRqlVatW6ec//7keeeQRXXPNNSorK1N6enqkbgEAAEQZg8/n80U6iHjh8XhkMpnkdruVlJQU6XAAAEAQLuTvd9y+qgMAAAg1EicAAIAgxe0ap0hKX1ChBGPXSIcBAEBcOfJUdqRDYMYJAAAgWCROAAAAQYrbxKlv374yGAxnlZkzZ7bZZ926dUpLS1NiYqIGDhyozZs3t2PEAAAg2sVt4vTuu++qsbHRXyorKyVJd9xxR6vtd+zYoZycHE2bNk179+6V3W6X3W5XbW1te4YNAACi2EWzj1N+fr42btyoDz74QAaD4azzU6ZMkdfr1caNG/11I0eOVGZmpkpLS4O6xpl9IFLz17I4HACAEAvX4nD2cfqakydP6tVXX9WPf/zjVpMmSXI4HLLZbAF1WVlZcjgcbY7b3Nwsj8cTUAAAQPy6KBKnsrIynThxQnfffXebbZxOp8xmc0Cd2WyW0+lss09RUZFMJpO/pKamhipkAAAQhS6KxGnZsmWaMGGCUlJSQjpuYWGh3G63vzQ0NIR0fAAAEF3ifgPMDz/8UG+++abWr19/znYWi0UulyugzuVyyWKxtNnHaDTKaDSGJE4AABD94n7G6eWXX9aVV16p7OxzLyizWq2qqqoKqKusrJTVag1neAAAIIbEdeLU0tKil19+WXl5eerYMXByLTc3V4WFhf7j2bNnq7y8XMXFxdq/f78effRRVVdXa9asWe0dNgAAiFJxnTi9+eabqq+v149//OOzztXX16uxsdF/PGrUKK1atUpLly5VRkaGXnvtNZWVlSk9Pb09QwYAAFHsotnHqT1cyD4QAAAgOrCPEwAAQBiQOAEAAASJxAkAACBIcb+PUySkL6jgW3UAAIRYuL5VdyFCPuO0ZcsWGQwGnThxQpK0YsUKXXrppW22P3LkiAwGg2pqakIdCgAAQEh9o8TJ4XCoQ4cO591UMhipqalqbGyMyM/++/btq2eeeabdrwsAAGLTN0qcli1bpnvvvVfbtm3TJ5988q0C6NChgywWy1kbVAIAAESbC06cmpqatGbNGt1zzz3Kzs7WihUrvlUAX39Vd+ZVX1VVlYYNG6auXbtq1KhROnDggL/Po48+qszMTP3nf/6nUlNT1bVrV/3gBz+Q2+32t7n11luVn58fcC273a67777bf/7DDz/UnDlzZDAYZDAYJH31bbuJEyfqsssuU7du3XTDDTdo8+bN3+oeAQBAfLjgxGnt2rVKS0vTddddpx/+8Idavny5wrGH5r//+7+ruLhY1dXV6tix41m7fx88eFBr167V73//e5WXl2vv3r362c9+FvT469evV+/evfWLX/xCjY2N/l3EZ86cqebmZm3btk379u3TokWLdMkll7Q6RnNzszweT0ABAADx64Lfjy1btkw//OEPJUnjx4+X2+3W1q1bdeutt4Y0sCeeeEKjR4+WJM2dO1fZ2dn68ssvlZiYKEn68ssv9corr6hXr16SpOeff17Z2dkqLi6WxWI57/g9evRQhw4d1L1794D29fX1uv322zVw4EBJ0tVXX93mGEVFRVq4cOE3vkcAABBbLmjG6cCBA9q1a5dycnIkSR07dtSUKVO0bNmykAc2aNAg/7+Tk5MlSUePHvXX9enTx580SZLValVLS0vAK71v4r777tPjjz+um266SQsWLNB7773XZtvCwkK53W5/aWho+FbXBgAA0e2CEqdly5bp73//u1JSUtSxY0d17NhRS5Ys0X/9138FrC8KhU6dOvn/fWb9UUtLS9D9ExISznqFeOrUqfP2mz59ug4fPqwf/ehH2rdvn4YNG6bnn3++1bZGo1FJSUkBBQAAxK+gE6e///3veuWVV1RcXKyamhp/+dOf/qSUlBT97ne/C2ecZ6mvrw/4Rd/OnTuVkJCg6667TpJ0xRVX+NctSdLp06dVW1sbMEbnzp11+vTps8ZOTU3VjBkztH79et1///168cUXw3QXAAAglgSdOG3cuFGfffaZpk2bpvT09IBy++23h+V13bkkJiYqLy9Pf/rTn/T222/rvvvu0w9+8AP/eqXvfve72rRpkzZt2qT9+/frnnvu8W/KeUbfvn21bds2ffzxxzp+/LgkKT8/XxUVFaqrq9OePXv01ltvacCAAe16bwAAIDoFnTgtW7ZMNptNJpPprHO33367qqurz7keKNT69++v2267Tf/yL/+icePGadCgQXrhhRf853/84x8rLy9Pubm5Gj16tK6++mqNGTMmYIxf/OIXOnLkiL7zne/oiiuukPTVzNTMmTM1YMAAjR8/Xtdee23AuAAA4OJl8IVjL4Ewe/TRR1VWVhZ1n2nxeDwymUxKzV/Lt+oAAAixcH2r7szfb7fbfd71ymzXHQa1C7NYKA4AQBwK+Ud+AQAA4lVMvqqLVhcy1QcAAKIDr+oiLH1BBWucAAAIsXCtcboQvKoDAAAIUkwmTtu2bdPEiROVkpIig8GgsrKygPN33323DAZDQBk/fvx5xy0pKVHfvn2VmJioESNGaNeuXWG6AwAAEItiMnHyer3KyMhQSUlJm23Gjx+vxsZGfznfzuZr1qxRQUGBFixYoD179igjI0NZWVkB38cDAAAXt5hc4zRhwgRNmDDhnG2MRqN/F/Fg/PrXv9ZPfvITTZ06VZJUWlqqTZs2afny5Zo7d+63ihcAAMSHmJxxCsaWLVt05ZVX6rrrrtM999yjTz/9tM22J0+e1O7du2Wz2fx1CQkJstlscjgcbfZrbm6Wx+MJKAAAIH7FZeI0fvx4vfLKK6qqqtKiRYu0detWTZgwodUP+krS8ePHdfr0aZnN5oB6s9ksp9PZ5nWKiopkMpn8JTU1NaT3AQAAoktMvqo7nzvvvNP/74EDB2rQoEH6zne+oy1btmjs2LEhu05hYaEKCgr8xx6Ph+QJAIA4FpczTl939dVXq2fPnjp48GCr53v27KkOHTrI5XIF1LtcrnOukzIajUpKSgooAAAgfl0UidNHH32kTz/9VMnJya2e79y5s4YOHaqqqip/XUtLi6qqqmS1WtsrTAAAEOViMnFqampSTU2NampqJEl1dXWqqalRfX29mpqa9OCDD2rnzp06cuSIqqqqNGnSJPXv319ZWVn+McaOHavFixf7jwsKCvTiiy9q5cqV+stf/qJ77rlHXq/X/ys7AACAmFzjVF1drTFjxviPz6wzysvL05IlS/Tee+9p5cqVOnHihFJSUjRu3Dg99thjMhqN/j6HDh3S8ePH/cdTpkzRsWPHNH/+fDmdTmVmZqq8vPysBeMAAODixUd+Q+jMRwJT89fyrToAAEIsXN+q4yO/EVa7MIuF4gAAxKGYXOMEAAAQCSROAAAAQeJVXRikL6hgjRMAACEWrjVOF4IZJwAAgCDFZOK0bds2TZw4USkpKTIYDCorKws439TUpFmzZql3797q0qWLrr/+epWWlp533HXr1iktLU2JiYkaOHCgNm/eHKY7AAAAsSgmEyev16uMjAyVlJS0er6goEDl5eV69dVX9Ze//EX5+fmaNWuW3njjjTbH3LFjh3JycjRt2jTt3btXdrtddrtdtbW14boNAAAQY2J+HyeDwaANGzbIbrf769LT0zVlyhTNmzfPXzd06FBNmDBBjz/+eKvjTJkyRV6vVxs3bvTXjRw5UpmZmUHNVkns4wQAQDhFwz5OMTnjdD6jRo3SG2+8oY8//lg+n09vvfWW3n//fY0bN67NPg6HQzabLaAuKytLDoejzT7Nzc3yeDwBBQAAxK+4TJyef/55XX/99erdu7c6d+6s8ePHq6SkRLfcckubfZxO51mfVzGbzXI6nW32KSoqkslk8pfU1NSQ3QMAAIg+cZs47dy5U2+88YZ2796t4uJizZw5U2+++WZIr1NYWCi32+0vDQ0NIR0fAABEl7jbx+mLL77QI488og0bNig7+6t3oYMGDVJNTY1+9atfnfU67gyLxSKXyxVQ53K5ZLFY2ryW0WgM+HAwAACIb3E343Tq1CmdOnVKCQmBt9ahQwe1tLS02c9qtaqqqiqgrrKyUlarNSxxAgCA2BOTM05NTU06ePCg/7iurk41NTXq0aOH+vTpo9GjR+vBBx9Uly5ddNVVV2nr1q165ZVX9Otf/9rfJzc3V7169VJRUZEkafbs2Ro9erSKi4uVnZ2t1atXq7q6WkuXLm33+wMAANEpJhOn6upqjRkzxn9cUFAgScrLy9OKFSu0evVqFRYW6q677tJf//pXXXXVVXriiSc0Y8YMf5/6+vqAWalRo0Zp1apV+vnPf65HHnlE11xzjcrKypSent5+NwYAAKJazO/jFE3YxwkAgPCJhn2cYnLGKdrVLsw674MHAACxJ+4WhwMAAIQLiRMAAECQeFUXBukLKljjBABAiIVrjdOFYMYJAAAgSDGZOG3btk0TJ05USkqKDAaDysrKAs67XC7dfffdSklJUdeuXTV+/Hh98MEH5x133bp1SktLU2JiogYOHKjNmzeH6Q4AAEAsisnEyev1KiMjQyUlJWed8/l8stvtOnz4sF5//XXt3btXV111lWw2m7xeb5tj7tixQzk5OZo2bZr27t0ru90uu92u2tracN4KAACIITG/j5PBYNCGDRtkt9slSe+//76uu+461dbW6oYbbpAktbS0yGKx6Mknn9T06dNbHWfKlCnyer3auHGjv27kyJHKzMxUaWlpULGwjxMAAOETDfs4xeSM07k0NzdLkhITE/11CQkJMhqN2r59e5v9HA7HWR8AzsrKksPhCE+gAAAg5sRd4pSWlqY+ffqosLBQn332mU6ePKlFixbpo48+UmNjY5v9nE6nzGZzQJ3ZbJbT6WyzT3NzszweT0ABAADxK+4Sp06dOmn9+vV6//331aNHD3Xt2lVvvfWWJkyYEPBtulAoKiqSyWTyl9TU1JCODwAAokvcJU6SNHToUNXU1OjEiRNqbGxUeXm5Pv30U1199dVt9rFYLHK5XAF1LpdLFoulzT6FhYVyu93+0tDQELJ7AAAA0ScuE6czTCaTrrjiCn3wwQeqrq7WpEmT2mxrtVpVVVUVUFdZWSmr1dpmH6PRqKSkpIACAADiV0zuHN7U1KSDBw/6j+vq6lRTU6MePXqoT58+Wrduna644gr16dNH+/bt0+zZs2W32zVu3Dh/n9zcXPXq1UtFRUWSpNmzZ2v06NEqLi5Wdna2Vq9ererqai1durTd7w8AAESnmEycqqurNWbMGP9xQUGBJCkvL08rVqxQY2OjCgoK5HK5lJycrNzcXM2bNy9gjPr6+oA1T6NGjdKqVav085//XI888oiuueYalZWVKT09vX1uCgAARL2Y38cpmrCPEwAA4RMN+zjF5IxTtKtdmMV6JwAA4lBcLw4HAAAIJRInAACAIPGqLgzSF1SwxgkAgBAL1xqnC8GMEwAAQJBInAAAAIIUk4lTUVGRhg8fru7du+vKK6+U3W7XgQMHAtp8+eWXmjlzpi6//HJdcskluv3228/6pMrX+Xw+zZ8/X8nJyerSpYtsNps++OCDcN4KAACIITGZOG3dulUzZ87Uzp07VVlZqVOnTmncuHHyer3+NnPmzNHvf/97rVu3Tlu3btUnn3yi22677Zzj/vKXv9Rzzz2n0tJSvfPOO+rWrZuysrL05ZdfhvuWAABADIiLDTCPHTumK6+8Ulu3btUtt9wit9utK664QqtWrdL3v/99SdL+/fs1YMAAORwOjRw58qwxfD6fUlJSdP/99+uBBx6QJLndbpnNZq1YsUJ33nnneeNgA0wAAMInGjbAjMkZp69zu92SpB49ekiSdu/erVOnTslms/nbpKWlqU+fPnI4HK2OUVdXJ6fTGdDHZDJpxIgRbfZpbm6Wx+MJKAAAIH7FfOLU0tKi/Px83XTTTf7vyjmdTnXu3FmXXnppQFuz2Syn09nqOGfqzWZz0H2KiopkMpn8JTU19VveDQAAiGYxnzjNnDlTtbW1Wr16dbtfu7CwUG63218aGhraPQYAANB+YjpxmjVrljZu3Ki33npLvXv39tdbLBadPHlSJ06cCGjvcrlksVhaHetM/dd/eXeuPkajUUlJSQEFAADEr5hMnHw+n2bNmqUNGzboj3/8o/r16xdwfujQoerUqZOqqqr8dQcOHFB9fb2sVmurY/br108WiyWgj8fj0TvvvNNmHwAAcHGJycRp5syZevXVV7Vq1Sp1795dTqdTTqdTX3zxhaSvFnVPmzZNBQUFeuutt7R7925NnTpVVqs14Bd1aWlp2rBhgyTJYDAoPz9fjz/+uN544w3t27dPubm5SklJkd1uj8RtAgCAKBOT36pbsmSJJOnWW28NqH/55Zd19913S5KefvppJSQk6Pbbb1dzc7OysrL0wgsvBLQ/cOCA/xd5kvTQQw/J6/Xqpz/9qU6cOKGbb75Z5eXlSkxMDOv9AACA2BAX+zhFiwvZBwIAAESHi24fJwAAgPZA4gQAABCkmFzjFO3SF1TwyRUAAEIsXJ9cuRDMOAEAAASJxAkAACBIcZs4nT59WvPmzVO/fv3UpUsXfec739Fjjz2m8/2IcMuWLRoyZIiMRqP69++vFStWtE/AAAAg6sXtGqdFixZpyZIlWrlypW644QZVV1dr6tSpMplMuu+++1rtU1dXp+zsbM2YMUO//e1vVVVVpenTpys5OVlZWVntfAcAACDaxG3itGPHDk2aNEnZ2V8tJOvbt69+97vfadeuXW32KS0tVb9+/VRcXCxJGjBggLZv366nn36axAkAAMTvq7pRo0apqqpK77//viTpT3/6k7Zv364JEya02cfhcMhmswXUZWVlyeFwtNq+ublZHo8noAAAgPgVtzNOc+fOlcfjUVpamjp06KDTp0/riSee0F133dVmH6fTKbPZHFBnNpvl8Xj0xRdfqEuXLgHnioqKtHDhwrDEDwAAok/czjitXbtWv/3tb7Vq1Srt2bNHK1eu1K9+9SutXLkyZNcoLCyU2+32l4aGhpCNDQAAok/czjg9+OCDmjt3ru68805J0sCBA/Xhhx+qqKhIeXl5rfaxWCxyuVwBdS6XS0lJSWfNNkmS0WiU0WgMffAAACAqxe2M09/+9jclJATeXocOHdTS0tJmH6vVqqqqqoC6yspKWa3WsMQIAABiS9wmThMnTtQTTzyhTZs26ciRI9qwYYN+/etfa/Lkyf42hYWFys3N9R/PmDFDhw8f1kMPPaT9+/frhRde0Nq1azVnzpxI3AIAAIgycfuq7vnnn9e8efP0s5/9TEePHlVKSor+3//7f5o/f76/TWNjo+rr6/3H/fr106ZNmzRnzhw9++yz6t27t1566SW2IgAAAJIkg+98W2kjaB6PRyaTSW63W0lJSZEOBwAABOFC/n7H7as6AACAUCNxAgAACBKJEwAAQJDidnF4JKUvqFCCsWukwwAAIK4ceSo70iEw4wQAABCsmEyctm3bpokTJyolJUUGg0FlZWUB59evX69x48bp8ssvl8FgUE1NTVDjrlu3TmlpaUpMTNTAgQO1efPm0AcPAABiVkwmTl6vVxkZGSopKWnz/M0336xFixYFPeaOHTuUk5OjadOmae/evbLb7bLb7aqtrQ1V2AAAIMbF/D5OBoNBGzZskN1uP+vckSNH1K9fP+3du1eZmZnnHGfKlCnyer3auHGjv27kyJHKzMxUaWlpULGc2QciNX8ta5wAAAixcK1xYh+nb8DhcMhmswXUZWVlyeFwtNmnublZHo8noAAAgPhF4vS/nE6nzGZzQJ3ZbJbT6WyzT1FRkUwmk7+kpqaGO0wAABBBJE7fQmFhodxut780NDREOiQAABBG7OP0vywWi1wuV0Cdy+WSxWJps4/RaJTRaAx3aAAAIEow4/S/rFarqqqqAuoqKytltVojFBEAAIg2MTnj1NTUpIMHD/qP6+rqVFNTox49eqhPnz7661//qvr6en3yySeSpAMHDkj6albpzAxSbm6uevXqpaKiIknS7NmzNXr0aBUXFys7O1urV69WdXW1li5d2s53BwAAolVMzjhVV1dr8ODBGjx4sCSpoKBAgwcP1vz58yVJb7zxhgYPHqzs7K9+tnjnnXdq8ODBAdsK1NfXq7Gx0X88atQorVq1SkuXLlVGRoZee+01lZWVKT09vR3vDAAARLOY38cpmlzIPhAAACA6sI8TAABAGJA4AQAABInECQAAIEgkTgAAAEEicQIAAAgSiRMAAECQSJwAAACCROIEAAAQJBInAACAIJE4AQAABInECQAAIEgkTgAAAEEicQIAAAgSiRMAAECQSJwAAACC1DHSAcQTn88nSfJ4PBGOBAAABOvM3+0zf8fPhcQphD799FNJUmpqaoQjAQAAF+rzzz+XyWQ6ZxsSpxDq0aOHJKm+vv68Dx6h5fF4lJqaqoaGBiUlJUU6nIsOzz9yePaRw7OPnFA/e5/Pp88//1wpKSnnbUviFEIJCV8tGTOZTPxHFCFJSUk8+wji+UcOzz5yePaRE8pnH+yEB4vDAQAAgkTiBAAAECQSpxAyGo1asGCBjEZjpEO56PDsI4vnHzk8+8jh2UdOJJ+9wRfMb+8AAADAjBMAAECwSJwAAACCROIEAAAQJBInAACAIJE4AQAABInECcC3VldXp7///e+RDuOixbOPLH6cfnEhcfoW/vznP+tnP/uZBg8erOTkZCUnJ2vw4MH62c9+pj//+c+RDi+uNTY26tVXX9XmzZt18uTJgHNer1e/+MUvIhTZxem6667TBx98EOkw4l55ebn27dsnSWppadFjjz2mXr16yWg0qnfv3nrqqaf4Ix4mzc3NeuCBB3TLLbdo0aJFkqTHH39cl1xyibp3765/+7d/k8fjiXCUF4/m5mY1NzdH5Nrs4/QN/eEPf5DdbteQIUOUlZUls9ksSXK5XKqsrNTu3bv1+uuvKysrK8KRxp93331X48aNU0tLi06dOqVevXqprKxMN9xwg6Sv/jdISUnR6dOnIxxp/LnttttarX/99df13e9+V927d5ckrV+/vj3DumikpaXpxRdf1D/90z+pqKhIxcXF+vd//3cNGDBABw4cUFFRkebMmaOHH3440qHGnYKCAq1Zs0Y5OTnavHmzxowZo40bN+rJJ59UQkKC5s+frwkTJui5556LdKhxq7KyUk8//bQcDoc/SU1KSpLValVBQYFsNlu7xEHi9A1lZGRo0qRJbc5sPProo1q/fr3ee++9do4s/v3zP/+zUlNT9dJLL8nr9erhhx/W2rVrVVlZqcGDB5M4hVFCQoJuueUW9evXL6D+lVde0fe+9z1deumlkqSXX345AtHFv8TERL3//vvq06ePBg4cqPnz5+uOO+7wn9+0aZPy8/OZ/QuDPn36aPny5bLZbDp8+LCuueYarV+/XpMmTZL01R/1n/zkJzpy5EhkA41TK1eu1PTp0/X973//rMmK//7v/9Zrr72mZcuW6Uc/+lH4g/HhG0lMTPTt37+/zfP79+/3JSYmtmNEF4/LLrvMd+DAgYC6oqIi32WXXebbtWuXz+l0+hISEiIUXXz73e9+5+vdu7dv+fLlAfUdO3b0/c///E+Eorp4JCcn+xwOh8/n8/nMZrNvz549Aefff/99X5cuXSIRWtzr0qWL78MPP/Qfd+rUyVdbW+s/rqur83Xt2jUSoV0UrrnmGt/ixYvbPF9SUuLr379/u8TCGqdvqG/fvtq0aVOb5zdt2qSrrrqqHSO6uHz55ZcBx3PnztUjjzyicePGaceOHRGKKv7deeedevvtt7Vs2TLdfvvt+uyzzyId0kVl8uTJeuKJJ3T69GlNmjRJL7zwQsCapueff16ZmZmRCzCO9enTRw6HQ9JXywUMBoN27drlP//OO++oV69ekQov7tXX15/zVdzYsWP10UcftUssHdvlKnHoF7/4hf7t3/5NW7Zskc1mC5g2rKqqUnl5uVatWhXhKONTenq6duzYoUGDBgXUP/DAA2ppaVFOTk6EIrs49O3bV9u2bdPChQuVkZGhF198UQaDIdJhXRSefPJJ2Ww2paWlyWq1at26daqsrNS1116rgwcP6q9//asqKioiHWZcmjFjhu6++2699NJL2r17t371q1/pkUce0f79+5WQkKAlS5bo/vvvj3SYceuGG27QsmXL9Mtf/rLV88uXL9f111/fLrGwxulb2LFjh5577jk5HA45nU5JksVikdVq1ezZs2W1WiMcYXx66aWXtHXrVv3mN79p9fyiRYtUWlqqurq6do7s4rN9+3bl5ubqww8/1L59+9rt/7guZqdOndKyZcv0+9//XocPH1ZLS4uSk5N100036Z577lHv3r0jHWLcWrVqlRwOh0aNGqWcnBxt2bJF8+fP19/+9jdNnDhR8+bNU0ICL3LCYcuWLfrXf/1XXX311a1OVhw+fFibNm3SLbfcEvZYSJwAfCtNTU06dOiQBgwYoM6dO0c6HABx6siRI1qyZIl27tx51mTFjBkz1Ldv33aJg8QJAAAgSMwphskjjzyiH//4x5EO46LEs48cnn1k8fwjh2d/8SBxCpOPPvqI/TwihGcfOTz7yOL5Rw7PPrLy8vL03e9+t12uxas6AAAQ0woLC+V0Ottl810Sp2/h+PHjWr58+Vm/qhs1apTuvvtuXXHFFRGOMH7x7COHZx9ZPP/I4dlDInH6xt59911lZWWpa9eurf408m9/+5sqKio0bNiwCEcaf3j2kcOzjyyef+Tw7KNbQ0ODFixYoOXLl4f9WiRO39DIkSOVkZGh0tLSszb/8/l8mjFjht577z3/TrMIHZ595PDsI4vnHzk8++j2pz/9SUOGDGmXb5SSOH1DXbp00d69e5WWltbq+f3792vw4MH64osv2jmy+MezjxyefWTx/COHZx9Zb7zxxjnPHz58WPfff3+7JE58cuUbslgs2rVrV5v/Ee3atcs/lYvQ4tlHDs8+snj+kcOzjyy73S6DwaBzzfW016efSJy+oQceeEA//elPtXv3bo0dO/as990vvviifvWrX0U4yvjEs48cnn1k8fwjh2cfWcnJyXrhhRc0adKkVs/X1NRo6NCh7ROMD9/Y6tWrfSNGjPB17NjRZzAYfAaDwdexY0ffiBEjfGvWrIl0eHGNZx85PPvI4vlHDs8+ciZOnOibN29em+dramp8BoOhXWJhjVMInDp1SsePH5ck9ezZU506dYpwRBcPnn3k8Owji+cfOTz79vf222/L6/Vq/PjxrZ73er2qrq7W6NGjwx4LiRMAAECQ+OQKAABAkEicAAAAgkTiBAAAECQSJwAAgCCROAEAAASJxAkAACBIJE4AAABBInECAAAI0v8HMOP3Zl6Ex+YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "index = np.arange(1,data.shape[1]+1)[:,np.newaxis]\n",
    "rel_mean = np.mean(figure_of_merit_relevance_matrix,axis=0)[:,np.newaxis]\n",
    "rel_std = np.std(figure_of_merit_relevance_matrix,axis=0)[:,np.newaxis]\n",
    "\n",
    "df_relevance = pd.DataFrame(data=np.concatenate((index, rel_mean, rel_std),axis=1), \n",
    "                            columns=['input', 'mean', 'std'])\n",
    "df_relevance = df_relevance.astype({\"input\": str, \"mean\": float, \"std\": float})\n",
    "\n",
    "\n",
    "index = 'All inputs'\n",
    "rel_mean = np.mean(figure_of_merit_relevance_refence,axis=0)\n",
    "rel_std = np.std(figure_of_merit_relevance_refence,axis=0)\n",
    "\n",
    "df_reference = pd.DataFrame(data=(index, rel_mean[0], rel_std[0])).T\n",
    "df_reference = df_reference.rename(columns={0:'input', 1:'mean', 2:'std'})\n",
    "\n",
    "df_relevance = pd.concat([df_relevance, df_reference], axis=0)\n",
    "\n",
    "df_relevance = df_relevance.sort_values(by=['mean'], ascending=False)\n",
    "\n",
    "\n",
    "plt.barh(df_relevance['input'], df_relevance['mean'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "#df_relevance = np.sort(df_relevance, order=['mean', 'std']) # Sort by mean, then std if means are equal\n",
    "\n",
    "#plt.barh(np.arange(1,data.shape[1]+1),np.mean(figure_of_merit_relevance_matrix,axis=0))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0cfd7e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df_relevance.plot.barh(x='input', y='mean', rot=0, legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "da2955cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all inputs</td>\n",
       "      <td>0.99259</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        input     mean  std\n",
       "0  all inputs  0.99259  0.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reference = df_reference.rename(columns={0:'input', 1:'mean', 2:'std'})\n",
    "df_reference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
